{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from translate_api.translate_api import api\n",
    "from numpy import *\n",
    "import unidecode\n",
    "import snowballstemmer\n",
    "from hunspell import Hunspell\n",
    "import numpy as np\n",
    "\n",
    "def levenshtein(source, target):\n",
    "    if len(source) < len(target):\n",
    "        return levenshtein(target, source)\n",
    "\n",
    "    # So now we have len(source) >= len(target).\n",
    "    if len(target) == 0:\n",
    "        return len(source)\n",
    "\n",
    "    # We call tuple() to force strings to be used as sequences\n",
    "    # ('c', 'a', 't', 's') - numpy uses them as values by default.\n",
    "    source = np.array(tuple(source))\n",
    "    target = np.array(tuple(target))\n",
    "\n",
    "    # We use a dynamic programming algorithm, but with the\n",
    "    # added optimization that we only need the last two rows\n",
    "    # of the matrix.\n",
    "    previous_row = np.arange(target.size + 1)\n",
    "    for s in source:\n",
    "        # Insertion (target grows longer than source):\n",
    "        current_row = previous_row + 1\n",
    "\n",
    "        # Substitution or matching:\n",
    "        # Target and source items are aligned, and either\n",
    "        # are different (cost of 1), or are the same (cost of 0).\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                np.add(previous_row[:-1], target != s))\n",
    "\n",
    "        # Deletion (target grows shorter than source):\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                current_row[0:-1] + 1)\n",
    "\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "\n",
    "h = Hunspell('pt_BR', hunspell_data_dir='pt_BR')\n",
    "\n",
    "read = pd.ExcelFile('Banco de Termos final Lucas 10-04-2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_termos = read.parse('Planilha1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.ExcelFile('CliniMap_CIPE2.xlsx')\n",
    "CIPE_df = read.parse('Match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.ExcelFile('CIPE2017_tabela organizada_CPeCC.xlsx')\n",
    "df_CIPE = read.parse('Plan1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb(lis, dict_lis):\n",
    "    aux = []\n",
    "    for s in lis:\n",
    "        for ss in dict_lis:\n",
    "            aux.append(s+' '+ss)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removearticles(text):\n",
    "    text = re.sub('\"','',text)\n",
    "    return re.sub('\\s+(de|do|dos|da|das|o|os|a|as|com|para|pra|e|ou|na|nas|no|nos|ao|aos|em|mg|ml|um)(\\s+)',' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematizador(text):\n",
    "    auxt = str('')\n",
    "    words = text.split()\n",
    "    for x in words:\n",
    "        if h.spell(x):\n",
    "            if len(h.stem(x)) != 0:\n",
    "                auxt += h.stem(x)[0] + ' '\n",
    "            else:\n",
    "                auxt += x + ' '\n",
    "        else:\n",
    "            auxt += x + ' '\n",
    "    auxt.strip()\n",
    "    return auxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "    stemmer = snowballstemmer.stemmer('portuguese')\n",
    "    return ' '.join(stemmer.stemWords(text.split())).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini = time.time()\n",
    "h = Hunspell('pt_BR', hunspell_data_dir='pt_BR')\n",
    "\n",
    "\n",
    "cnx = pymysql.connect(user='root', password='1234',database='umls2017aa')\n",
    "cursor = cnx.cursor()\n",
    "sqlstr = (\"SELECT  CUI, STR FROM umls2017aa.mrconso where LAT='POR' order by CUI;\")\n",
    "cursor.execute(sqlstr)\n",
    "umls = []\n",
    "CUI1 = []\n",
    "STR1 = []\n",
    "y = 0\n",
    "for (CUI,STR) in cursor:\n",
    "    CUI1.insert(y,CUI)\n",
    "    STR1.insert(y,STR)\n",
    "    y+=1\n",
    "umls = array([STR1,CUI1])\n",
    "umls2 = array([STR1,STR1,STR1,CUI1])\n",
    "df_umls = pd.DataFrame(umls.transpose(),columns=['STR','CUI'])\n",
    "df_umls_norm = pd.DataFrame(umls2.transpose(),columns=['STR', 'STRlemma', 'STRstem', 'CUI'])\n",
    "\n",
    "sqlstr = (\"SELECT  CUI, WD FROM umls2017aa.mrxw_por;\")\n",
    "cursor.execute(sqlstr)\n",
    "umls = []\n",
    "CUI2 = []\n",
    "WD2 = []\n",
    "y = 0\n",
    "for (CUI,WD) in cursor:\n",
    "    CUI2.insert(y,CUI)\n",
    "    WD2.insert(y,WD)\n",
    "    y+=1\n",
    "umls_word = array([WD2,CUI2])\n",
    "umls2_word = array([WD2,WD2,WD2,CUI2])\n",
    "df_umls_word = pd.DataFrame(umls_word.transpose(),columns=['WD','CUI'])\n",
    "df_umls_word_norm = pd.DataFrame(umls2_word.transpose(),columns=['WD', 'WDlemma', 'WDstem', 'CUI'])\n",
    "\n",
    "sqlstr = (\"SELECT CUI1, CUI2 FROM umls2017aa.mrrel where CUI1!=CUI2 and REL='SY';\")\n",
    "cursor.execute(sqlstr)\n",
    "umls = []\n",
    "CUIs2 = []\n",
    "CUIs1 = []\n",
    "y = 0\n",
    "for (CUI1,CUI2) in cursor:\n",
    "    CUIs1.insert(y,CUI1)\n",
    "    CUIs2.insert(y,CUI2)\n",
    "    y+=1\n",
    "umls_word = array([CUIs2,CUIs1])\n",
    "df_umls_rel = pd.DataFrame(umls_word.transpose(),columns=['CUI1','CUI2'])\n",
    "\n",
    "cursor.close()\n",
    "cnx.close()\n",
    "\n",
    "for x in range(0,df_umls['STR'].size):\n",
    "    df_umls.at[x,'STR'] = str(df_umls.at[x,'STR']).lower()\n",
    "\n",
    "for x in range(0,df_umls_word['WD'].size):\n",
    "    df_umls_word.at[x,'WD'] = str(df_umls_word.at[x,'WD']).lower()\n",
    "\n",
    "for x in range(0,df_umls_norm['STR'].size):\n",
    "    df_umls_norm.at[x,'STR'] = str(df_umls_norm.at[x,'STR']).lower()\n",
    "    df_umls_norm.at[x,'STRlemma'] = str(df_umls_norm.at[x,'STRlemma']).lower()\n",
    "    df_umls_norm.at[x,'STRstem'] = str(df_umls_norm.at[x,'STRstem']).lower()\n",
    "\n",
    "for x in range(0,df_umls_word_norm['WD'].size):\n",
    "    df_umls_word_norm.at[x,'WD'] = str(df_umls_word_norm.at[x,'WD']).lower()\n",
    "    df_umls_word_norm.at[x,'WDlemma'] = str(df_umls_word_norm.at[x,'WDlemma']).lower()\n",
    "    df_umls_word_norm.at[x,'WDstem'] = str(df_umls_word_norm.at[x,'WDstem']).lower()\n",
    "\n",
    "\n",
    "for x in range(0,df_umls_norm['STR'].size):\n",
    "    df_umls_norm.at[x,'STR'] = removearticles(unidecode.unidecode(str(df_umls_norm.at[x,'STR']))).strip()\n",
    "\n",
    "for x in range(0,df_umls_norm['STRlemma'].size):\n",
    "    df_umls_norm.at[x,'STRlemma'] = removearticles(unidecode.unidecode(lematizador(str(df_umls_norm.at[x,'STRlemma']))))\n",
    "\n",
    "for x in range(0,df_umls_norm['STRstem'].size):\n",
    "    df_umls_norm.at[x,'STRstem'] = removearticles(unidecode.unidecode(stemmer(str(df_umls_norm.at[x,'STRstem']))))\n",
    "\n",
    "for x in range(0,df_umls_word_norm['WD'].size):\n",
    "    df_umls_word_norm.at[x,'WD'] = unidecode.unidecode(str(df_umls_word_norm.at[x,'WD'])).strip()\n",
    "\n",
    "for x in range(0,df_umls_word_norm['WDlemma'].size):\n",
    "    df_umls_word_norm.at[x,'WDlemma'] = unidecode.unidecode(lematizador(str(df_umls_word_norm.at[x,'WDlemma'])))\n",
    "\n",
    "for x in range(0,df_umls_word_norm['WDstem'].size):\n",
    "    df_umls_word_norm.at[x,'WDstem'] = unidecode.unidecode(stemmer(str(df_umls_word_norm.at[x,'WDstem'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,df_termos.size):\n",
    "    df_termos.at[x,'Termos'] = str(df_termos.at[x,'Termos']).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,df_CIPE['Termo'].size):\n",
    "    df_CIPE.at[x,'Termo'] = str(df_CIPE.at[x,'Termo']).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_termos_norm = pd.DataFrame(data=None, columns=['Termos'])\n",
    "df_termos_lemma = pd.DataFrame(data=None, columns=['Termos'])\n",
    "df_termos_stem = pd.DataFrame(data=None, columns=['Termos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CIPE_norm = pd.DataFrame(data=None, columns=['Termo'])\n",
    "df_CIPE_lemma = pd.DataFrame(data=None, columns=['Termo'])\n",
    "df_CIPE_stem = pd.DataFrame(data=None, columns=['Termo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,df_termos.size):\n",
    "    df_termos_norm.at[x,'Termos'] = removearticles(unidecode.unidecode(str(df_termos.at[x,'Termos']))).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,df_termos.size):\n",
    "    df_termos_lemma.at[x,'Termos'] = removearticles(unidecode.unidecode(lematizador(str(df_termos.at[x,'Termos']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,df_termos.size):\n",
    "    df_termos_stem.at[x,'Termos'] = removearticles(unidecode.unidecode(stemmer(str(df_termos.at[x,'Termos']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,df_CIPE['Termo'].size):\n",
    "    df_CIPE_norm.at[x,'Termo'] = removearticles(unidecode.unidecode(str(df_CIPE.at[x,'Termo']))).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,df_CIPE['Termo'].size):\n",
    "    df_CIPE_lemma.at[x,'Termo'] = removearticles(unidecode.unidecode(lematizador(str(df_CIPE.at[x,'Termo']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,df_CIPE['Termo'].size):\n",
    "    df_CIPE_stem.at[x,'Termo'] = removearticles(unidecode.unidecode(stemmer(str(df_CIPE.at[x,'Termo']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estagnação\n",
      "estagnacao\n",
      "estagnacao \n",
      "estagn\n"
     ]
    }
   ],
   "source": [
    "print(df_termos.at[301,'Termos'])\n",
    "print(df_termos_norm.at[301,'Termos'])\n",
    "print(df_termos_lemma.at[301, 'Termos'])\n",
    "print(df_termos_stem.at[301, 'Termos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controle da dor \n",
      "controle dor\n",
      "controlar dor \n",
      "control dor\n"
     ]
    }
   ],
   "source": [
    "print(df_CIPE.at[2301,'Termo'])\n",
    "print(df_CIPE_norm.at[2301,'Termo'])\n",
    "print(df_CIPE_lemma.at[2301, 'Termo'])\n",
    "print(df_CIPE_stem.at[2301, 'Termo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cama, álveo, casamento, matrimônio, estrato]\n"
     ]
    }
   ],
   "source": [
    "from dicio import Dicio\n",
    "\n",
    "# Create a Dicio object\n",
    "dicio = Dicio()\n",
    "\n",
    "# Search for \"Doce\" and return an object Word\n",
    "word = dicio.search(\"leito\")\n",
    "\n",
    "# Print the word, the url and the meaning\n",
    "# print(word, word.url, word.meaning)\n",
    "\n",
    "# Print a list of synonyms\n",
    "print(word.synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_termos_match = pd.DataFrame(data=None, columns=['Termos', 'Regra', 'perc', 'ICNPcode', 'ICNPterm',\n",
    "                                                   'ICNPmod', 'ICNPeixo', 'ICNPVersao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333334\n",
      "abertura indiscriminada  entrou\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-fa1a138439fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_umls_norm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdf_termos_lemma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Termos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf_umls_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STRlemma'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_umls_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STRlemma'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mt_max_lemma\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_umls_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STRlemma'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mt_min_lemma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                 \u001b[0mnum_lemma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevenshtein\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_termos_lemma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Termos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_umls_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STRlemma'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m                 \u001b[0mnum_steam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevenshtein\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_termos_stem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Termos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_umls_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STRstem'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_umls_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STRlemma'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-4bfdab8efd0a>\u001b[0m in \u001b[0;36mlevenshtein\u001b[1;34m(source, target)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlevenshtein\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlevenshtein\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# So now we have len(source) >= len(target).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-4bfdab8efd0a>\u001b[0m in \u001b[0;36mlevenshtein\u001b[1;34m(source, target)\u001b[0m\n\u001b[0;32m     36\u001b[0m         current_row[1:] = np.minimum(\n\u001b[0;32m     37\u001b[0m                 \u001b[0mcurrent_row\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                 np.add(previous_row[:-1], target != s))\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# Deletion (target grows shorter than source):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(100 - 1 / len('lucass') * 100)\n",
    "\n",
    "zz = 0\n",
    "achou = 0\n",
    "candidato = ''\n",
    "perc_max = 0\n",
    "metodo = 0\n",
    "y_aux = 0\n",
    "terms = 0\n",
    "\n",
    "\n",
    "\n",
    "controle = 1\n",
    "for x in range(0, len(df_termos_norm)):\n",
    "    CUIS = []\n",
    "    t = len(df_termos_norm.at[x,'Termos'])\n",
    "    t_max = int(t+(t*0.2))\n",
    "    t_min =  int(t-(t*0.2))\n",
    "    t_lemma = len(df_termos_lemma.at[x, 'Termos'])\n",
    "    t_max_lemma = int(t_lemma+(t_lemma*0.2))\n",
    "    t_min_lemma =  int(t_lemma-(t_lemma*0.2))\n",
    "    perc_max=0\n",
    "    metodo = 0\n",
    "    '''locTerm = CIPE_df.loc[CIPE_df['Termos'] == df_termos.at[x, 'Termos']]\n",
    "    if not locTerm['Termos'].empty:\n",
    "    #if df_termos.at[x, 'Termos'] == CIPE_df.at[zzz, 'Termos']:\n",
    "        for xx in range(0,len(locTerm['Termos'])):\n",
    "            df_termos_match.at[zz, 'Termos'] = CIPE_df.at[locTerm.index[xx], 'Termos']\n",
    "            df_termos_match.at[zz, 'ICNPcode'] = CIPE_df.at[locTerm.index[xx], 'ICNPcode']\n",
    "            df_termos_match.at[zz, 'ICNPterm'] = CIPE_df.at[locTerm.index[xx], 'ICNPterm']\n",
    "            df_termos_match.at[zz, 'ICNPmod'] = CIPE_df.at[locTerm.index[xx], 'ICNPmod']\n",
    "            df_termos_match.at[zz, 'ICNPVersao'] = CIPE_df.at[locTerm.index[xx], 'ICNPVersao']\n",
    "            df_termos_match.at[zz, 'ICNPeixo'] = CIPE_df.at[locTerm.index[xx], 'ICNPeixo']\n",
    "            df_termos_match.at[zz, 'Regra'] = CIPE_df.at[locTerm.index[xx], 'Regra']\n",
    "            df_termos_match.at[zz, 'perc'] = CIPE_df.at[locTerm.index[xx], 'perc']\n",
    "            zz += 1\n",
    "        continue\n",
    "    print(df_termos.at[x, 'Termos'], ' ------- passou')\n",
    "    print(controle , ' termos ja passaram')'''\n",
    "    controle += 1\n",
    "    for y in range(0, len(df_CIPE_norm)):\n",
    "        num = levenshtein(df_termos_norm.at[x, 'Termos'], df_CIPE_norm.at[y, 'Termo'])\n",
    "        perc = 100 - num / len(df_CIPE_norm.at[y, 'Termo']) * 100\n",
    "        if perc > perc_max:\n",
    "            perc_max = perc\n",
    "            candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "            metodo = 1\n",
    "            y_aux = y\n",
    "    if not perc_max == 100:\n",
    "        print(df_termos_norm.at[x,'Termos'],' entrou')\n",
    "        noventa = False\n",
    "        for y in range(0,len(df_umls_norm['STR'])):\n",
    "            \n",
    "            if df_termos_norm.at[x,'Termos'][0] == df_umls_norm.at[y,'STR'][0] and len(df_umls_norm.at[y,'STR']) < t_max and len(df_umls_norm.at[y,'STR']) > t_min:\n",
    "                num = levenshtein(df_termos_norm.at[x,'Termos'],df_umls_norm.at[y,'STR'])\n",
    "                if len(df_umls_norm.at[y,'STR']) > 0:\n",
    "                    perc = 100-num/len(df_umls_norm.at[y,'STR'])*100\n",
    "                else:\n",
    "                    perc = 0\n",
    "                if perc == 100:\n",
    "                    if not df_umls_norm.at[y, 'CUI'] in CUIS:\n",
    "                        CUIS.append(df_umls_norm.at[y, 'CUI'])\n",
    "                        for z in range(0, len(df_umls_rel)):\n",
    "                            if df_umls_rel.at[z,'CUI1'] == df_umls_norm.at[y, 'CUI']:\n",
    "                                if not df_umls_rel.at[z,'CUI2'] in CUIS:\n",
    "                                    CUIS.append(df_umls_rel.at[z,'CUI2'])\n",
    "                    print('achou')\n",
    "                    noventa = False\n",
    "                    terms += 1\n",
    "                    break\n",
    "                if perc >= 90:\n",
    "                    if not df_umls_norm.at[y, 'CUI'] in CUIS:\n",
    "                        CUIS.append(df_umls_norm.at[y, 'CUI'])\n",
    "                        for z in range(0, len(df_umls_rel)):\n",
    "                            if df_umls_rel.at[z,'CUI1'] == df_umls_norm.at[y, 'CUI']:\n",
    "                                if not df_umls_rel.at[z,'CUI2'] in CUIS:\n",
    "                                    CUIS.append(df_umls_rel.at[z,'CUI2'])\n",
    "                    print('talvez achou')\n",
    "                    noventa = True\n",
    "        if noventa:\n",
    "            terms+=1\n",
    "        if perc < 90:\n",
    "            noventa = False\n",
    "        for y in range(0,len(df_umls_norm['STR'])):\n",
    "            if df_termos_lemma.at[x, 'Termos'][0] == df_umls_norm.at[y, 'STRlemma'][0] and len(df_umls_norm.at[y, 'STRlemma']) < t_max_lemma and len(df_umls_norm.at[y, 'STRlemma']) > t_min_lemma:\n",
    "                num_lemma = levenshtein(df_termos_lemma.at[x, 'Termos'], df_umls_norm.at[y, 'STRlemma'])\n",
    "                num_steam = levenshtein(df_termos_stem.at[x, 'Termos'], df_umls_norm.at[y, 'STRstem'])\n",
    "                if len(df_umls_norm.at[y, 'STRlemma']) > 0:\n",
    "                    perc_lemma = 100-num_lemma/len(df_umls_norm.at[y, 'STRlemma'])*100\n",
    "                    perc_steam = 100-num_steam/len(df_umls_norm.at[y, 'STRstem'])*100\n",
    "                else:\n",
    "                    perc_lemma = 0\n",
    "                    perc_steam = 0\n",
    "                if perc_lemma == 100 and perc_steam >= 90:\n",
    "                    if not df_umls_norm.at[y, 'CUI'] in CUIS:\n",
    "                        CUIS.append(df_umls_norm.at[y, 'CUI'])\n",
    "                        for z in range(0, len(df_umls_rel)):\n",
    "                            if df_umls_rel.at[z,'CUI1'] == df_umls_norm.at[y, 'CUI']:\n",
    "                                if not df_umls_rel.at[z,'CUI2'] in CUIS:\n",
    "                                    CUIS.append(df_umls_rel.at[z,'CUI2'])\n",
    "                    print('achou')\n",
    "                    noventa = False\n",
    "                    terms += 1\n",
    "                    break\n",
    "                if perc_lemma >= 90 and perc_steam >= 90:\n",
    "                    if not df_umls_norm.at[y, 'CUI'] in CUIS:\n",
    "                        CUIS.append(df_umls_norm.at[y, 'CUI'])\n",
    "                        for z in range(0, len(df_umls_rel)):\n",
    "                            if df_umls_rel.at[z,'CUI1'] == df_umls_norm.at[y, 'CUI']:\n",
    "                                if not df_umls_rel.at[z,'CUI2'] in CUIS:\n",
    "                                    CUIS.append(df_umls_rel.at[z,'CUI2'])\n",
    "                    print('talvez achou')\n",
    "                    noventa = True\n",
    "        if noventa:\n",
    "            terms+=1\n",
    "        if len(CUIS) > 0:\n",
    "            print('existe na UMLS com as CUIs ', CUIS)\n",
    "            for c in CUIS:\n",
    "                perc = 0\n",
    "                perc_max = 0\n",
    "                print(c)\n",
    "                locCUI = df_umls_norm.loc[df_umls_norm['CUI'] == c]\n",
    "                print(locCUI)\n",
    "                if not locCUI['CUI'].empty:\n",
    "                    for xx in range(0,len(locCUI['CUI'])):\n",
    "                        perc = 0\n",
    "                        perc_max = 0\n",
    "                        df_umls_norm.at[locCUI.index[xx], 'STR']\n",
    "                        df_umls_norm.at[locCUI.index[xx], 'STRlemma']\n",
    "                        df_umls_norm.at[locCUI.index[xx], 'STRstem']\n",
    "                        \n",
    "                        for y in range(0, len(df_CIPE_norm)):\n",
    "                            num = levenshtein(df_umls_norm.at[locCUI.index[xx], 'STR'], df_CIPE_norm.at[y, 'Termo'])\n",
    "                            perc = 100 - num / len(df_CIPE_norm.at[y, 'Termo']) * 100\n",
    "                            if perc > perc_max:\n",
    "                                perc_max = perc\n",
    "                                candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                metodo = 1\n",
    "                                y_aux = y\n",
    "                            if perc_max == 100:\n",
    "                                metodo = 1\n",
    "                                break\n",
    "                        if metodo == 1 and perc_max >= 90:\n",
    "                            print('encontrou o termo ', df_umls_norm.at[locCUI.index[xx], 'STR'], ' na CIPE o termo ', df_CIPE.at[y_aux, 'Termo'], ' com o codigo CIPE ',df_CIPE.at[y_aux, 'Código'])\n",
    "                            df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                            df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                            df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                            df_termos_match.at[zz, 'ICNPmod'] = df_umls_norm.at[locCUI.index[xx], 'STR']\n",
    "                            df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                            df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                            df_termos_match.at[zz, 'Regra'] = 1\n",
    "                            df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                            zz += 1\n",
    "                        if not perc_max == 100:\n",
    "                            for y in range(0, len(df_CIPE_norm)):\n",
    "                                numlemma = levenshtein(df_umls_norm.at[locCUI.index[xx], 'STRlemma'], df_CIPE_lemma.at[y, 'Termo'])\n",
    "                                numstem = levenshtein(df_umls_norm.at[locCUI.index[xx], 'STRstem'], df_CIPE_stem.at[y, 'Termo'])\n",
    "                                perclemma = 100 - numlemma / len(df_CIPE_lemma.at[y, 'Termo']) * 100\n",
    "                                percstem = 100 - numstem / len(df_CIPE_lemma.at[y, 'Termo']) * 100\n",
    "                                if perclemma == 100 and percstem == 100:\n",
    "                                    print('encontrou o termo ', df_umls_norm.at[locCUI.index[xx], 'STR'], ' na CIPE o termo ', df_CIPE.at[y_aux, 'Termo'], ' com o codigo CIPE ',df_CIPE.at[y_aux, 'Código'])\n",
    "                                    df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                    df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y, 'Código']\n",
    "                                    df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y, 'Termo']\n",
    "                                    df_termos_match.at[zz, 'ICNPmod'] = df_umls_norm.at[locCUI.index[xx], 'STR']\n",
    "                                    df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y, 'Versão']\n",
    "                                    df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y, 'Eixo']\n",
    "                                    df_termos_match.at[zz, 'Regra'] = 2\n",
    "                                    df_termos_match.at[zz, 'perc'] = 100\n",
    "                                    zz += 1\n",
    "                                elif perclemma >= 90 and percstem >= 90:\n",
    "                                    print('encontrou o termo ', df_umls_norm.at[locCUI.index[xx], 'STR'], ' na CIPE o termo ', df_CIPE.at[y_aux, 'Termo'], ' com o codigo CIPE ',df_CIPE.at[y_aux, 'Código'])\n",
    "                                    df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                    df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y, 'Código']\n",
    "                                    df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y, 'Termo']\n",
    "                                    df_termos_match.at[zz, 'ICNPmod'] = df_umls_norm.at[locCUI.index[xx], 'STR']\n",
    "                                    df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y, 'Versão']\n",
    "                                    df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y, 'Eixo']\n",
    "                                    df_termos_match.at[zz, 'Regra'] = 2\n",
    "                                    df_termos_match.at[zz, 'perc'] = (perclemma,percstem)\n",
    "                                    zz += 1\n",
    "print('foram encontrados pelo metodo 1, ', terms,' termos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('CliniMap_CIPE_sin_UMLS2.xlsx')\n",
    "df_termos_match.to_excel(writer, 'Match')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333334\n",
      "abertura corporal  tem o par  abertura corporal  com a porcentagem  100.0\n",
      "abrangencia  tem o par  abortamento  com a porcentagem  0\n",
      "abrasao  tem o par  bandagem   com a porcentagem  0\n",
      "absenteismo  tem o par  aument  com a porcentagem  0\n",
      "absorver  tem o par  dispositivo absorver coletar  com a porcentagem  100.0\n",
      "abstinencia  tem o par  sintoma abstinencia (de afastamento de retirada algo)  com a porcentagem  100.0\n",
      "abuso alcool (ou alcoolismo)  tem o par  abuso alcool (ou alcoolismo)  com a porcentagem  100.0\n",
      "abuso tabaco (ou fumo)  tem o par  abuso tabaco (ou fumo)  com a porcentagem  100.0\n",
      "acao  tem o par  acao  com a porcentagem  100.0\n",
      "aceitacao  tem o par  aceitacao  com a porcentagem  100.0\n",
      "acessibilidade  tem o par  suscetibilidade  com a porcentagem  0\n",
      "acesso  tem o par  acesso  com a porcentagem  100.0\n",
      "acido  tem o par  aceit  com a porcentagem  0\n",
      "acidose  tem o par  acidose respiratoria  com a porcentagem  100.0\n",
      "adaptacao  tem o par  adaptacao  com a porcentagem  100.0\n",
      "adaptacao, prejudicada  tem o par  adaptacao, prejudicada  com a porcentagem  100.0\n",
      "adesao  tem o par  adesao  com a porcentagem  100.0\n",
      "administracao  tem o par  tecnica administracao medicamento  com a porcentagem  100.0\n",
      "administrar  tem o par  administrar  com a porcentagem  100.0\n",
      "adoecimento  tem o par  anoitec  com a porcentagem  0\n",
      "aeruginosa  tem o par  cerumen  com a porcentagem  0\n",
      "agencia  tem o par  dependencia  com a porcentagem  0\n",
      "agente  tem o par  agente hemostatico  com a porcentagem  100.0\n",
      "agudo  tem o par  agudo  com a porcentagem  100.0\n",
      "alimento  tem o par  alimento  com a porcentagem  100.0\n",
      "alto  tem o par  alto  com a porcentagem  100.0\n",
      "ambiente  tem o par  estresse por mudanca (ou transferencia) ambiente  com a porcentagem  100.0\n",
      "amostra (ou especimen)  tem o par  amostra (ou especimen)  com a porcentagem  100.0\n",
      "amputacao  tem o par  amputacao  com a porcentagem  100.0\n",
      "analgesico  tem o par  analgesico  com a porcentagem  100.0\n",
      "analisar  tem o par  analisar  com a porcentagem  100.0\n",
      "anestesico  tem o par  efeito anestesico  com a porcentagem  100.0\n",
      "angustia  tem o par  angustia  com a porcentagem  100.0\n",
      "anormal  tem o par  anormal  com a porcentagem  100.0\n",
      "ansiedade  tem o par  ansiedade  com a porcentagem  100.0\n",
      "antibiograma  tem o par  sensibil mam  com a porcentagem  0\n",
      "antibiotico  tem o par  antibiotico  com a porcentagem  100.0\n",
      "aplicar bandagem compressao  tem o par  aplicar bandagem compressao  com a porcentagem  100.0\n",
      "aplicar meias elasticas  tem o par  aplicar meias elasticas  com a porcentagem  100.0\n",
      "apoio emocional  tem o par  apoio emocional  com a porcentagem  100.0\n",
      "apoio espiritual  tem o par  apoio espiritual  com a porcentagem  100.0\n",
      "apoio familiar  tem o par  apoio familiar  com a porcentagem  100.0\n",
      "aprendizagem  tem o par  aprendizagem  com a porcentagem  100.0\n",
      "aprendizagem cognitiva  tem o par  aprendizagem cognitiva  com a porcentagem  100.0\n",
      "aprimoramento  tem o par  tocar   com a porcentagem  0\n",
      "aprofundamento  tem o par  autocuid  com a porcentagem  0\n",
      "argumento  tem o par  negacao   com a porcentagem  0\n",
      "arrancamento  tem o par  abracar   com a porcentagem  0\n",
      "arteria  tem o par  arteria  com a porcentagem  100.0\n",
      "arterial  tem o par  ulcera arterial  com a porcentagem  100.0\n",
      "arteriografia  tem o par  anterior  com a porcentagem  0\n",
      "articulacao  tem o par  articulacao  com a porcentagem  100.0\n",
      "artificial  tem o par  membro artificial  com a porcentagem  100.0\n",
      "atadura  tem o par  ciume   com a porcentagem  0\n",
      "aterosclerotica  tem o par  terap eletrolit  com a porcentagem  0\n",
      "atitude  tem o par  atitude  com a porcentagem  100.0\n",
      "atitude relacao dor  tem o par  atitude relacao dor  com a porcentagem  100.0\n",
      "ativacao  tem o par  amplitude movimento, ativa  com a porcentagem  100.0\n",
      "atividade  tem o par  aumentar tolerancia atividade  com a porcentagem  100.0\n",
      "ativo  tem o par  amplitude movimento, ativa  com a porcentagem  100.0\n",
      "atrasado (ou lento)  tem o par  atrasado (ou lento)  com a porcentagem  100.0\n",
      "atraso  tem o par  crescimento, atrasado (ou atraso crescimento)  com a porcentagem  100.0\n",
      "atrito  tem o par  nutricao   com a porcentagem  0\n",
      "['atrito', 'pressão']\n",
      "tempo sinonimos,  4.08058762550354\n",
      "---------dicionarios------- atrito pressao\n",
      "{'atrito': ['atricao', 'desacordo', 'desinteligencia', 'divergencia', 'friccao', 'rocadura', 'atrito'], 'pressão': ['coacao', 'violencia', 'aperto', 'compressao', 'pressão']}\n",
      "{'atrito': ['atricao ', 'acordar ', 'desinteligencia ', 'divergencia ', 'friccao ', 'rocadura ', 'tritar '], 'pressão': ['coacao ', 'violencia ', 'apertar ', 'compressao ', 'pressão ']}\n",
      "{'atrito': ['atrica', 'desacord', 'desinteligenc', 'divergenc', 'fricca', 'rocadur', 'atrit'], 'pressão': ['coaca', 'violenc', 'apert', 'compressa', 'pressã']}\n",
      "atrito pressao  numero de combinações:  35\n",
      "tempo posib,  0.0\n",
      "['atricao coacao', 'atricao violencia', 'atricao aperto', 'atricao compressao', 'atricao pressão', 'desacordo coacao', 'desacordo violencia', 'desacordo aperto', 'desacordo compressao', 'desacordo pressão', 'desinteligencia coacao', 'desinteligencia violencia', 'desinteligencia aperto', 'desinteligencia compressao', 'desinteligencia pressão', 'divergencia coacao', 'divergencia violencia', 'divergencia aperto', 'divergencia compressao', 'divergencia pressão', 'friccao coacao', 'friccao violencia', 'friccao aperto', 'friccao compressao', 'friccao pressão', 'rocadura coacao', 'rocadura violencia', 'rocadura aperto', 'rocadura compressao', 'rocadura pressão', 'atrito coacao', 'atrito violencia', 'atrito aperto', 'atrito compressao', 'atrito pressão']\n",
      "atrito pressao  tem o par  pressao  com a porcentagem  100.0\n",
      "aumentar  tem o par  aumentar  com a porcentagem  100.0\n",
      "aumentar tolerancia atividade  tem o par  aumentar tolerancia atividade  com a porcentagem  100.0\n",
      "ausente  tem o par  vomito, ausente  com a porcentagem  100.0\n",
      "autoconfianca  tem o par  estabelecer confianca  com a porcentagem  100.0\n",
      "autocontrole  tem o par  autocontrole  com a porcentagem  100.0\n",
      "autocuidado  tem o par  autocuidado  com a porcentagem  100.0\n",
      "autoestima  tem o par  autoestima  com a porcentagem  100.0\n",
      "autoimagem  tem o par  autoimagem  com a porcentagem  100.0\n",
      "autoimagem, negativa  tem o par  autoimagem, negativa  com a porcentagem  100.0\n",
      "autonomia  tem o par  autonomia  com a porcentagem  100.0\n",
      "autorizar  tem o par  autorizar  com a porcentagem  100.0\n",
      "avaliar cicatrizacao ferida  tem o par  avaliar cicatrizacao ferida  com a porcentagem  100.0\n",
      "baba  tem o par  mamar   com a porcentagem  0\n",
      "baixa autoestima  tem o par  baixa autoestima  com a porcentagem  100.0\n",
      "baixa autoestima, cronica  tem o par  baixa autoestima, cronica  com a porcentagem  100.0\n",
      "baixo  tem o par  baixo  com a porcentagem  100.0\n",
      "baixo comparecimento escolar  tem o par  baixo comparecimento escolar  com a porcentagem  100.0\n",
      "bandagem  tem o par  bandagem  com a porcentagem  100.0\n",
      "bandagem compressiva  tem o par  bandagem compressiva  com a porcentagem  100.0\n",
      "barreira adesao  tem o par  barreira adesao  com a porcentagem  100.0\n",
      "bastonete  tem o par  vagina   com a porcentagem  0\n",
      "betalactamicos  tem o par  problem lactaca  com a porcentagem  0\n",
      "biblioteca  tem o par  literacia   com a porcentagem  0\n",
      "biocompatibilidade  tem o par  baix comparec escol  com a porcentagem  0\n",
      "biofilme  tem o par  hipovolem  com a porcentagem  0\n",
      "biomateriais  tem o par  material leitura  com a porcentagem  100.0\n",
      "caibra  tem o par  caibra muscular  com a porcentagem  100.0\n",
      "calafrio  tem o par  calafrio  com a porcentagem  100.0\n",
      "calcanhar  tem o par  calcanhar  com a porcentagem  100.0\n",
      "calcio  tem o par  calcul  com a porcentagem  0\n",
      "calibre  tem o par  capacidade  com a porcentagem  0\n",
      "calor  tem o par  onda calor (ou fogacho)  com a porcentagem  100.0\n",
      "caminhada  tem o par  passar   com a porcentagem  0\n",
      "cancer  tem o par  fazer rastreamento (screening) cancer  com a porcentagem  100.0\n",
      "capilar  tem o par  capilar  com a porcentagem  100.0\n",
      "caracteristica  tem o par  caracteristica  com a porcentagem  100.0\n",
      "cardiopatia  tem o par  candidias  com a porcentagem  0\n",
      "casal  tem o par  casal  com a porcentagem  100.0\n",
      "['casuística', 'coleta']\n",
      "tempo sinonimos,  3.952025890350342\n",
      "---------dicionarios------- casuistica coleta\n",
      "{'casuística': ['casuística'], 'coleta': ['colheita', 'recolhimento', 'arrecadacao', 'coleta']}\n",
      "{'casuística': ['casuístico '], 'coleta': ['colheito ', 'colher ', 'arrecadacao ', 'coletar ']}\n",
      "{'casuística': ['casuíst'], 'coleta': ['colheit', 'recolh', 'arrecadaca', 'colet']}\n",
      "casuistica coleta  numero de combinações:  4\n",
      "tempo posib,  0.0\n",
      "['casuística colheita', 'casuística recolhimento', 'casuística arrecadacao', 'casuística coleta']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casuistica coleta  tem o par  coletar  com a porcentagem  100.0\n",
      "categorizar  tem o par  categorizar  com a porcentagem  100.0\n",
      "causa  tem o par  motivar   com a porcentagem  0\n",
      "cefalosporina  tem o par  regia corporal  com a porcentagem  0\n",
      "celula  tem o par  celula cervical  com a porcentagem  100.0\n",
      "choque  tem o par  choque  com a porcentagem  100.0\n",
      "cicatrizacao ferida  tem o par  cicatrizacao ferida  com a porcentagem  100.0\n",
      "ciencia  tem o par  conhecimento  com a porcentagem  0\n",
      "cientifico  tem o par  identific  com a porcentagem  0\n",
      "cirurgia  tem o par  cirurgia  com a porcentagem  100.0\n",
      "citotoxicas  tem o par  cataton  com a porcentagem  0\n",
      "claudicacao  tem o par  falar   com a porcentagem  0\n",
      "clindamicina  tem o par  confin domicili  com a porcentagem  0\n",
      "clinica  tem o par  clinica  com a porcentagem  100.0\n",
      "clorexidina  tem o par  colabor medic  com a porcentagem  0\n",
      "coagulase  tem o par  convulsa  com a porcentagem  0\n",
      "cobertura  tem o par  dispositivo cobertura  com a porcentagem  100.0\n",
      "['cobertura', 'ferida', '(curativo)']\n",
      "tempo sinonimos,  25.00299882888794\n",
      "---------dicionarios------- cobertura ferida (curativo)\n",
      "{'cobertura': ['cobertura'], 'ferida': ['chaga', 'ferimento', 'lesao', 'ferida'], '(curativo)': ['(curativo)']}\n",
      "{'cobertura': ['cobertura '], 'ferida': ['chagar ', 'ferir ', 'lesao ', 'ferir '], '(curativo)': ['(curativo) ']}\n",
      "{'cobertura': ['cobertur'], 'ferida': ['chag', 'feriment', 'lesa', 'fer'], '(curativo)': ['(curativo)']}\n",
      "cobertura ferida (curativo)  numero de combinações:  4\n",
      "tempo posib,  0.0\n",
      "['cobertura chaga (curativo)', 'cobertura ferimento (curativo)', 'cobertura lesao (curativo)', 'cobertura ferida (curativo)']\n",
      "cobertura ferida (curativo)  tem o par  ferida  com a porcentagem  100.0\n",
      "coco  tem o par  cabeca  com a porcentagem  0\n",
      "['cocos', 'grampositivos']\n",
      "tempo sinonimos,  3.9280760288238525\n",
      "---------dicionarios------- cocos grampositivos\n",
      "{'cocos': ['cabecas', 'emboladas', 'cocos'], 'grampositivos': ['grampositivos']}\n",
      "{'cocos': ['cabecas ', 'embolar ', 'coco '], 'grampositivos': ['grampositivos ']}\n",
      "{'cocos': ['cabec', 'embol', 'coc'], 'grampositivos': ['gramposit']}\n",
      "cocos grampositivos  numero de combinações:  3\n",
      "tempo posib,  0.0\n",
      "['cabecas grampositivos', 'emboladas grampositivos', 'cocos grampositivos']\n",
      "cocos grampositivos  tem o par  condicao humor, positivar   com a porcentagem  0\n",
      "['cojunto', 'atos']\n",
      "tempo sinonimos,  3.9080278873443604\n",
      "---------dicionarios------- cojunto atos\n",
      "{'cojunto': ['cojunto'], 'atos': ['inuteis', 'pobretoes', 'autos', 'feitas', 'declaracaos', 'declaracoes', 'dedos', 'feitos', 'insignificantes', 'ordinarios', 'profissoes', 'atos']}\n",
      "{'cojunto': ['cojunto '], 'atos': ['inuteis ', 'pobretoes ', 'auto ', 'feitar ', 'declaracaos ', 'declaracoes ', 'dedos ', 'fazer ', 'insignificante ', 'ordinarios ', 'profissoes ', 'ato ']}\n",
      "{'cojunto': ['cojunt'], 'atos': ['inut', 'pobreto', 'aut', 'feit', 'declaraca', 'declaraco', 'ded', 'feit', 'insignific', 'ordinari', 'profisso', 'atos']}\n",
      "cojunto atos  numero de combinações:  12\n",
      "tempo posib,  0.0\n",
      "['cojunto inuteis', 'cojunto pobretoes', 'cojunto autos', 'cojunto feitas', 'cojunto declaracaos', 'cojunto declaracoes', 'cojunto dedos', 'cojunto feitos', 'cojunto insignificantes', 'cojunto ordinarios', 'cojunto profissoes', 'cojunto atos']\n",
      "cojunto atos  tem o par  conjunto atos  com a porcentagem  0\n",
      "colaborar equipe interprofissional cuidados ferida  tem o par  colaborar equipe interprofissional cuidados ferida  com a porcentagem  100.0\n",
      "coleta dados admissao  tem o par  coleta dados admissao  com a porcentagem  100.0\n",
      "coletar  tem o par  coletar  com a porcentagem  100.0\n",
      "coletivo  tem o par  dispositivo absorver coletar  com a porcentagem  100.0\n",
      "colocar roupas  tem o par  colocar roupas  com a porcentagem  100.0\n",
      "colonia  tem o par  colic  com a porcentagem  0\n",
      "coloracao  tem o par  colabor  com a porcentagem  0\n",
      "combate  tem o par  contat  com a porcentagem  0\n",
      "combinacao  tem o par  negociar   com a porcentagem  0\n",
      "comorbidades  tem o par  fertilidade   com a porcentagem  0\n",
      "comparecimento escolar  tem o par  comparecimento escolar  com a porcentagem  100.0\n",
      "compatibilidade  tem o par  confort  com a porcentagem  0\n",
      "compativel  tem o par  confortavel   com a porcentagem  0\n",
      "competencia  tem o par  conhecimento  com a porcentagem  0\n",
      "competente  tem o par  analisar   com a porcentagem  0\n",
      "complexidade  tem o par  complexidade  com a porcentagem  100.0\n",
      "complicacao  tem o par  complicacao  com a porcentagem  100.0\n",
      "componente  tem o par  componente sistema urinario  com a porcentagem  100.0\n",
      "componente sistema nervoso  tem o par  componente sistema nervoso  com a porcentagem  100.0\n",
      "componente sistema sensorial  tem o par  componente sistema sensorial  com a porcentagem  100.0\n",
      "comportamento  tem o par  comportamento  com a porcentagem  100.0\n",
      "comportamento busca saude  tem o par  comportamento busca saude  com a porcentagem  100.0\n",
      "comportamento repouso  tem o par  comportamento repouso  com a porcentagem  100.0\n",
      "comportamento sexual, prejudicado  tem o par  comportamento sexual, prejudicado  com a porcentagem  100.0\n",
      "compreensao  tem o par  rapport (relacao compreensao mutua)  com a porcentagem  100.0\n",
      "compressas/gazes  tem o par  compressas/gazes  com a porcentagem  100.0\n",
      "comprimento  tem o par  comprimento  com a porcentagem  100.0\n",
      "compromisso  tem o par  ajustar   com a porcentagem  0\n",
      "comunicacao  tem o par  comunicacao  com a porcentagem  100.0\n",
      "comunidade  tem o par  comunidade  com a porcentagem  100.0\n",
      "concentracao  tem o par  concentracao  com a porcentagem  100.0\n",
      "concepcao  tem o par  periodo pre-natal (da concepcao nascimento)  com a porcentagem  100.0\n",
      "condicao  tem o par  condicao  com a porcentagem  100.0\n",
      "condicao social  tem o par  condicao social  com a porcentagem  100.0\n",
      "conduta clinica  tem o par  conduta clinica  com a porcentagem  100.0\n",
      "confeccao  tem o par  vestir   com a porcentagem  0\n",
      "confluencia  tem o par  succao   com a porcentagem  0\n",
      "conforto  tem o par  conforto  com a porcentagem  100.0\n",
      "conhecimento  tem o par  conhecimento  com a porcentagem  100.0\n",
      "conhecimento saude  tem o par  conhecimento saude  com a porcentagem  100.0\n",
      "conhecimento sobre cuidados ferida  tem o par  conhecimento sobre cuidados ferida  com a porcentagem  100.0\n",
      "conjunto  tem o par  conjunto processos corporais  com a porcentagem  100.0\n",
      "conjunto atos  tem o par  conjunto atos  com a porcentagem  100.0\n",
      "conjunto processos  tem o par  conjunto processos  com a porcentagem  100.0\n",
      "['conjunto', 'processos', 'corporal']\n",
      "tempo sinonimos,  6.138251543045044\n",
      "---------dicionarios------- conjunto processos corporal\n",
      "{'conjunto': ['bloco', 'simultaneo', 'adjacente', 'reunido', 'conjunto'], 'processos': ['processo', 'processos'], 'corporal': ['material', 'corporeo', 'corporal']}\n",
      "{'conjunto': ['blocar ', 'simultaneo ', 'adjacente ', 'reunir ', 'conjunto '], 'processos': ['processar ', 'processos '], 'corporal': ['material ', 'corporeo ', 'corporal ']}\n",
      "{'conjunto': ['bloc', 'simultan', 'adjacent', 'reun', 'conjunt'], 'processos': ['process', 'process'], 'corporal': ['material', 'corpor', 'corporal']}\n",
      "conjunto processos corporal  numero de combinações:  30\n",
      "tempo posib,  0.0\n",
      "['bloco processo material', 'bloco processo corporeo', 'bloco processo corporal', 'bloco processos material', 'bloco processos corporeo', 'bloco processos corporal', 'simultaneo processo material', 'simultaneo processo corporeo', 'simultaneo processo corporal', 'simultaneo processos material', 'simultaneo processos corporeo', 'simultaneo processos corporal', 'adjacente processo material', 'adjacente processo corporeo', 'adjacente processo corporal', 'adjacente processos material', 'adjacente processos corporeo', 'adjacente processos corporal', 'reunido processo material', 'reunido processo corporeo', 'reunido processo corporal', 'reunido processos material', 'reunido processos corporeo', 'reunido processos corporal', 'conjunto processo material', 'conjunto processo corporeo', 'conjunto processo corporal', 'conjunto processos material', 'conjunto processos corporeo', 'conjunto processos corporal']\n",
      "conjunto processos corporal  tem o par  conjunto processos  com a porcentagem  100.0\n",
      "consciente  tem o par  informar   com a porcentagem  0\n",
      "consequencia  tem o par  resultado  com a porcentagem  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consulta acompanhamento (ou consulta subsequente)  tem o par  consulta acompanhamento (ou consulta subsequente)  com a porcentagem  100.0\n",
      "['consulta', 'acompanhamento']\n",
      "tempo sinonimos,  4.084670305252075\n",
      "---------dicionarios------- consulta acompanhamento\n",
      "{'consulta': ['parecer', 'conselho', 'opiniao', 'consulta'], 'acompanhamento': ['comitiva', 'seguimento', 'sequito', 'acompanhamento']}\n",
      "{'consulta': ['parecer ', 'conselho ', 'opiniao ', 'consultar '], 'acompanhamento': ['comitiva ', 'seguir ', 'sequito ', 'acompanhar ']}\n",
      "{'consulta': ['parec', 'conselh', 'opinia', 'consult'], 'acompanhamento': ['comit', 'seguiment', 'sequit', 'acompanh']}\n",
      "consulta acompanhamento  numero de combinações:  16\n",
      "tempo posib,  0.0\n",
      "['parecer comitiva', 'parecer seguimento', 'parecer sequito', 'parecer acompanhamento', 'conselho comitiva', 'conselho seguimento', 'conselho sequito', 'conselho acompanhamento', 'opiniao comitiva', 'opiniao seguimento', 'opiniao sequito', 'opiniao acompanhamento', 'consulta comitiva', 'consulta seguimento', 'consulta sequito', 'consulta acompanhamento']\n",
      "consulta acompanhamento  tem o par  consulta acompanhamento (ou consulta subsequente)  com a porcentagem  100.0\n",
      "consultar  tem o par  consultar  com a porcentagem  100.0\n",
      "consumo  tem o par  congestao   com a porcentagem  0\n",
      "contaminacao  tem o par  contaminacao  com a porcentagem  100.0\n",
      "continuidade cuidado  tem o par  continuidade cuidado  com a porcentagem  100.0\n",
      "continuo  tem o par  continuo  com a porcentagem  100.0\n",
      "contorno  tem o par  perifer  com a porcentagem  0\n",
      "controlar  tem o par  controlar  com a porcentagem  100.0\n",
      "controle  tem o par  controle  com a porcentagem  100.0\n",
      "controle dor  tem o par  controle dor  com a porcentagem  100.0\n",
      "coracao  tem o par  coracao  com a porcentagem  100.0\n",
      "corpo  tem o par  corpo  com a porcentagem  100.0\n",
      "crise  tem o par  crise  com a porcentagem  100.0\n",
      "cronico  tem o par  cronico  com a porcentagem  100.0\n",
      "crosta  tem o par  crosta lactea (ou dermatite seborreica)  com a porcentagem  100.0\n",
      "cuidados ferida  tem o par  cuidados ferida  com a porcentagem  100.0\n",
      "cuidados ulcera  tem o par  cuidados ulcera  com a porcentagem  100.0\n",
      "cuidar (ou tomar conta)  tem o par  cuidar (ou tomar conta)  com a porcentagem  100.0\n",
      "culpa  tem o par  culpa  com a porcentagem  100.0\n",
      "cura  tem o par  cura  com a porcentagem  100.0\n",
      "dano  tem o par  dano ambiental  com a porcentagem  100.0\n",
      "deficiencia  tem o par  deficiencia imunologica  com a porcentagem  100.0\n",
      "deficiente  tem o par  deficiencia imunologica  com a porcentagem  100.0\n",
      "deficit  tem o par  tecnicas adaptacao deficit sensorial  com a porcentagem  100.0\n",
      "degradacao  tem o par  envelhecimento  com a porcentagem  0\n",
      "dependencia  tem o par  dependencia  com a porcentagem  100.0\n",
      "deposicao  tem o par  admissao   com a porcentagem  0\n",
      "depressao  tem o par  baixar   com a porcentagem  0\n",
      "derme  tem o par  deliri  com a porcentagem  0\n",
      "descamacao  tem o par  desmam  com a porcentagem  0\n",
      "descoloracao  tem o par  chorar   com a porcentagem  0\n",
      "descompressao  tem o par  terapia por compressao  com a porcentagem  100.0\n",
      "descrever  tem o par  descrever  com a porcentagem  100.0\n",
      "desenvolver  tem o par  desenvolver  com a porcentagem  100.0\n",
      "desfiguracao  tem o par  mutilacao   com a porcentagem  0\n",
      "desidratacao  tem o par  desidratacao  com a porcentagem  100.0\n",
      "desinfetar  tem o par  desinfetar  com a porcentagem  100.0\n",
      "deslizamento  tem o par  lidar   com a porcentagem  0\n",
      "['deslocamento', 'diário']\n",
      "tempo sinonimos,  4.0803351402282715\n",
      "---------dicionarios------- deslocamento diario\n",
      "{'deslocamento': ['deslocacao', 'deslocamento'], 'diário': ['quotidiano', 'cotidiano', 'diário']}\n",
      "{'deslocamento': ['deslocacao ', 'deslocamento '], 'diário': ['quotidiano ', 'cotidiano ', 'diário ']}\n",
      "{'deslocamento': ['deslocaca', 'desloc'], 'diário': ['quotidian', 'cotidian', 'diári']}\n",
      "deslocamento diario  numero de combinações:  6\n",
      "tempo posib,  0.0\n",
      "['deslocacao quotidiano', 'deslocacao cotidiano', 'deslocacao diário', 'deslocamento quotidiano', 'deslocamento cotidiano', 'deslocamento diário']\n",
      "deslocamento diario  tem o par  gestao alimentos liquido   com a porcentagem  0\n",
      "desnutricao  tem o par  desnutricao  com a porcentagem  100.0\n",
      "desordem  tem o par  desol  com a porcentagem  0\n",
      "destruicao  tem o par  desnutrica  com a porcentagem  0\n",
      "detalhado  tem o par  planejar   com a porcentagem  0\n",
      "detentor  tem o par  disposit apoi  com a porcentagem  0\n",
      "determinar intervencao  tem o par  determinar intervencao  com a porcentagem  100.0\n",
      "detrimento  tem o par  estradar   com a porcentagem  0\n",
      "dia  tem o par  dia  com a porcentagem  100.0\n",
      "diabetes  tem o par  diabetes  com a porcentagem  100.0\n",
      "['diagnóstico', 'resultado']\n",
      "tempo sinonimos,  4.095255136489868\n",
      "---------dicionarios------- diagnostico resultado\n",
      "{'diagnóstico': ['analise', 'pesquisa', 'reconhecimento', 'determinacao', 'identificacao', 'descricao', 'diagnóstico'], 'resultado': ['produto', 'efeito', 'consequencia', 'solucao', 'resolucao', 'lucro', 'resultado']}\n",
      "{'diagnóstico': ['analisar ', 'pesquisar ', 'conhecer ', 'determinacao ', 'identificacao ', 'descricao ', 'diagnóstico '], 'resultado': ['produto ', 'efeito ', 'consequencia ', 'solucao ', 'resolucao ', 'lucro ', 'resultar ']}\n",
      "{'diagnóstico': ['analis', 'pesquis', 'reconhec', 'determinaca', 'identificaca', 'descrica', 'diagnóst'], 'resultado': ['produt', 'efeit', 'consequenc', 'soluca', 'resoluca', 'lucr', 'result']}\n",
      "diagnostico resultado  numero de combinações:  49\n",
      "tempo posib,  0.0\n",
      "['analise produto', 'analise efeito', 'analise consequencia', 'analise solucao', 'analise resolucao', 'analise lucro', 'analise resultado', 'pesquisa produto', 'pesquisa efeito', 'pesquisa consequencia', 'pesquisa solucao', 'pesquisa resolucao', 'pesquisa lucro', 'pesquisa resultado', 'reconhecimento produto', 'reconhecimento efeito', 'reconhecimento consequencia', 'reconhecimento solucao', 'reconhecimento resolucao', 'reconhecimento lucro', 'reconhecimento resultado', 'determinacao produto', 'determinacao efeito', 'determinacao consequencia', 'determinacao solucao', 'determinacao resolucao', 'determinacao lucro', 'determinacao resultado', 'identificacao produto', 'identificacao efeito', 'identificacao consequencia', 'identificacao solucao', 'identificacao resolucao', 'identificacao lucro', 'identificacao resultado', 'descricao produto', 'descricao efeito', 'descricao consequencia', 'descricao solucao', 'descricao resolucao', 'descricao lucro', 'descricao resultado', 'diagnóstico produto', 'diagnóstico efeito', 'diagnóstico consequencia', 'diagnóstico solucao', 'diagnóstico resolucao', 'diagnóstico lucro', 'diagnóstico resultado']\n",
      "diagnostico resultado  tem o par  resultado  com a porcentagem  100.0\n",
      "diapasao  tem o par  agitacao   com a porcentagem  0\n",
      "dieta  tem o par  tolerancia dieta  com a porcentagem  100.0\n",
      "dificuldade  tem o par  risco dificuldade enfrentamento  com a porcentagem  100.0\n",
      "dificuldade enfrentamento  tem o par  dificuldade enfrentamento  com a porcentagem  100.0\n",
      "difusao  tem o par  discriminacao   com a porcentagem  0\n",
      "dilatacao  tem o par  dor dilatacao cervical  com a porcentagem  100.0\n",
      "dimensao  tem o par  dimensao fisica  com a porcentagem  100.0\n",
      "diminuido  tem o par  risco suicidio, diminuido  com a porcentagem  100.0\n",
      "diminuir  tem o par  diminuir  com a porcentagem  100.0\n",
      "discodifusao  tem o par  risc confusa  com a porcentagem  0\n",
      "disposicao  tem o par  disposicao (ou prontidao) manejo (controle), por si proprio  com a porcentagem  100.0\n",
      "dispositivo  tem o par  dispositivo  com a porcentagem  100.0\n",
      "dispositivo absorver coletar  tem o par  dispositivo absorver coletar  com a porcentagem  100.0\n",
      "disseminacao  tem o par  ilusao   com a porcentagem  0\n",
      "distribuir  tem o par  distribuir  com a porcentagem  100.0\n",
      "disturbio  tem o par  ajustar   com a porcentagem  0\n",
      "divergencia  tem o par  atender   com a porcentagem  0\n",
      "diversidade  tem o par  diversidade cultural  com a porcentagem  100.0\n",
      "diversidade cultural  tem o par  diversidade cultural  com a porcentagem  100.0\n",
      "documentar  tem o par  documentar  com a porcentagem  100.0\n",
      "doenca  tem o par  negacao sobre severidade doenca  com a porcentagem  100.0\n",
      "doenca  tem o par  negacao sobre severidade doenca  com a porcentagem  100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doppler  tem o par  complic  com a porcentagem  0\n",
      "dor  tem o par  dor  com a porcentagem  100.0\n",
      "dor por ferida  tem o par  dor por ferida  com a porcentagem  100.0\n",
      "dormencia  tem o par  envelhecimento  com a porcentagem  0\n",
      "drenagem  tem o par  tubo drenagem  com a porcentagem  100.0\n",
      "droga  tem o par  droga  com a porcentagem  100.0\n",
      "duracao  tem o par  duracao  com a porcentagem  100.0\n",
      "eczema  tem o par  eczema  com a porcentagem  100.0\n",
      "edema  tem o par  edema  com a porcentagem  100.0\n",
      "efeito  tem o par  papel efeito colateral (ou secundario)  com a porcentagem  100.0\n",
      "efeito analgesico  tem o par  efeito analgesico  com a porcentagem  100.0\n",
      "efeito antibiotico  tem o par  efeito antibiotico  com a porcentagem  100.0\n",
      "efeito colateral  tem o par  efeito colateral  com a porcentagem  100.0\n",
      "eficiencia  tem o par  deficiencia imunologica  com a porcentagem  90.9090909090909\n",
      "elastico  tem o par  meia elastica  com a porcentagem  100.0\n",
      "elevar  tem o par  elevar  com a porcentagem  100.0\n",
      "elogiar  tem o par  elogiar  com a porcentagem  100.0\n",
      "emocao  tem o par  emocao  com a porcentagem  100.0\n",
      "emocao, negativa  tem o par  emocao, negativa  com a porcentagem  100.0\n",
      "emoliente  tem o par  polit  com a porcentagem  0\n",
      "empurrar  tem o par  pulsar   com a porcentagem  0\n",
      "endarterectomia  tem o par  efeit expector  com a porcentagem  0\n",
      "endotelio  tem o par  tend oxigeni  com a porcentagem  0\n",
      "['endotélio', 'vascular']\n",
      "tempo sinonimos,  3.9009106159210205\n",
      "---------dicionarios------- endotelio vascular\n",
      "{'endotélio': ['endotélio'], 'vascular': ['vascular']}\n",
      "{'endotélio': ['endotélio '], 'vascular': ['vascular ']}\n",
      "{'endotélio': ['endotéli'], 'vascular': ['vascul']}\n",
      "endotelio vascular  numero de combinações:  1\n",
      "tempo posib,  0.0\n",
      "['endotélio vascular']\n",
      "endotelio vascular  tem o par  process vascul  com a porcentagem  0\n",
      "enfermagem  tem o par  servico enfermagem  com a porcentagem  100.0\n",
      "enfermeira(o)  tem o par  enfermeira(o)  com a porcentagem  100.0\n",
      "enfraquecimento  tem o par  frustracao   com a porcentagem  0\n",
      "enfrentamento  tem o par  enfrentamento  com a porcentagem  100.0\n",
      "enfrentamento dor  tem o par  enfrentamento dor  com a porcentagem  100.0\n",
      "enjoo  tem o par  nausea  com a porcentagem  0\n",
      "enredo  tem o par  confusao  com a porcentagem  0\n",
      "enterobacter  tem o par  lent contat  com a porcentagem  0\n",
      "entrevistar  tem o par  entrevistar  com a porcentagem  100.0\n",
      "envelhecimento  tem o par  envelhecimento  com a porcentagem  100.0\n",
      "enxerto  tem o par  preocupacao   com a porcentagem  0\n",
      "enxofre  tem o par  cultur  com a porcentagem  0\n",
      "enxugo  tem o par  enxaguar   com a porcentagem  0\n",
      "enzima  tem o par  disfas  com a porcentagem  0\n",
      "epiderme  tem o par  ferida epidermica  com a porcentagem  100.0\n",
      "episodio  tem o par  evento episodio  com a porcentagem  100.0\n",
      "equipe interprofissional  tem o par  equipe interprofissional  com a porcentagem  100.0\n",
      "['equipe', 'multidisciplinar']\n",
      "tempo sinonimos,  4.357872009277344\n",
      "---------dicionarios------- equipe multidisciplinar\n",
      "{'equipe': ['time', 'quadro', 'equipo', 'equipe'], 'multidisciplinar': ['pluridisciplinar', 'multidisciplinar']}\n",
      "{'equipe': ['time ', 'quadrar ', 'equipar ', 'equipe '], 'multidisciplinar': ['pluridisciplinar ', 'multidisciplinar ']}\n",
      "{'equipe': ['tim', 'quadr', 'equip', 'equip'], 'multidisciplinar': ['pluridisciplin', 'multidisciplin']}\n",
      "equipe multidisciplinar  numero de combinações:  8\n",
      "tempo posib,  0.0009992122650146484\n",
      "['time pluridisciplinar', 'time multidisciplinar', 'quadro pluridisciplinar', 'quadro multidisciplinar', 'equipo pluridisciplinar', 'equipo multidisciplinar', 'equipe pluridisciplinar', 'equipe multidisciplinar']\n",
      "equipe multidisciplinar  tem o par  equipe profissional   com a porcentagem  0\n",
      "eritema  tem o par  eritema  com a porcentagem  100.0\n",
      "eritrocito  tem o par  emac  com a porcentagem  0\n",
      "escala  tem o par  radiacao   com a porcentagem  0\n",
      "escherichia  tem o par  desnutrica  com a porcentagem  0\n",
      "escolher  tem o par  usar   com a porcentagem  0\n",
      "escritorio  tem o par  dependencia  com a porcentagem  0\n",
      "esfacelo  tem o par  pesadel  com a porcentagem  0\n",
      "esfera  tem o par  colar   com a porcentagem  0\n",
      "esfoliacao  tem o par  escori  com a porcentagem  0\n",
      "esfregaco  tem o par  esfreg  com a porcentagem  0\n",
      "esgotamento  tem o par  esgotamento (burnout)  com a porcentagem  100.0\n",
      "especialidade  tem o par  especialista dor  com a porcentagem  100.0\n",
      "esperanca  tem o par  esperanca  com a porcentagem  100.0\n",
      "estabelecer  tem o par  estabelecer  com a porcentagem  100.0\n",
      "estabelecer perfil  tem o par  estabelecer perfil  com a porcentagem  100.0\n",
      "estadiamento  tem o par  estadi  com a porcentagem  0\n",
      "estafilococo  tem o par  estabelec confianc  com a porcentagem  0\n",
      "estagnacao  tem o par  marasmo  com a porcentagem  0\n",
      "estigma  tem o par  estigma  com a porcentagem  100.0\n",
      "estilo  tem o par  prevenir estilo vida isolamento social  com a porcentagem  100.0\n",
      "estimulo  tem o par  estimular reflexao sobre experiencia vivida (debriefing)  com a porcentagem  100.0\n",
      "estomaterapeuta  tem o par  enfermeira(o) estomaterapeuta  com a porcentagem  100.0\n",
      "estomaterapia  tem o par  aromaterap  com a porcentagem  0\n",
      "estreptococo  tem o par  enfrent dor  com a porcentagem  0\n",
      "estresse  tem o par  estresse  com a porcentagem  100.0\n",
      "estressores  tem o par  estress  com a porcentagem  0\n",
      "estrutura psicossocial  tem o par  estrutura psicossocial  com a porcentagem  100.0\n",
      "eutroficos  tem o par  escrot  com a porcentagem  0\n",
      "evento episodio  tem o par  evento episodio  com a porcentagem  100.0\n",
      "exacerbacao  tem o par  coletar   com a porcentagem  0\n",
      "exame fisico  tem o par  exame fisico  com a porcentagem  100.0\n",
      "examinar  tem o par  examinar  com a porcentagem  100.0\n",
      "exantema  tem o par  exantema  com a porcentagem  100.0\n",
      "execucao papel  tem o par  execucao papel  com a porcentagem  100.0\n",
      "executar  tem o par  executar  com a porcentagem  100.0\n",
      "exercicio fisico  tem o par  exercicio fisico  com a porcentagem  100.0\n",
      "existencia  tem o par  presenca  com a porcentagem  0\n",
      "expectativa  tem o par  expectativa  com a porcentagem  100.0\n",
      "experiencia  tem o par  estimular reflexao sobre experiencia vivida (debriefing)  com a porcentagem  100.0\n",
      "extravasamento  tem o par  expectoracao   com a porcentagem  0\n",
      "face  tem o par  face  com a porcentagem  100.0\n",
      "falcemica  tem o par  hipocalcem  com a porcentagem  0\n",
      "falciforme  tem o par  sal cirurg  com a porcentagem  0\n",
      "falciformes  tem o par  sal cirurg  com a porcentagem  0\n",
      "falcizacao  tem o par  alucin  com a porcentagem  0\n",
      "familia  tem o par  familia  com a porcentagem  100.0\n",
      "fase  tem o par  perineo   com a porcentagem  0\n",
      "fator  tem o par  alimento  com a porcentagem  0\n",
      "fatores  tem o par  condicao  com a porcentagem  0\n",
      "fazer progredir (ou promover)  tem o par  fazer progredir (ou promover)  com a porcentagem  100.0\n",
      "fenomeno  tem o par  fenomeno  com a porcentagem  100.0\n",
      "ferida  tem o par  ferida  com a porcentagem  100.0\n",
      "ferida aberta  tem o par  ferida aberta  com a porcentagem  100.0\n",
      "fezes  tem o par  fezes  com a porcentagem  100.0\n",
      "fisicoquimico  tem o par  risc qued  com a porcentagem  0\n",
      "fisiologica  tem o par  condicao fisiologica  com a porcentagem  100.0\n",
      "fistula  tem o par  ulcera  com a porcentagem  0\n",
      "fluxo  tem o par  taxa fluxo sanguineo  com a porcentagem  100.0\n",
      "foice  tem o par  colic  com a porcentagem  0\n",
      "foliculo  tem o par  articul  com a porcentagem  0\n",
      "forma  tem o par  talar   com a porcentagem  0\n",
      "formato  tem o par  feicao   com a porcentagem  0\n",
      "formigamento  tem o par  demencia   com a porcentagem  0\n",
      "formulacao  tem o par  sedacao   com a porcentagem  0\n",
      "fragmentadoras  tem o par  amament  com a porcentagem  0\n",
      "fragmento  tem o par  rigar   com a porcentagem  0\n",
      "fraqueza  tem o par  fraqueza  com a porcentagem  100.0\n",
      "frequencia  tem o par  frequencia  com a porcentagem  100.0\n",
      "frequencia pulso  tem o par  frequencia pulso  com a porcentagem  100.0\n",
      "friccao  tem o par  esfregar   com a porcentagem  0\n",
      "funcao cardiaca, prejudicada  tem o par  funcao cardiaca, prejudicada  com a porcentagem  100.0\n",
      "generico  tem o par  medicamento generico  com a porcentagem  100.0\n",
      "genetica  tem o par  aconselhamento genetico  com a porcentagem  100.0\n",
      "genetico  tem o par  aconselhamento genetico  com a porcentagem  100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gentamicina  tem o par  gerenc micca  com a porcentagem  0\n",
      "glandula  tem o par  glandula  com a porcentagem  100.0\n",
      "glicemia  tem o par  gerenciar hipoglicemia  com a porcentagem  100.0\n",
      "globina  tem o par  alodin  com a porcentagem  0\n",
      "glossario  tem o par  ver cavitario   com a porcentagem  0\n",
      "grau  tem o par  grau  com a porcentagem  100.0\n",
      "gravidade  tem o par  gravidade  com a porcentagem  100.0\n",
      "grupo  tem o par  grupo  com a porcentagem  100.0\n",
      "hemacia  tem o par  ver topico   com a porcentagem  0\n",
      "hematologia  tem o par  hematom  com a porcentagem  0\n",
      "hemoderivados  tem o par  hemoterap  com a porcentagem  0\n",
      "hemorragia  tem o par  hemorragia  com a porcentagem  100.0\n",
      "hidratacao  tem o par  terapia liquidos (ou hidratacao)  com a porcentagem  90.9090909090909\n",
      "hidroterapia  tem o par  hidroterapia  com a porcentagem  100.0\n",
      "hiperglicemia  tem o par  hiperglicemia  com a porcentagem  100.0\n",
      "hiperpigmentacao  tem o par  hipervitaminos  com a porcentagem  0\n",
      "hipersensibilidade  tem o par  sensibilidade mamas  com a porcentagem  100.0\n",
      "hipertensao  tem o par  hipertensao  com a porcentagem  100.0\n",
      "hipoglicemia  tem o par  hipoglicemia  com a porcentagem  100.0\n",
      "hipotricose  tem o par  hipovitaminos  com a porcentagem  0\n",
      "hipoxia  tem o par  hipoxia  com a porcentagem  100.0\n",
      "homogeneidade  tem o par  regular   com a porcentagem  0\n",
      "hospital  tem o par  hospital  com a porcentagem  100.0\n",
      "humor  tem o par  humor  com a porcentagem  100.0\n",
      "ideal  tem o par  prazer   com a porcentagem  0\n",
      "identificar  tem o par  identificar  com a porcentagem  100.0\n",
      "idoso  tem o par  idoso  com a porcentagem  100.0\n",
      "imagem corporal  tem o par  imagem corporal  com a porcentagem  100.0\n",
      "impacto  tem o par  (*)[1] impactacao fecal  com a porcentagem  100.0\n",
      "impotencia  tem o par  impotencia  com a porcentagem  100.0\n",
      "inalacao  tem o par  tecnica inalacao  com a porcentagem  100.0\n",
      "incapacidade (ou limitacao)  tem o par  incapacidade (ou limitacao)  com a porcentagem  100.0\n",
      "['incidência', 'doença']\n",
      "tempo sinonimos,  23.032463550567627\n",
      "---------dicionarios------- incidencia doenca\n",
      "{'incidência': ['incidência'], 'doença': ['achaque', 'afeccao', 'enfermidade', 'mal', 'molestia', 'morbo', 'padecimento', 'doença']}\n",
      "{'incidência': ['incidência '], 'doença': ['achacar ', 'afeccao ', 'enfermos ', 'mal ', 'molestia ', 'morbo ', 'padecer ', 'doença ']}\n",
      "{'incidência': ['incident'], 'doença': ['achaqu', 'afecca', 'enferm', 'mal', 'molest', 'morb', 'padec', 'doenc']}\n",
      "incidencia doenca  numero de combinações:  8\n",
      "tempo posib,  0.0\n",
      "['incidência achaque', 'incidência afeccao', 'incidência enfermidade', 'incidência mal', 'incidência molestia', 'incidência morbo', 'incidência padecimento', 'incidência doença']\n",
      "incidencia doenca  tem o par  incident doenc  com a porcentagem  0\n",
      "incidencia doencas  tem o par  incidencia doencas  com a porcentagem  100.0\n",
      "incisao  tem o par  fazer incisao  com a porcentagem  100.0\n",
      "incompetencia  tem o par  capaz   com a porcentagem  0\n",
      "incontinencia  tem o par  tecnica treinamento incontinencia  com a porcentagem  100.0\n",
      "incubacao  tem o par  chorar   com a porcentagem  0\n",
      "individuo  tem o par  individuo  com a porcentagem  100.0\n",
      "inducao  tem o par  duzir   com a porcentagem  0\n",
      "infeccao  tem o par  infeccao  com a porcentagem  100.0\n",
      "['infecção', 'ausente']\n",
      "tempo sinonimos,  4.078914642333984\n",
      "---------dicionarios------- infeccao ausente\n",
      "{'infecção': ['contaminacao', 'contagio', 'corrupcao', 'inflamacao', 'infecção'], 'ausente': ['afastado', 'retirado', 'distraido', 'distante', 'ausente']}\n",
      "{'infecção': ['contaminacao ', 'contagiar ', 'corrupcao ', 'inflamacao ', 'infecção '], 'ausente': ['afastar ', 'tirar ', 'distraido ', 'distar ', 'ausentar ']}\n",
      "{'infecção': ['contaminaca', 'contagi', 'corrupca', 'inflamaca', 'infecçã'], 'ausente': ['afast', 'retir', 'distra', 'distant', 'ausent']}\n",
      "infeccao ausente  numero de combinações:  25\n",
      "tempo posib,  0.0\n",
      "['contaminacao afastado', 'contaminacao retirado', 'contaminacao distraido', 'contaminacao distante', 'contaminacao ausente', 'contagio afastado', 'contagio retirado', 'contagio distraido', 'contagio distante', 'contagio ausente', 'corrupcao afastado', 'corrupcao retirado', 'corrupcao distraido', 'corrupcao distante', 'corrupcao ausente', 'inflamacao afastado', 'inflamacao retirado', 'inflamacao distraido', 'inflamacao distante', 'inflamacao ausente', 'infecção afastado', 'infecção retirado', 'infecção distraido', 'infecção distante', 'infecção ausente']\n",
      "infeccao ausente  tem o par  infeccao  com a porcentagem  100.0\n",
      "inflamacao  tem o par  inflamacao  com a porcentagem  100.0\n",
      "informar  tem o par  informar  com a porcentagem  100.0\n",
      "infusao  tem o par  terapia infusao  com a porcentagem  100.0\n",
      "ingestao  tem o par  padrao ingestao liquidos  com a porcentagem  100.0\n",
      "['ingestão', 'alimentos', '10008101']\n",
      "tempo sinonimos,  6.001088619232178\n",
      "---------dicionarios------- ingestao alimentos 10008101\n",
      "{'ingestão': ['degluticao', 'engolicao', 'ingestão'], 'alimentos': ['iguarias', 'manjares', 'alimentacoes', 'comidas', 'manas', 'sustentos', 'alimentos'], '10008101': ['10008101']}\n",
      "{'ingestão': ['degluticao ', 'engolicao ', 'gestão '], 'alimentos': ['iguaria ', 'manjar ', 'alimentacoes ', 'comer ', 'manar ', 'sustentos ', 'alimentos '], '10008101': ['10008101 ']}\n",
      "{'ingestão': ['deglutica', 'engolica', 'ingestã'], 'alimentos': ['igu', 'manj', 'alimentaco', 'com', 'man', 'sustent', 'aliment'], '10008101': ['10008101']}\n",
      "ingestao alimentos 10008101  numero de combinações:  21\n",
      "tempo posib,  0.0\n",
      "['degluticao iguarias 10008101', 'degluticao manjares 10008101', 'degluticao alimentacoes 10008101', 'degluticao comidas 10008101', 'degluticao manas 10008101', 'degluticao sustentos 10008101', 'degluticao alimentos 10008101', 'engolicao iguarias 10008101', 'engolicao manjares 10008101', 'engolicao alimentacoes 10008101', 'engolicao comidas 10008101', 'engolicao manas 10008101', 'engolicao sustentos 10008101', 'engolicao alimentos 10008101', 'ingestão iguarias 10008101', 'ingestão manjares 10008101', 'ingestão alimentacoes 10008101', 'ingestão comidas 10008101', 'ingestão manas 10008101', 'ingestão sustentos 10008101', 'ingestão alimentos 10008101']\n",
      "ingestao alimentos 10008101  tem o par  ingestao alimentos  com a porcentagem  100.0\n",
      "inibicao  tem o par  vergonha  com a porcentagem  0\n",
      "inibitorio  tem o par  iniciativo   com a porcentagem  0\n",
      "inicativa  tem o par  iniciar analgesia controlada por enfermeira(o)  com a porcentagem  100.0\n",
      "inquerir  tem o par  inquiet  com a porcentagem  0\n",
      "insanidade  tem o par  demencia  com a porcentagem  0\n",
      "insensibilidade  tem o par  sensibilidade mamas  com a porcentagem  100.0\n",
      "instabilidade  tem o par  inseguranca  com a porcentagem  0\n",
      "instituicao atencao saude  tem o par  instituicao atencao saude  com a porcentagem  100.0\n",
      "instrumento avaliacao  tem o par  instrumento avaliacao  com a porcentagem  100.0\n",
      "insuficiencia  tem o par  risco ingestao alimentos, insuficiente (ou deficitaria)  com a porcentagem  100.0\n",
      "insulina  tem o par  insulina  com a porcentagem  100.0\n",
      "integridade tissular  tem o par  integridade tissular  com a porcentagem  100.0\n",
      "integridade tissular, prejudicada  tem o par  integridade tissular, prejudicada  com a porcentagem  100.0\n",
      "interacao  tem o par  tecnica interacao  com a porcentagem  100.0\n",
      "intercorrencias  tem o par  alter  com a porcentagem  0\n",
      "internacional  tem o par  idad gestacional  com a porcentagem  0\n",
      "interromper  tem o par  interromper  com a porcentagem  100.0\n",
      "intersticio  tem o par  valor   com a porcentagem  0\n",
      "intervencao  tem o par  determinar intervencao  com a porcentagem  100.0\n",
      "investigar  tem o par  vigiar (ou investigar)  com a porcentagem  90.9090909090909\n",
      "iruxol  tem o par  areol  com a porcentagem  0\n",
      "isolamento  tem o par  tecnica isolamento  com a porcentagem  100.0\n",
      "isulina  tem o par  insulin  com a porcentagem  0\n",
      "jato  tem o par  remover (algo) jato agua outro liquido  com a porcentagem  100.0\n",
      "julgamento, positivo negativo  tem o par  julgamento, positivo negativo  com a porcentagem  100.0\n",
      "juncao  tem o par  succa  com a porcentagem  0\n",
      "laboratorial  tem o par  resultado laboratorial  com a porcentagem  100.0\n",
      "laceracao  tem o par  laceracao  com a porcentagem  100.0\n",
      "lesado  tem o par  prejudicado  com a porcentagem  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lesao  tem o par  lesao  com a porcentagem  100.0\n",
      "lesao  tem o par  lesao  com a porcentagem  100.0\n",
      "letalidade  tem o par  fertilidade  com a porcentagem  0\n",
      "leucocito  tem o par  insignific  com a porcentagem  0\n",
      "leucocitose  tem o par  lencol movel  com a porcentagem  0\n",
      "lidar  tem o par  lidar  com a porcentagem  100.0\n",
      "ligacao afetiva  tem o par  ligacao afetiva  com a porcentagem  100.0\n",
      "limiar  tem o par  inicio  com a porcentagem  0\n",
      "lise  tem o par  ris  com a porcentagem  0\n",
      "literatura  tem o par  biblioterapia   com a porcentagem  0\n",
      "localizacao  tem o par  localizacao ferida  com a porcentagem  100.0\n",
      "localizacao ferida  tem o par  localizacao ferida  com a porcentagem  100.0\n",
      "maceracao  tem o par  maceracao  com a porcentagem  100.0\n",
      "macro  tem o par  grande  com a porcentagem  0\n",
      "macula  tem o par  inflam  com a porcentagem  0\n",
      "mais  tem o par  molh  com a porcentagem  0\n",
      "manejar  tem o par  capacidade manejar (controlar)o regime, positiva  com a porcentagem  100.0\n",
      "manejo  tem o par  terapia manejo (controle) raiva  com a porcentagem  100.0\n",
      "manha  tem o par  manha  com a porcentagem  100.0\n",
      "manter saude  tem o par  manter saude  com a porcentagem  100.0\n",
      "manutencao  tem o par  capacidade executar manutencao saude  com a porcentagem  100.0\n",
      "margem  tem o par  banhar   com a porcentagem  0\n",
      "mascaramento  tem o par  massag  com a porcentagem  0\n",
      "massa  tem o par  tamanho  com a porcentagem  0\n",
      "material  tem o par  material  com a porcentagem  100.0\n",
      "matriz  tem o par  material  com a porcentagem  0\n",
      "maturacao  tem o par  maturidade  com a porcentagem  0\n",
      "media  tem o par  escola ensino medio  com a porcentagem  100.0\n",
      "medicacao  tem o par  medicacao  com a porcentagem  100.0\n",
      "medicamento  tem o par  tecnica administracao medicamento  com a porcentagem  100.0\n",
      "medico  tem o par  medico  com a porcentagem  100.0\n",
      "medir  tem o par  medir (ou verificar)  com a porcentagem  100.0\n",
      "medir (ou verificar)  tem o par  medir (ou verificar)  com a porcentagem  100.0\n",
      "melhorado  tem o par  melhorado  com a porcentagem  100.0\n",
      "mellitus  tem o par  menopaus  com a porcentagem  0\n",
      "mes  tem o par  mes  com a porcentagem  100.0\n",
      "metodo  tem o par  processo  com a porcentagem  0\n",
      "micose  tem o par  micca  com a porcentagem  0\n",
      "micro  tem o par  computador  com a porcentagem  0\n",
      "microangiopatica  tem o par  administr antibiot  com a porcentagem  0\n",
      "microbio  tem o par  microrganismo  com a porcentagem  0\n",
      "microbiologico  tem o par  unidad radiolog  com a porcentagem  0\n",
      "microcirculacao  tem o par  almof circul  com a porcentagem  0\n",
      "microrganismo  tem o par  microrganismo  com a porcentagem  100.0\n",
      "migracao  tem o par  taxa migracao  com a porcentagem  100.0\n",
      "mobilidade, prejudicada  tem o par  mobilidade, prejudicada  com a porcentagem  100.0\n",
      "modelagem  tem o par  mutilacao   com a porcentagem  0\n",
      "moderacao  tem o par  comprimento  com a porcentagem  0\n",
      "moderado  tem o par  moderado  com a porcentagem  100.0\n",
      "monitorar  tem o par  monitorar  com a porcentagem  100.0\n",
      "monitorar cicatrizacao ferida  tem o par  monitorar cicatrizacao ferida  com a porcentagem  100.0\n",
      "mortalidade  tem o par  taxa mortalidade perinatal  com a porcentagem  100.0\n",
      "morte  tem o par  morte  com a porcentagem  100.0\n",
      "motilidade  tem o par  motilidade intestinal  com a porcentagem  100.0\n",
      "mudanca  tem o par  estresse por mudanca (ou transferencia) ambiente  com a porcentagem  100.0\n",
      "multifatoriedade  tem o par  hereditariedad  com a porcentagem  0\n",
      "multiplicacao  tem o par  aumentar   com a porcentagem  0\n",
      "multiplicidade  tem o par  universidade  com a porcentagem  0\n",
      "necessidade  tem o par  necessidade  com a porcentagem  100.0\n",
      "necrose  tem o par  necrose  com a porcentagem  100.0\n",
      "nefropatia  tem o par  nefrostom  com a porcentagem  0\n",
      "negacao  tem o par  negacao  com a porcentagem  100.0\n",
      "negocio  tem o par  tratar   com a porcentagem  0\n",
      "nenhum  tem o par  nenhum  com a porcentagem  100.0\n",
      "neoplasia  tem o par  escoriacao   com a porcentagem  0\n",
      "neoplasicas  tem o par  encopres  com a porcentagem  0\n",
      "neovascularizacao  tem o par  process vascular, posit  com a porcentagem  0\n",
      "nervo  tem o par  nervo  com a porcentagem  100.0\n",
      "neuropatia  tem o par  necrosar   com a porcentagem  0\n",
      "nivel  tem o par  nivel esperado  com a porcentagem  100.0\n",
      "normal  tem o par  normal  com a porcentagem  100.0\n",
      "nutricao  tem o par  servico nutricao  com a porcentagem  100.0\n",
      "nutriente  tem o par  nutriente  com a porcentagem  100.0\n",
      "obesidade  tem o par  obesidade  com a porcentagem  100.0\n",
      "obliteracao  tem o par  ilusao   com a porcentagem  0\n",
      "['obliteração', 'artérias']\n",
      "tempo sinonimos,  3.7600595951080322\n",
      "---------dicionarios------- obliteracao arterias\n",
      "{'obliteração': ['oclusao', 'obliteração'], 'artérias': ['artérias']}\n",
      "{'obliteração': ['oclusao ', 'obliteração '], 'artérias': ['artério ']}\n",
      "{'obliteração': ['oclusa', 'obliter'], 'artérias': ['artér']}\n",
      "obliteracao arterias  numero de combinações:  2\n",
      "tempo posib,  0.0\n",
      "['oclusao artérias', 'obliteração artérias']\n",
      "obliteracao arterias  tem o par  arteria  com a porcentagem  100.0\n",
      "observar  tem o par  observar  com a porcentagem  100.0\n",
      "obstrucao  tem o par  obstrucao  com a porcentagem  100.0\n",
      "obter dados  tem o par  obter dados  com a porcentagem  100.0\n",
      "odor  tem o par  odor fetido  com a porcentagem  100.0\n",
      "odor fetido  tem o par  odor fetido  com a porcentagem  100.0\n",
      "ordem  tem o par  processo  com a porcentagem  0\n",
      "organizar  tem o par  organizar  com a porcentagem  100.0\n",
      "orientacao  tem o par  orientacao  com a porcentagem  100.0\n",
      "orientar  tem o par  orientar  com a porcentagem  100.0\n",
      "orientar sobre dieta  tem o par  orientar sobre dieta  com a porcentagem  100.0\n",
      "osso  tem o par  osso  com a porcentagem  100.0\n",
      "osteomielite  tem o par  osso pelvic  com a porcentagem  0\n",
      "otimismo  tem o par  ansiedade  com a porcentagem  0\n",
      "otimizar  tem o par  otimizar  com a porcentagem  100.0\n",
      "ototoxicicidade  tem o par  fototerap  com a porcentagem  0\n",
      "ouvir  tem o par  ouvir  com a porcentagem  100.0\n",
      "oxido  tem o par  direito   com a porcentagem  0\n",
      "['óxido', 'nítrico']\n",
      "tempo sinonimos,  5.009975910186768\n",
      "---------dicionarios------- oxido nitrico\n",
      "{'óxido': ['barita', 'óxido'], 'nítrico': ['azotico', 'nítrico']}\n",
      "{'óxido': ['barito ', 'óxido '], 'nítrico': ['azotico ', 'nítrico ']}\n",
      "{'óxido': ['barit', 'óxid'], 'nítrico': ['azot', 'nítric']}\n",
      "oxido nitrico  numero de combinações:  4\n",
      "tempo posib,  0.0\n",
      "['barita azotico', 'barita nítrico', 'óxido azotico', 'óxido nítrico']\n",
      "oxido nitrico  tem o par  efeito biotico   com a porcentagem  0\n",
      "oxigenoterapia  tem o par  oxigenoterapia  com a porcentagem  100.0\n",
      "paciente  tem o par  paciente  com a porcentagem  100.0\n",
      "pacote  tem o par  tardar   com a porcentagem  0\n",
      "padrao  tem o par  padrao mobilidade  com a porcentagem  100.0\n",
      "padrao mobilidade  tem o par  padrao mobilidade  com a porcentagem  100.0\n",
      "padronizacao  tem o par  padra mobil  com a porcentagem  0\n",
      "['palavra', 'chave']\n",
      "tempo sinonimos,  4.153783559799194\n",
      "---------dicionarios------- palavra chave\n",
      "{'palavra': ['termo', 'vocabulo', 'frase', 'declaracao', 'promessa', 'palavra'], 'chave': ['fecho', 'solucao', 'mecanismo', 'explicacao', 'base', 'essencia', 'fundamento', 'parcial', 'pedra', 'poder', 'controle', 'propriedade', 'simbolo', 'codigo', 'cifra', 'inicio', 'principio', 'comeco', 'clave', 'chave']}\n",
      "{'palavra': ['termo ', 'vocabulo ', 'frase ', 'declaracao ', 'promessa ', 'palavrar '], 'chave': ['fechar ', 'solucao ', 'mecanismo ', 'explicacao ', 'base ', 'essencia ', 'fundamentar ', 'parcial ', 'pedrar ', 'poder ', 'controlar ', 'propriedade ', 'simbolar ', 'codigo ', 'cifrar ', 'iniciar ', 'principiar ', 'comeco ', 'clavar ', 'chave ']}\n",
      "{'palavra': ['term', 'vocabul', 'fras', 'declaraca', 'promess', 'palavr'], 'chave': ['fech', 'soluca', 'mecan', 'explicaca', 'bas', 'essenc', 'fundament', 'parcial', 'pedr', 'pod', 'control', 'propriedad', 'simbol', 'codig', 'cifr', 'inici', 'principi', 'comec', 'clav', 'chav']}\n",
      "palavra chave  numero de combinações:  120\n",
      "tempo posib,  0.0009992122650146484\n",
      "['termo fecho', 'termo solucao', 'termo mecanismo', 'termo explicacao', 'termo base', 'termo essencia', 'termo fundamento', 'termo parcial', 'termo pedra', 'termo poder', 'termo controle', 'termo propriedade', 'termo simbolo', 'termo codigo', 'termo cifra', 'termo inicio', 'termo principio', 'termo comeco', 'termo clave', 'termo chave', 'vocabulo fecho', 'vocabulo solucao', 'vocabulo mecanismo', 'vocabulo explicacao', 'vocabulo base', 'vocabulo essencia', 'vocabulo fundamento', 'vocabulo parcial', 'vocabulo pedra', 'vocabulo poder', 'vocabulo controle', 'vocabulo propriedade', 'vocabulo simbolo', 'vocabulo codigo', 'vocabulo cifra', 'vocabulo inicio', 'vocabulo principio', 'vocabulo comeco', 'vocabulo clave', 'vocabulo chave', 'frase fecho', 'frase solucao', 'frase mecanismo', 'frase explicacao', 'frase base', 'frase essencia', 'frase fundamento', 'frase parcial', 'frase pedra', 'frase poder', 'frase controle', 'frase propriedade', 'frase simbolo', 'frase codigo', 'frase cifra', 'frase inicio', 'frase principio', 'frase comeco', 'frase clave', 'frase chave', 'declaracao fecho', 'declaracao solucao', 'declaracao mecanismo', 'declaracao explicacao', 'declaracao base', 'declaracao essencia', 'declaracao fundamento', 'declaracao parcial', 'declaracao pedra', 'declaracao poder', 'declaracao controle', 'declaracao propriedade', 'declaracao simbolo', 'declaracao codigo', 'declaracao cifra', 'declaracao inicio', 'declaracao principio', 'declaracao comeco', 'declaracao clave', 'declaracao chave', 'promessa fecho', 'promessa solucao', 'promessa mecanismo', 'promessa explicacao', 'promessa base', 'promessa essencia', 'promessa fundamento', 'promessa parcial', 'promessa pedra', 'promessa poder', 'promessa controle', 'promessa propriedade', 'promessa simbolo', 'promessa codigo', 'promessa cifra', 'promessa inicio', 'promessa principio', 'promessa comeco', 'promessa clave', 'promessa chave', 'palavra fecho', 'palavra solucao', 'palavra mecanismo', 'palavra explicacao', 'palavra base', 'palavra essencia', 'palavra fundamento', 'palavra parcial', 'palavra pedra', 'palavra poder', 'palavra controle', 'palavra propriedade', 'palavra simbolo', 'palavra codigo', 'palavra cifra', 'palavra inicio', 'palavra principio', 'palavra comeco', 'palavra clave', 'palavra chave']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palavra chave  tem o par  ferir fechar   com a porcentagem  0\n",
      "paliacao  tem o par  prover (proporcionar, fornecer) paliacao  com a porcentagem  100.0\n",
      "palpar  tem o par  palpar  com a porcentagem  100.0\n",
      "panorama  tem o par  visitar   com a porcentagem  0\n",
      "papaina  tem o par  paralis  com a porcentagem  0\n",
      "papel apoio  tem o par  papel apoio  com a porcentagem  100.0\n",
      "papel estudante  tem o par  papel estudante  com a porcentagem  100.0\n",
      "papel genero  tem o par  papel genero  com a porcentagem  100.0\n",
      "papel lazer  tem o par  papel lazer  com a porcentagem  100.0\n",
      "papel terapeuta ocupacional  tem o par  papel terapeuta ocupacional  com a porcentagem  100.0\n",
      "papel trabalho  tem o par  papel trabalho  com a porcentagem  100.0\n",
      "papel espiritual  tem o par  papel espiritual  com a porcentagem  100.0\n",
      "patologia  tem o par  processo patologico  com a porcentagem  100.0\n",
      "pe  tem o par  pe  com a porcentagem  100.0\n",
      "pele  tem o par  pele  com a porcentagem  100.0\n",
      "pelicula  tem o par  ritmar   com a porcentagem  0\n",
      "penicilina  tem o par  tecnic dialis  com a porcentagem  0\n",
      "percepcao  tem o par  percepcao  com a porcentagem  100.0\n",
      "perda  tem o par  estradar   com a porcentagem  0\n",
      "perfusao tissular  tem o par  perfusao tissular  com a porcentagem  100.0\n",
      "['perfusão', 'tissular', 'periférica']\n",
      "tempo sinonimos,  6.007650375366211\n",
      "---------dicionarios------- perfusao tissular periferica\n",
      "{'perfusão': ['perfusão'], 'tissular': ['tissular'], 'periférica': ['periférica']}\n",
      "{'perfusão': ['perfusão '], 'tissular': ['tissular '], 'periférica': ['periférico ']}\n",
      "{'perfusão': ['perfusã'], 'tissular': ['tissul'], 'periférica': ['perifér']}\n",
      "perfusao tissular periferica  numero de combinações:  1\n",
      "tempo posib,  0.0\n",
      "['perfusão tissular periférica']\n",
      "perfusao tissular periferica  tem o par  perfusao tissular  com a porcentagem  100.0\n",
      "perfusao tissular, ineficaz  tem o par  perfusao tissular, ineficaz  com a porcentagem  100.0\n",
      "perilesao  tem o par  perifer  com a porcentagem  0\n",
      "perilesional  tem o par  papel sinal  com a porcentagem  0\n",
      "periodo desenvolvimento  tem o par  periodo desenvolvimento  com a porcentagem  100.0\n",
      "permeabilidade  tem o par  hiperatividade  com a porcentagem  0\n",
      "perna  tem o par  perna  com a porcentagem  100.0\n",
      "pesquisa  tem o par  inquietacao   com a porcentagem  0\n",
      "['pesquisa', 'março']\n",
      "tempo sinonimos,  4.073568105697632\n",
      "---------dicionarios------- pesquisa marco\n",
      "{'pesquisa': ['perquiricao', 'perquisicao', 'averiguacao', 'devassa', 'indagacao', 'inquiricao', 'investigacao', 'pesquisa'], 'março': ['baliza', 'demarcacao', 'divisa', 'fronteira', 'limite', 'março']}\n",
      "{'pesquisa': ['perquiricao ', 'perquisicao ', 'averiguacao ', 'devassar ', 'indagacao ', 'inquiricao ', 'investigacao ', 'pesquisar '], 'março': ['balizar ', 'demarcacao ', 'divisar ', 'fronteirar ', 'limitar ', 'março ']}\n",
      "{'pesquisa': ['perquirica', 'perquisica', 'averiguaca', 'devass', 'indagaca', 'inquirica', 'investigaca', 'pesquis'], 'março': ['baliz', 'demarcaca', 'divis', 'fronteir', 'limit', 'marc']}\n",
      "pesquisa marco  numero de combinações:  48\n",
      "tempo posib,  0.0\n",
      "['perquiricao baliza', 'perquiricao demarcacao', 'perquiricao divisa', 'perquiricao fronteira', 'perquiricao limite', 'perquiricao março', 'perquisicao baliza', 'perquisicao demarcacao', 'perquisicao divisa', 'perquisicao fronteira', 'perquisicao limite', 'perquisicao março', 'averiguacao baliza', 'averiguacao demarcacao', 'averiguacao divisa', 'averiguacao fronteira', 'averiguacao limite', 'averiguacao março', 'devassa baliza', 'devassa demarcacao', 'devassa divisa', 'devassa fronteira', 'devassa limite', 'devassa março', 'indagacao baliza', 'indagacao demarcacao', 'indagacao divisa', 'indagacao fronteira', 'indagacao limite', 'indagacao março', 'inquiricao baliza', 'inquiricao demarcacao', 'inquiricao divisa', 'inquiricao fronteira', 'inquiricao limite', 'inquiricao março', 'investigacao baliza', 'investigacao demarcacao', 'investigacao divisa', 'investigacao fronteira', 'investigacao limite', 'investigacao março', 'pesquisa baliza', 'pesquisa demarcacao', 'pesquisa divisa', 'pesquisa fronteira', 'pesquisa limite', 'pesquisa março']\n",
      "pesquisa marco  tem o par  aquisicao medicacao   com a porcentagem  0\n",
      "planejada  tem o par  gestacao (gravidez), nao planejada  com a porcentagem  100.0\n",
      "planejar  tem o par  planejar  com a porcentagem  100.0\n",
      "plano cuidado  tem o par  plano cuidado  com a porcentagem  100.0\n",
      "ponto tempo intervalo tempo  tem o par  ponto tempo intervalo tempo  com a porcentagem  100.0\n",
      "possibilidade  tem o par  casal   com a porcentagem  0\n",
      "posterior  tem o par  posterior  com a porcentagem  100.0\n",
      "potencial  tem o par  potencial risco  com a porcentagem  100.0\n",
      "prata  tem o par  praz  com a porcentagem  0\n",
      "pratica  tem o par  real   com a porcentagem  0\n",
      "predisposicao  tem o par  disposicao (ou prontidao) manejo (controle), por si proprio  com a porcentagem  100.0\n",
      "preexistentes  tem o par  anterior   com a porcentagem  0\n",
      "prejudicado  tem o par  prejudicado  com a porcentagem  100.0\n",
      "preocupacao  tem o par  preocupacao  com a porcentagem  100.0\n",
      "presenca  tem o par  presenca  com a porcentagem  100.0\n",
      "pressao  tem o par  pressao  com a porcentagem  100.0\n",
      "prestar  tem o par  prestador (ou provedor) cuidados saude  com a porcentagem  100.0\n",
      "prevenir  tem o par  prevenir  com a porcentagem  100.0\n",
      "privacao  tem o par  privacao sono  com a porcentagem  100.0\n",
      "privacidade  tem o par  privacidade  com a porcentagem  100.0\n",
      "procedimento  tem o par  procedimento  com a porcentagem  100.0\n",
      "processo  tem o par  processo  com a porcentagem  100.0\n",
      "processo corporal  tem o par  processo corporal  com a porcentagem  100.0\n",
      "processo sistema imune, eficaz  tem o par  processo sistema imune, eficaz  com a porcentagem  100.0\n",
      "processo sistema imunologico  tem o par  processo sistema imunologico  com a porcentagem  100.0\n",
      "processo neurovascular, prejudicado  tem o par  processo neurovascular, prejudicado  com a porcentagem  100.0\n",
      "processo secretorio  tem o par  processo secretorio  com a porcentagem  100.0\n",
      "processo sexual  tem o par  processo sexual  com a porcentagem  100.0\n",
      "processofamiliar  tem o par  process famili  com a porcentagem  0\n",
      "produto sangue  tem o par  produto sangue  com a porcentagem  100.0\n",
      "prognostico  tem o par  prepucio  com a porcentagem  0\n",
      "programa  tem o par  plano  com a porcentagem  0\n",
      "prolongamento  tem o par  crescimento  com a porcentagem  0\n",
      "propilenoglicol  tem o par  problem relacion  com a porcentagem  0\n",
      "['propilenoglicol', 'água']\n",
      "tempo sinonimos,  3.9277656078338623\n",
      "---------dicionarios------- propilenoglicol agua\n",
      "{'propilenoglicol': ['propilenoglicol'], 'água': ['chuva', 'água']}\n",
      "{'propilenoglicol': ['propilenoglicol '], 'água': ['chuva ', 'água ']}\n",
      "{'propilenoglicol': ['propilenoglicol'], 'água': ['chuv', 'águ']}\n",
      "propilenoglicol agua  numero de combinações:  2\n",
      "tempo posib,  0.0\n",
      "['propilenoglicol chuva', 'propilenoglicol água']\n",
      "propilenoglicol agua  tem o par  agua  com a porcentagem  100.0\n",
      "protecao  tem o par  abrigo  com a porcentagem  0\n",
      "proteger  tem o par  proteger  com a porcentagem  100.0\n",
      "proteina  tem o par  hiperfosfatemia   com a porcentagem  0\n",
      "protese  tem o par  protese dentaria  com a porcentagem  100.0\n",
      "protocolo  tem o par  protocolo  com a porcentagem  100.0\n",
      "prurido  tem o par  prurido  com a porcentagem  100.0\n",
      "pseudomonas  tem o par  pression  com a porcentagem  0\n",
      "purificar  tem o par  purificar  com a porcentagem  100.0\n",
      "pvpi  tem o par  pali  com a porcentagem  0\n",
      "qualidade  tem o par  qualidade vida  com a porcentagem  100.0\n",
      "queimacao  tem o par  queixar   com a porcentagem  0\n",
      "queixa  tem o par  posicao   com a porcentagem  0\n",
      "questionario  tem o par  questionario  com a porcentagem  100.0\n",
      "randomizados  tem o par  tranquiliz  com a porcentagem  0\n",
      "reabilitacao  tem o par  regime reabilitacao cardiaca  com a porcentagem  100.0\n",
      "reabsorcao  tem o par  absorca  com a porcentagem  0\n",
      "realizacao (alcance)  tem o par  realizacao (alcance)  com a porcentagem  100.0\n",
      "reavaliacao  tem o par  instrumento avaliacao  com a porcentagem  100.0\n",
      "recaida  tem o par  recaida  com a porcentagem  100.0\n",
      "recuperacao  tem o par  recuperacao  com a porcentagem  100.0\n",
      "reduzir  tem o par  tristeza cronica, reduzida  com a porcentagem  100.0\n",
      "reestruturacao  tem o par  forcar   com a porcentagem  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regiao corporal  tem o par  regiao corporal  com a porcentagem  100.0\n",
      "regime medicamentoso  tem o par  regime medicamentoso  com a porcentagem  100.0\n",
      "registrar  tem o par  registrar  com a porcentagem  100.0\n",
      "registro  tem o par  raivar   com a porcentagem  0\n",
      "regra  tem o par  lei  com a porcentagem  0\n",
      "regular  tem o par  regular  com a porcentagem  100.0\n",
      "relatar  tem o par  relatar  com a porcentagem  100.0\n",
      "remover  tem o par  remover  com a porcentagem  100.0\n",
      "repeticao  tem o par  desolacao   com a porcentagem  0\n",
      "reposicao  tem o par  posicao supina (ou decubito dorsal)  com a porcentagem  100.0\n",
      "resfriamento  tem o par  dispositivo aquecimento esfriamento  com a porcentagem  90.9090909090909\n",
      "['resfriamento', 'súbito']\n",
      "tempo sinonimos,  4.1608617305755615\n",
      "---------dicionarios------- resfriamento subito\n",
      "{'resfriamento': ['esfriamento', 'arrefecimento', 'resfriamento'], 'súbito': ['subitamente', 'imediato', 'inesperado', 'inopino', 'repentino', 'subitaneo', 'impeto', 'assalto', 'súbito']}\n",
      "{'resfriamento': ['esfriar ', 'refecer ', 'resfriar '], 'súbito': ['subitamente ', 'imediatar ', 'inesperado ', 'inopino ', 'repentino ', 'subitaneo ', 'petar ', 'assalto ', 'súbito ']}\n",
      "{'resfriamento': ['esfriament', 'arrefec', 'resfriament'], 'súbito': ['subit', 'imediat', 'inesper', 'inopin', 'repentin', 'subitan', 'impet', 'assalt', 'súbit']}\n",
      "resfriamento subito  numero de combinações:  27\n",
      "tempo posib,  0.0\n",
      "['esfriamento subitamente', 'esfriamento imediato', 'esfriamento inesperado', 'esfriamento inopino', 'esfriamento repentino', 'esfriamento subitaneo', 'esfriamento impeto', 'esfriamento assalto', 'esfriamento súbito', 'arrefecimento subitamente', 'arrefecimento imediato', 'arrefecimento inesperado', 'arrefecimento inopino', 'arrefecimento repentino', 'arrefecimento subitaneo', 'arrefecimento impeto', 'arrefecimento assalto', 'arrefecimento súbito', 'resfriamento subitamente', 'resfriamento imediato', 'resfriamento inesperado', 'resfriamento inopino', 'resfriamento repentino', 'resfriamento subitaneo', 'resfriamento impeto', 'resfriamento assalto', 'resfriamento súbito']\n",
      "resfriamento subito  tem o par  resultar testar   com a porcentagem  0\n",
      "resolucao  tem o par  solucao  com a porcentagem  0\n",
      "responder  tem o par  responder  com a porcentagem  100.0\n",
      "['resposta', 'analgesia', '(controlada', 'pelo', 'paciente)']\n",
      "tempo sinonimos,  10.268828630447388\n",
      "---------dicionarios------- resposta analgesia (controlada pelo paciente)\n",
      "{'resposta': ['refutacao', 'reacao', 'replica', 'resposta'], 'analgesia': ['analgia', 'analgesia'], '(controlada': ['(controlada'], 'pelo': ['atraves', 'cabelo', 'penugem', 'pelo'], 'paciente)': ['paciente)']}\n",
      "{'resposta': ['refutacao ', 'reacao ', 'plicar ', 'respostar '], 'analgesia': ['analgia ', 'analgesia '], '(controlada': ['(controlada '], 'pelo': ['atraves ', 'cabelo ', 'penugem ', 'pelar '], 'paciente)': ['paciente) ']}\n",
      "{'resposta': ['refutaca', 'reaca', 'replic', 'respost'], 'analgesia': ['analg', 'analges'], '(controlada': ['(control'], 'pelo': ['atrav', 'cabel', 'penug', 'pel'], 'paciente)': ['paciente)']}\n",
      "resposta analgesia (controlada pelo paciente)  numero de combinações:  32\n",
      "tempo posib,  0.0\n",
      "['refutacao analgia (controlada atraves paciente)', 'refutacao analgia (controlada cabelo paciente)', 'refutacao analgia (controlada penugem paciente)', 'refutacao analgia (controlada pelo paciente)', 'refutacao analgesia (controlada atraves paciente)', 'refutacao analgesia (controlada cabelo paciente)', 'refutacao analgesia (controlada penugem paciente)', 'refutacao analgesia (controlada pelo paciente)', 'reacao analgia (controlada atraves paciente)', 'reacao analgia (controlada cabelo paciente)', 'reacao analgia (controlada penugem paciente)', 'reacao analgia (controlada pelo paciente)', 'reacao analgesia (controlada atraves paciente)', 'reacao analgesia (controlada cabelo paciente)', 'reacao analgesia (controlada penugem paciente)', 'reacao analgesia (controlada pelo paciente)', 'replica analgia (controlada atraves paciente)', 'replica analgia (controlada cabelo paciente)', 'replica analgia (controlada penugem paciente)', 'replica analgia (controlada pelo paciente)', 'replica analgesia (controlada atraves paciente)', 'replica analgesia (controlada cabelo paciente)', 'replica analgesia (controlada penugem paciente)', 'replica analgesia (controlada pelo paciente)', 'resposta analgia (controlada atraves paciente)', 'resposta analgia (controlada cabelo paciente)', 'resposta analgia (controlada penugem paciente)', 'resposta analgia (controlada pelo paciente)', 'resposta analgesia (controlada atraves paciente)', 'resposta analgesia (controlada cabelo paciente)', 'resposta analgesia (controlada penugem paciente)', 'resposta analgesia (controlada pelo paciente)']\n",
      "resposta analgesia (controlada pelo paciente)  tem o par  pele  com a porcentagem  100.0\n",
      "resposta manejo (controle) dor  tem o par  resposta manejo (controle) dor  com a porcentagem  100.0\n",
      "resposta fisica  tem o par  resposta fisica  com a porcentagem  100.0\n",
      "resultado  tem o par  resultado  com a porcentagem  100.0\n",
      "resumo  tem o par  presentar   com a porcentagem  0\n",
      "rigor  tem o par  potencialidade  com a porcentagem  0\n",
      "risco  tem o par  risco  com a porcentagem  100.0\n",
      "rotina  tem o par  rotina  com a porcentagem  100.0\n",
      "ruptura  tem o par  fratura  com a porcentagem  0\n",
      "sacarose  tem o par  lavar-s  com a porcentagem  0\n",
      "salina  tem o par  saliv  com a porcentagem  0\n",
      "sangue  tem o par  sangue  com a porcentagem  100.0\n",
      "satisfacao conjugal  tem o par  satisfacao conjugal  com a porcentagem  100.0\n",
      "saudavel  tem o par  prepucio  com a porcentagem  0\n",
      "saude  tem o par  saude  com a porcentagem  100.0\n",
      "secrecao  tem o par  secrecao  com a porcentagem  100.0\n",
      "sedentario  tem o par  aliviar   com a porcentagem  0\n",
      "sedentarismo  tem o par  acao  com a porcentagem  0\n",
      "seguranca  tem o par  seguranca  com a porcentagem  100.0\n",
      "sensoriais  tem o par  componente sistema sensorial  com a porcentagem  100.0\n",
      "seroso  tem o par  necros  com a porcentagem  0\n",
      "servico comunitario  tem o par  servico comunitario  com a porcentagem  100.0\n",
      "servico educacao  tem o par  servico educacao  com a porcentagem  100.0\n",
      "servico enfermagem  tem o par  servico enfermagem  com a porcentagem  100.0\n",
      "['serviço', 'escola']\n",
      "tempo sinonimos,  4.072209596633911\n",
      "---------dicionarios------- servico escola\n",
      "{'serviço': ['emprego', 'ocupacao', 'oficio', 'tarefa', 'trabalho', 'serviço'], 'escola': ['colegio', 'escola']}\n",
      "{'serviço': ['emprego ', 'ocupacao ', 'oficiar ', 'tarefar ', 'trabalhar ', 'serviço '], 'escola': ['colegio ', 'escol ']}\n",
      "{'serviço': ['empreg', 'ocupaca', 'ofici', 'taref', 'trabalh', 'servic'], 'escola': ['colegi', 'escol']}\n",
      "servico escola  numero de combinações:  12\n",
      "tempo posib,  0.0\n",
      "['emprego colegio', 'emprego escola', 'ocupacao colegio', 'ocupacao escola', 'oficio colegio', 'oficio escola', 'tarefa colegio', 'tarefa escola', 'trabalho colegio', 'trabalho escola', 'serviço colegio', 'serviço escola']\n",
      "servico escola  tem o par  escola  com a porcentagem  100.0\n",
      "servico saude  tem o par  servico saude  com a porcentagem  100.0\n",
      "['serviços', 'promoção', 'saúde']\n",
      "tempo sinonimos,  5.975378036499023\n",
      "---------dicionarios------- servicos promocao saude\n",
      "{'serviços': ['trabalhos', 'empregos', 'ocupacaos', 'ocupacoes', 'oficios', 'tarefas', 'serviços'], 'promoção': ['acessao', 'ascensao', 'melhoria', 'anuncio', 'promoção'], 'saúde': ['forca', 'robustez', 'saudacao', 'vigor', 'brinde', 'saúde']}\n",
      "{'serviços': ['trabalhos ', 'emprego ', 'ocupacaos ', 'ocupacoes ', 'oficios ', 'tarefar ', 'serviço '], 'promoção': ['acessao ', 'ascensao ', 'melhorio ', 'nunciar ', 'promoção '], 'saúde': ['forca ', 'robustez ', 'saudacao ', 'vigor ', 'brindar ', 'saudar ']}\n",
      "{'serviços': ['trabalh', 'empreg', 'ocupaca', 'ocupaco', 'ofici', 'taref', 'servic'], 'promoção': ['acessa', 'ascensa', 'melhor', 'anunci', 'promoçã'], 'saúde': ['forc', 'robustez', 'saudaca', 'vigor', 'brind', 'saúd']}\n",
      "servicos promocao saude  numero de combinações:  210\n",
      "tempo posib,  0.0\n",
      "['trabalhos acessao forca', 'trabalhos acessao robustez', 'trabalhos acessao saudacao', 'trabalhos acessao vigor', 'trabalhos acessao brinde', 'trabalhos acessao saúde', 'trabalhos ascensao forca', 'trabalhos ascensao robustez', 'trabalhos ascensao saudacao', 'trabalhos ascensao vigor', 'trabalhos ascensao brinde', 'trabalhos ascensao saúde', 'trabalhos melhoria forca', 'trabalhos melhoria robustez', 'trabalhos melhoria saudacao', 'trabalhos melhoria vigor', 'trabalhos melhoria brinde', 'trabalhos melhoria saúde', 'trabalhos anuncio forca', 'trabalhos anuncio robustez', 'trabalhos anuncio saudacao', 'trabalhos anuncio vigor', 'trabalhos anuncio brinde', 'trabalhos anuncio saúde', 'trabalhos promoção forca', 'trabalhos promoção robustez', 'trabalhos promoção saudacao', 'trabalhos promoção vigor', 'trabalhos promoção brinde', 'trabalhos promoção saúde', 'empregos acessao forca', 'empregos acessao robustez', 'empregos acessao saudacao', 'empregos acessao vigor', 'empregos acessao brinde', 'empregos acessao saúde', 'empregos ascensao forca', 'empregos ascensao robustez', 'empregos ascensao saudacao', 'empregos ascensao vigor', 'empregos ascensao brinde', 'empregos ascensao saúde', 'empregos melhoria forca', 'empregos melhoria robustez', 'empregos melhoria saudacao', 'empregos melhoria vigor', 'empregos melhoria brinde', 'empregos melhoria saúde', 'empregos anuncio forca', 'empregos anuncio robustez', 'empregos anuncio saudacao', 'empregos anuncio vigor', 'empregos anuncio brinde', 'empregos anuncio saúde', 'empregos promoção forca', 'empregos promoção robustez', 'empregos promoção saudacao', 'empregos promoção vigor', 'empregos promoção brinde', 'empregos promoção saúde', 'ocupacaos acessao forca', 'ocupacaos acessao robustez', 'ocupacaos acessao saudacao', 'ocupacaos acessao vigor', 'ocupacaos acessao brinde', 'ocupacaos acessao saúde', 'ocupacaos ascensao forca', 'ocupacaos ascensao robustez', 'ocupacaos ascensao saudacao', 'ocupacaos ascensao vigor', 'ocupacaos ascensao brinde', 'ocupacaos ascensao saúde', 'ocupacaos melhoria forca', 'ocupacaos melhoria robustez', 'ocupacaos melhoria saudacao', 'ocupacaos melhoria vigor', 'ocupacaos melhoria brinde', 'ocupacaos melhoria saúde', 'ocupacaos anuncio forca', 'ocupacaos anuncio robustez', 'ocupacaos anuncio saudacao', 'ocupacaos anuncio vigor', 'ocupacaos anuncio brinde', 'ocupacaos anuncio saúde', 'ocupacaos promoção forca', 'ocupacaos promoção robustez', 'ocupacaos promoção saudacao', 'ocupacaos promoção vigor', 'ocupacaos promoção brinde', 'ocupacaos promoção saúde', 'ocupacoes acessao forca', 'ocupacoes acessao robustez', 'ocupacoes acessao saudacao', 'ocupacoes acessao vigor', 'ocupacoes acessao brinde', 'ocupacoes acessao saúde', 'ocupacoes ascensao forca', 'ocupacoes ascensao robustez', 'ocupacoes ascensao saudacao', 'ocupacoes ascensao vigor', 'ocupacoes ascensao brinde', 'ocupacoes ascensao saúde', 'ocupacoes melhoria forca', 'ocupacoes melhoria robustez', 'ocupacoes melhoria saudacao', 'ocupacoes melhoria vigor', 'ocupacoes melhoria brinde', 'ocupacoes melhoria saúde', 'ocupacoes anuncio forca', 'ocupacoes anuncio robustez', 'ocupacoes anuncio saudacao', 'ocupacoes anuncio vigor', 'ocupacoes anuncio brinde', 'ocupacoes anuncio saúde', 'ocupacoes promoção forca', 'ocupacoes promoção robustez', 'ocupacoes promoção saudacao', 'ocupacoes promoção vigor', 'ocupacoes promoção brinde', 'ocupacoes promoção saúde', 'oficios acessao forca', 'oficios acessao robustez', 'oficios acessao saudacao', 'oficios acessao vigor', 'oficios acessao brinde', 'oficios acessao saúde', 'oficios ascensao forca', 'oficios ascensao robustez', 'oficios ascensao saudacao', 'oficios ascensao vigor', 'oficios ascensao brinde', 'oficios ascensao saúde', 'oficios melhoria forca', 'oficios melhoria robustez', 'oficios melhoria saudacao', 'oficios melhoria vigor', 'oficios melhoria brinde', 'oficios melhoria saúde', 'oficios anuncio forca', 'oficios anuncio robustez', 'oficios anuncio saudacao', 'oficios anuncio vigor', 'oficios anuncio brinde', 'oficios anuncio saúde', 'oficios promoção forca', 'oficios promoção robustez', 'oficios promoção saudacao', 'oficios promoção vigor', 'oficios promoção brinde', 'oficios promoção saúde', 'tarefas acessao forca', 'tarefas acessao robustez', 'tarefas acessao saudacao', 'tarefas acessao vigor', 'tarefas acessao brinde', 'tarefas acessao saúde', 'tarefas ascensao forca', 'tarefas ascensao robustez', 'tarefas ascensao saudacao', 'tarefas ascensao vigor', 'tarefas ascensao brinde', 'tarefas ascensao saúde', 'tarefas melhoria forca', 'tarefas melhoria robustez', 'tarefas melhoria saudacao', 'tarefas melhoria vigor', 'tarefas melhoria brinde', 'tarefas melhoria saúde', 'tarefas anuncio forca', 'tarefas anuncio robustez', 'tarefas anuncio saudacao', 'tarefas anuncio vigor', 'tarefas anuncio brinde', 'tarefas anuncio saúde', 'tarefas promoção forca', 'tarefas promoção robustez', 'tarefas promoção saudacao', 'tarefas promoção vigor', 'tarefas promoção brinde', 'tarefas promoção saúde', 'serviços acessao forca', 'serviços acessao robustez', 'serviços acessao saudacao', 'serviços acessao vigor', 'serviços acessao brinde', 'serviços acessao saúde', 'serviços ascensao forca', 'serviços ascensao robustez', 'serviços ascensao saudacao', 'serviços ascensao vigor', 'serviços ascensao brinde', 'serviços ascensao saúde', 'serviços melhoria forca', 'serviços melhoria robustez', 'serviços melhoria saudacao', 'serviços melhoria vigor', 'serviços melhoria brinde', 'serviços melhoria saúde', 'serviços anuncio forca', 'serviços anuncio robustez', 'serviços anuncio saudacao', 'serviços anuncio vigor', 'serviços anuncio brinde', 'serviços anuncio saúde', 'serviços promoção forca', 'serviços promoção robustez', 'serviços promoção saudacao', 'serviços promoção vigor', 'serviços promoção brinde', 'serviços promoção saúde']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "servicos promocao saude  tem o par  saude  com a porcentagem  100.0\n",
      "servidor  tem o par  esfregar   com a porcentagem  0\n",
      "['sigla', 'pressure', 'ulcer', 'scale', 'for', 'healing']\n",
      "tempo sinonimos,  12.1422119140625\n",
      "---------dicionarios------- sigla  pressure ulcer scale for healing\n",
      "{'sigla': ['sigla'], 'pressure': ['pressure'], 'ulcer': ['ulcer'], 'scale': ['scale'], 'for': ['moda', 'uso', 'costume', 'for'], 'healing': ['healing']}\n",
      "{'sigla': ['siglar '], 'pressure': ['pressure '], 'ulcer': ['ulcer '], 'scale': ['scale '], 'for': ['modo ', 'usar ', 'costume ', 'for '], 'healing': ['healing ']}\n",
      "{'sigla': ['sigl'], 'pressure': ['pressur'], 'ulcer': ['ulcer'], 'scale': ['scal'], 'for': ['mod', 'uso', 'costum', 'for'], 'healing': ['healing']}\n",
      "sigla  pressure ulcer scale for healing  numero de combinações:  4\n",
      "tempo posib,  0.0\n",
      "['sigla pressure ulcer scale moda healing', 'sigla pressure ulcer scale uso healing', 'sigla pressure ulcer scale costume healing', 'sigla pressure ulcer scale for healing']\n",
      "sigla  pressure ulcer scale for healing  tem o par  ulcera  com a porcentagem  100.0\n",
      "sinais  tem o par  obter dados sobre sinais sintomas infeccao  com a porcentagem  100.0\n",
      "sinal  tem o par  sinal  com a porcentagem  100.0\n",
      "sinal desconforto  tem o par  sinal desconforto  com a porcentagem  100.0\n",
      "sinal infeccao  tem o par  sinal infeccao  com a porcentagem  100.0\n",
      "sinoptico  tem o par  culto   com a porcentagem  0\n",
      "sintoma  tem o par  sintoma  com a porcentagem  100.0\n",
      "sistema musculoesqueletico  tem o par  sistema musculoesqueletico  com a porcentagem  100.0\n",
      "sistema nervoso  tem o par  sistema nervoso  com a porcentagem  100.0\n",
      "sistema tegumentar  tem o par  sistema tegumentar  com a porcentagem  100.0\n",
      "situacao  tem o par  situacao  com a porcentagem  100.0\n",
      "sobrenome*  tem o par  sobrepes  com a porcentagem  0\n",
      "sociedade  tem o par  comunidade  com a porcentagem  0\n",
      "['sócio', 'econômico']\n",
      "tempo sinonimos,  3.9924697875976562\n",
      "---------dicionarios------- socio economico\n",
      "{'sócio': ['parceiro', 'quinhoeiro', 'co-autor', 'comparte', 'comparsa', 'sócio'], 'econômico': ['parcimonioso', 'governado', 'agarrado', 'poupado', 'seguro', 'apertado', 'aproveitado', 'financial', 'econômico']}\n",
      "{'sócio': ['parceiro ', 'quinhoeiro ', 'co-autor ', 'comparte ', 'comparsa ', 'sócio '], 'econômico': ['parcimonioso ', 'governar ', 'agarrar ', 'poupar ', 'segurar ', 'apertar ', 'aproveitar ', 'financial ', 'econômico ']}\n",
      "{'sócio': ['parceir', 'quinhoeir', 'co-autor', 'compart', 'compars', 'sóci'], 'econômico': ['parcimoni', 'govern', 'agarr', 'poup', 'segur', 'apert', 'aproveit', 'financial', 'econôm']}\n",
      "socio economico  numero de combinações:  54\n",
      "tempo posib,  0.0\n",
      "['parceiro parcimonioso', 'parceiro governado', 'parceiro agarrado', 'parceiro poupado', 'parceiro seguro', 'parceiro apertado', 'parceiro aproveitado', 'parceiro financial', 'parceiro econômico', 'quinhoeiro parcimonioso', 'quinhoeiro governado', 'quinhoeiro agarrado', 'quinhoeiro poupado', 'quinhoeiro seguro', 'quinhoeiro apertado', 'quinhoeiro aproveitado', 'quinhoeiro financial', 'quinhoeiro econômico', 'co-autor parcimonioso', 'co-autor governado', 'co-autor agarrado', 'co-autor poupado', 'co-autor seguro', 'co-autor apertado', 'co-autor aproveitado', 'co-autor financial', 'co-autor econômico', 'comparte parcimonioso', 'comparte governado', 'comparte agarrado', 'comparte poupado', 'comparte seguro', 'comparte apertado', 'comparte aproveitado', 'comparte financial', 'comparte econômico', 'comparsa parcimonioso', 'comparsa governado', 'comparsa agarrado', 'comparsa poupado', 'comparsa seguro', 'comparsa apertado', 'comparsa aproveitado', 'comparsa financial', 'comparsa econômico', 'sócio parcimonioso', 'sócio governado', 'sócio agarrado', 'sócio poupado', 'sócio seguro', 'sócio apertado', 'sócio aproveitado', 'sócio financial', 'sócio econômico']\n",
      "socio economico  tem o par  comport assert  com a porcentagem  0\n",
      "sofrimento  tem o par  sofrimento  com a porcentagem  100.0\n",
      "solidao  tem o par  solidao  com a porcentagem  100.0\n",
      "soro  tem o par  equipo soro  com a porcentagem  100.0\n",
      "substancia corporal  tem o par  substancia corporal  com a porcentagem  100.0\n",
      "sulfato  tem o par  olfat  com a porcentagem  0\n",
      "superficie  tem o par  dispositivo neuroestimulador superficie  com a porcentagem  100.0\n",
      "taxa  tem o par  taxa  com a porcentagem  100.0\n",
      "taxa mortalidade  tem o par  taxa mortalidade  com a porcentagem  100.0\n",
      "['tecido', 'cicraticial']\n",
      "tempo sinonimos,  4.078537464141846\n",
      "---------dicionarios------- tecido cicraticial\n",
      "{'tecido': ['pano', 'tecido'], 'cicraticial': ['cicraticial']}\n",
      "{'tecido': ['panar ', 'tecer '], 'cicraticial': ['cicraticial ']}\n",
      "{'tecido': ['pan', 'tec'], 'cicraticial': ['cicraticial']}\n",
      "tecido cicraticial  numero de combinações:  2\n",
      "tempo posib,  0.0\n",
      "['pano cicraticial', 'tecido cicraticial']\n",
      "tecido cicraticial  tem o par  tecido cicatricial  com a porcentagem  0\n",
      "tecido corporal  tem o par  tecido corporal  com a porcentagem  100.0\n",
      "tecnica  tem o par  tecnica  com a porcentagem  100.0\n",
      "tecnica asseptica  tem o par  tecnica asseptica  com a porcentagem  100.0\n",
      "tecnica interacao  tem o par  tecnica interacao  com a porcentagem  100.0\n",
      "tecnica posicionamento  tem o par  tecnica posicionamento  com a porcentagem  100.0\n",
      "temor  tem o par  medo  com a porcentagem  0\n",
      "temperatura corporal  tem o par  temperatura corporal  com a porcentagem  100.0\n",
      "terapia  tem o par  terapia  com a porcentagem  100.0\n",
      "terapia por compressao  tem o par  terapia por compressao  com a porcentagem  100.0\n",
      "teste diagnostico  tem o par  teste diagnostico  com a porcentagem  100.0\n",
      "tetraciclina  tem o par  terap cris  com a porcentagem  0\n",
      "texto  tem o par  tremor   com a porcentagem  0\n",
      "['texto', 'seleção']\n",
      "tempo sinonimos,  23.041585206985474\n",
      "---------dicionarios------- texto selecao\n",
      "{'texto': ['teor', 'texto'], 'seleção': ['seleção']}\n",
      "{'texto': ['teor ', 'texto '], 'seleção': ['seleção ']}\n",
      "{'texto': ['teor', 'text'], 'seleção': ['seleçã']}\n",
      "texto selecao  numero de combinações:  2\n",
      "tempo posib,  0.0\n",
      "['teor seleção', 'texto seleção']\n",
      "texto selecao  tem o par  tremor senil  com a porcentagem  0\n",
      "['texto', 'seleção', 'artigos']\n",
      "tempo sinonimos,  5.964329957962036\n",
      "---------dicionarios------- texto selecao artigos\n",
      "{'texto': ['teor', 'texto'], 'seleção': ['escolha', 'apuracao', 'combinado', 'antologia', 'selecionado', 'seleção'], 'artigos': ['itens', 'clausulas', 'artigos']}\n",
      "{'texto': ['teor ', 'texto '], 'seleção': ['escolher ', 'apuracao ', 'combinar ', 'antologiar ', 'selecionar ', 'seleção '], 'artigos': ['item ', 'clausular ', 'artigo ']}\n",
      "{'texto': ['teor', 'text'], 'seleção': ['escolh', 'apuraca', 'combin', 'antolog', 'selecion', 'seleçã'], 'artigos': ['itens', 'clausul', 'artig']}\n",
      "texto selecao artigos  numero de combinações:  36\n",
      "tempo posib,  0.0\n",
      "['teor escolha itens', 'teor escolha clausulas', 'teor escolha artigos', 'teor apuracao itens', 'teor apuracao clausulas', 'teor apuracao artigos', 'teor combinado itens', 'teor combinado clausulas', 'teor combinado artigos', 'teor antologia itens', 'teor antologia clausulas', 'teor antologia artigos', 'teor selecionado itens', 'teor selecionado clausulas', 'teor selecionado artigos', 'teor seleção itens', 'teor seleção clausulas', 'teor seleção artigos', 'texto escolha itens', 'texto escolha clausulas', 'texto escolha artigos', 'texto apuracao itens', 'texto apuracao clausulas', 'texto apuracao artigos', 'texto combinado itens', 'texto combinado clausulas', 'texto combinado artigos', 'texto antologia itens', 'texto antologia clausulas', 'texto antologia artigos', 'texto selecionado itens', 'texto selecionado clausulas', 'texto selecionado artigos', 'texto seleção itens', 'texto seleção clausulas', 'texto seleção artigos']\n",
      "texto selecao artigos  tem o par  tecnico treinar genico   com a porcentagem  0\n",
      "trabalhar rede  tem o par  trabalhar rede  com a porcentagem  100.0\n",
      "transfusao  tem o par  transfer  com a porcentagem  0\n",
      "trauma  tem o par  trauma  com a porcentagem  100.0\n",
      "triglicerol  tem o par  tax literac  com a porcentagem  0\n",
      "['triglicerol', 'cadeia']\n",
      "tempo sinonimos,  3.965003728866577\n",
      "---------dicionarios------- triglicerol cadeia\n",
      "{'triglicerol': ['triglicerol'], 'cadeia': ['calabouco', 'carcere', 'enxovia', 'ergastulo', 'masmorra', 'prisao', 'algema', 'servidao', 'grilhao', 'cadeia']}\n",
      "{'triglicerol': ['triglicerol '], 'cadeia': ['calabouco ', 'carcerar ', 'enxovio ', 'ergastular ', 'masmorro ', 'prisao ', 'algemar ', 'servidao ', 'grilhao ', 'cadeia ']}\n",
      "{'triglicerol': ['triglicerol'], 'cadeia': ['calabouc', 'carcer', 'enxov', 'ergastul', 'masmorr', 'prisa', 'algem', 'servida', 'grilha', 'cad']}\n",
      "triglicerol cadeia  numero de combinações:  10\n",
      "tempo posib,  0.0\n",
      "['triglicerol calabouco', 'triglicerol carcere', 'triglicerol enxovia', 'triglicerol ergastulo', 'triglicerol masmorra', 'triglicerol prisao', 'triglicerol algema', 'triglicerol servidao', 'triglicerol grilhao', 'triglicerol cadeia']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triglicerol cadeia  tem o par  risc ulcer por pressa  com a porcentagem  0\n",
      "troca gasosa  tem o par  troca gasosa  com a porcentagem  100.0\n",
      "trocar cobertura ferida (ou curativo)  tem o par  trocar cobertura ferida (ou curativo)  com a porcentagem  100.0\n",
      "trombose  tem o par  trombose venosa profunda, ausente  com a porcentagem  100.0\n",
      "turvacao  tem o par  agitacao  com a porcentagem  0\n",
      "ulcera  tem o par  ulcera  com a porcentagem  100.0\n",
      "ulcera arterial  tem o par  ulcera arterial  com a porcentagem  100.0\n",
      "ulcera por pressao  tem o par  ulcera por pressao  com a porcentagem  100.0\n",
      "['úlcera', 'vascular']\n",
      "tempo sinonimos,  5.050112009048462\n",
      "---------dicionarios------- ulcera vascular\n",
      "{'úlcera': ['chaga', 'úlcera'], 'vascular': ['vascular']}\n",
      "{'úlcera': ['chagar ', 'úlcera '], 'vascular': ['vascular ']}\n",
      "{'úlcera': ['chag', 'úlcer'], 'vascular': ['vascul']}\n",
      "ulcera vascular  numero de combinações:  2\n",
      "tempo posib,  0.0\n",
      "['chaga vascular', 'úlcera vascular']\n",
      "ulcera vascular  tem o par  ulcera  com a porcentagem  100.0\n",
      "ulcera venosa  tem o par  ulcera venosa  com a porcentagem  100.0\n",
      "uniao  tem o par  concentracao   com a porcentagem  0\n",
      "unidade ambulatorial  tem o par  unidade ambulatorial  com a porcentagem  100.0\n",
      "unificado  tem o par  duzir   com a porcentagem  0\n",
      "universidade  tem o par  universidade  com a porcentagem  100.0\n",
      "vacina  tem o par  vacina  com a porcentagem  100.0\n",
      "valvula  tem o par  calcul  com a porcentagem  0\n",
      "varicosas  tem o par  vacin  com a porcentagem  0\n",
      "['varizes', 'mulheres']\n",
      "tempo sinonimos,  4.51025390625\n",
      "---------dicionarios------- varizes mulheres\n",
      "{'varizes': ['varizes'], 'mulheres': ['mulheres']}\n",
      "{'varizes': ['variz '], 'mulheres': ['mulher ']}\n",
      "{'varizes': ['variz'], 'mulheres': ['mulh']}\n",
      "varizes mulheres  numero de combinações:  1\n",
      "tempo posib,  0.0\n",
      "['varizes mulheres']\n",
      "varizes mulheres  tem o par  barreir comunic  com a porcentagem  0\n",
      "vascular  tem o par  dispositivo acesso vascular  com a porcentagem  100.0\n",
      "vascularizacao  tem o par  vestuari  com a porcentagem  0\n",
      "vasculite  tem o par  auscult  com a porcentagem  0\n",
      "vasculogenicas  tem o par  masc oxigeni  com a porcentagem  0\n",
      "vaselina  tem o par  insulin  com a porcentagem  0\n",
      "vaso sanguineo  tem o par  vaso sanguineo  com a porcentagem  100.0\n",
      "vazamento  tem o par  verrugar   com a porcentagem  0\n",
      "veia  tem o par  veia  com a porcentagem  100.0\n",
      "velocidade  tem o par  fugar   com a porcentagem  0\n",
      "venosa  tem o par  canula venosa  com a porcentagem  100.0\n",
      "vestir  tem o par  vestir  com a porcentagem  100.0\n",
      "via cutanea  tem o par  via cutanea  com a porcentagem  100.0\n",
      "via oral  tem o par  via oral  com a porcentagem  100.0\n",
      "via parenteral  tem o par  via parenteral  com a porcentagem  100.0\n",
      "via topica  tem o par  via topica  com a porcentagem  100.0\n",
      "vinculo  tem o par  vinculo  com a porcentagem  100.0\n",
      "visao  tem o par  visao  com a porcentagem  100.0\n",
      "viscosidade  tem o par  comunidade  com a porcentagem  0\n",
      "vitalidade  tem o par  sinal vital frequencia cardiaca  com a porcentagem  100.0\n",
      "vontade viver  tem o par  vontade viver  com a porcentagem  100.0\n",
      "vulnerabilidade  tem o par  inseguranca  com a porcentagem  0\n",
      "['vulnerabilidade', 'emocional']\n",
      "tempo sinonimos,  4.249853849411011\n",
      "---------dicionarios------- vulnerabilidade emocional\n",
      "{'vulnerabilidade': ['fragilidade', 'delicadeza', 'inseguranca', 'vulnerabilidade'], 'emocional': ['emotivo', 'sensivel', 'emocional']}\n",
      "{'vulnerabilidade': ['fragilidade ', 'delicadeza ', 'inseguranca ', 'vulnerável '], 'emocional': ['emotivo ', 'sensivel ', 'emocional ']}\n",
      "{'vulnerabilidade': ['fragil', 'delicad', 'inseguranc', 'vulner'], 'emocional': ['emot', 'sensivel', 'emocional']}\n",
      "vulnerabilidade emocional  numero de combinações:  12\n",
      "tempo posib,  0.0\n",
      "['fragilidade emotivo', 'fragilidade sensivel', 'fragilidade emocional', 'delicadeza emotivo', 'delicadeza sensivel', 'delicadeza emocional', 'inseguranca emotivo', 'inseguranca sensivel', 'inseguranca emocional', 'vulnerabilidade emotivo', 'vulnerabilidade sensivel', 'vulnerabilidade emocional']\n",
      "vulnerabilidade emocional  tem o par  recuper emocional  com a porcentagem  0\n"
     ]
    }
   ],
   "source": [
    "print(100 - 1 / len('lucass') * 100)\n",
    "\n",
    "zz = 0\n",
    "achou = 0\n",
    "candidato = ''\n",
    "perc_max = 0\n",
    "metodo = 0\n",
    "y_aux = 0\n",
    "\n",
    "\n",
    "controle = 1\n",
    "for x in range(0, len(df_termos_norm)):\n",
    "    \n",
    "    metodo = 0\n",
    "    '''locTerm = CIPE_df.loc[CIPE_df['Termos'] == df_termos.at[x, 'Termos']]\n",
    "    if not locTerm['Termos'].empty:\n",
    "    #if df_termos.at[x, 'Termos'] == CIPE_df.at[zzz, 'Termos']:\n",
    "        for xx in range(0,len(locTerm['Termos'])):\n",
    "            df_termos_match.at[zz, 'Termos'] = CIPE_df.at[locTerm.index[xx], 'Termos']\n",
    "            df_termos_match.at[zz, 'ICNPcode'] = CIPE_df.at[locTerm.index[xx], 'ICNPcode']\n",
    "            df_termos_match.at[zz, 'ICNPterm'] = CIPE_df.at[locTerm.index[xx], 'ICNPterm']\n",
    "            df_termos_match.at[zz, 'ICNPmod'] = CIPE_df.at[locTerm.index[xx], 'ICNPmod']\n",
    "            df_termos_match.at[zz, 'ICNPVersao'] = CIPE_df.at[locTerm.index[xx], 'ICNPVersao']\n",
    "            df_termos_match.at[zz, 'ICNPeixo'] = CIPE_df.at[locTerm.index[xx], 'ICNPeixo']\n",
    "            df_termos_match.at[zz, 'Regra'] = CIPE_df.at[locTerm.index[xx], 'Regra']\n",
    "            df_termos_match.at[zz, 'perc'] = CIPE_df.at[locTerm.index[xx], 'perc']\n",
    "            zz += 1\n",
    "        continue\n",
    "    print(df_termos.at[x, 'Termos'], ' ------- passou')\n",
    "    print(controle , ' termos ja passaram')'''\n",
    "    controle += 1\n",
    "    for y in range(0, len(df_CIPE_norm)):\n",
    "        num = levenshtein(df_termos_norm.at[x, 'Termos'], df_CIPE_norm.at[y, 'Termo'])\n",
    "        perc = 100 - num / len(df_CIPE_norm.at[y, 'Termo']) * 100\n",
    "        if perc > perc_max:\n",
    "            perc_max = perc\n",
    "            candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "            metodo = 1\n",
    "            y_aux = y\n",
    "        if perc_max == 100:\n",
    "            metodo = 1\n",
    "            break\n",
    "    if metodo == 1 and perc_max >= 90:\n",
    "        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "        df_termos_match.at[zz, 'Regra'] = 1\n",
    "        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "        zz += 1\n",
    "    if not perc_max == 100:\n",
    "        for y in range(0, len(df_CIPE_norm)):\n",
    "            num = levenshtein(df_termos_lemma.at[x, 'Termos'], df_CIPE_lemma.at[y, 'Termo'])\n",
    "            perc = 100 - num / len(df_CIPE_lemma.at[y, 'Termo']) * 100\n",
    "            if perc > perc_max:\n",
    "                perc_max = perc\n",
    "                candidato = df_CIPE_lemma.at[y, 'Termo']\n",
    "                metodo = 2\n",
    "                y_aux = y\n",
    "            elif perc == 100 and perc_max == 100:\n",
    "                df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                df_termos_match.at[zz, 'Regra'] = 2\n",
    "                df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                zz += 1\n",
    "                perc_max = perc\n",
    "                candidato = df_CIPE_lemma.at[y, 'Termo']\n",
    "                metodo = 2\n",
    "                y_aux = y\n",
    "        if metodo == 2 and perc_max >= 90:\n",
    "            df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "            df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "            df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "            df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "            df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "            df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "            df_termos_match.at[zz, 'Regra'] = 2\n",
    "            df_termos_match.at[zz, 'perc'] = perc_max\n",
    "            zz += 1\n",
    "        #if not perc_max == 100:\n",
    "        if not perc_max == 1000:\n",
    "            perc_max = 0\n",
    "            for y in range(0, len(df_CIPE_norm)):\n",
    "                num = levenshtein(df_termos_stem.at[x, 'Termos'], df_CIPE_stem.at[y, 'Termo'])\n",
    "                perc = 100 - num / len(df_CIPE_stem.at[y, 'Termo']) * 100\n",
    "                if perc > perc_max:\n",
    "                    perc_max = perc\n",
    "                    candidato = df_CIPE_stem.at[y, 'Termo']\n",
    "                    metodo = 3\n",
    "                    y_aux = y\n",
    "                elif perc == 100 and perc_max == 100:\n",
    "                    df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                    df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                    df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                    df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                    df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                    df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                    df_termos_match.at[zz, 'Regra'] = 3\n",
    "                    df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                    zz += 1\n",
    "                    perc_max = perc\n",
    "                    candidato = df_CIPE_lemma.at[y, 'Termo']\n",
    "                    metodo = 3\n",
    "                    y_aux = y\n",
    "            if metodo == 3 and perc_max >= 90:\n",
    "                df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                df_termos_match.at[zz, 'Regra'] = 3\n",
    "                df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                zz += 1\n",
    "            #if perc_max < 90:\n",
    "            if perc_max < 1000:\n",
    "                perc_max = 0\n",
    "                sem_sin = False\n",
    "                sinonimos_t = []\n",
    "                if len(df_termos.at[x, 'Termos'].split()) == 1:\n",
    "                    try:\n",
    "                        word = dicio.search(df_termos.at[x, 'Termos'])\n",
    "                        for w in word.synonyms:\n",
    "                            sinonimos_t.append(removearticles(unidecode.unidecode(str(w))).strip())\n",
    "                    except:\n",
    "                        sem_sin = True\n",
    "                else:\n",
    "                    iniR = time.time()\n",
    "                    sin = {}\n",
    "                    sin_lemma = {}\n",
    "                    sin_steam = {}\n",
    "                    words2 = (removearticles(df_termos.at[x, 'Termos']).strip()).split()\n",
    "                    print(words2)\n",
    "                    for p in words2:\n",
    "                        sinonimos = []\n",
    "                        sinonimos_lemma = []\n",
    "                        sinonimos_steam = []\n",
    "                        try:\n",
    "                            w = dicio.search(p)\n",
    "                            sinonimos = w.synonyms\n",
    "                            i = 0\n",
    "                            for s in sinonimos:\n",
    "                                sinonimos[i] = unidecode.unidecode(str(s))\n",
    "                                i += 1\n",
    "                            i = 0\n",
    "                            for s in sinonimos:\n",
    "                                sinonimos_lemma.append(lematizador(str(s)))\n",
    "                                sinonimos_steam.append(stemmer(str(s)))\n",
    "                                i += 1\n",
    "                            sinonimos.append(p)\n",
    "                            sinonimos_lemma.append(lematizador(p))\n",
    "                            sinonimos_steam.append(stemmer(p))\n",
    "                            sin[p] = sinonimos\n",
    "                            sin_lemma[p] = sinonimos_lemma\n",
    "                            sin_steam[p] = sinonimos_steam\n",
    "                        except:\n",
    "                            sin[p]=[p]\n",
    "                            sin_lemma[p] = [lematizador(p)]\n",
    "                            sin_steam[p] = [stemmer(p)]\n",
    "                    fimR = time.time()\n",
    "                    print('tempo sinonimos, ', (fimR-iniR))\n",
    "                    print('---------dicionarios-------', df_termos_norm.at[x,'Termos'])\n",
    "                    print(sin)\n",
    "                    print(sin_lemma)\n",
    "                    print(sin_steam)\n",
    "\n",
    "\n",
    "                    n = 0\n",
    "                    first = True\n",
    "                    for p in words2:\n",
    "                        if first:\n",
    "                            n = len(sin[p])\n",
    "                            first = False\n",
    "                            continue\n",
    "                        else:\n",
    "                            if len(sin[p]) != 0:\n",
    "                                n *= len(sin[p])\n",
    "                            else:\n",
    "                                continue\n",
    "                    print(df_termos_norm.at[x, 'Termos'], ' numero de combinações: ', n)\n",
    "                    posib = []\n",
    "                    posib_lemma = []\n",
    "                    posib_steam = []\n",
    "                    \n",
    "                    \n",
    "                    iniR = time.time()\n",
    "                    first = True\n",
    "                    for p in words2:\n",
    "                        if first:\n",
    "                            first = False\n",
    "                            for s in sin[p]:\n",
    "                                posib.append(s)\n",
    "                            for s in sin_lemma[p]:\n",
    "                                posib_lemma.append(s)\n",
    "                            for s in sin_steam[p]:\n",
    "                                posib_steam.append(s)\n",
    "                        else:\n",
    "                            posib = comb(posib, sin[p])\n",
    "                            posib_lemma = comb(posib_lemma, sin_lemma[p])\n",
    "                            posib_steam = comb(posib_steam, sin_steam[p])\n",
    "                    fimR = time.time()\n",
    "                    print('tempo posib, ', (fimR-iniR))\n",
    "                    print(posib)\n",
    "                    \n",
    "                    if len(posib) > 1:\n",
    "                        sinonimos_t = posib\n",
    "                    else:\n",
    "                        sem_sin = True\n",
    "                    \n",
    "                if not sem_sin:\n",
    "                    for sin in sinonimos_t:\n",
    "                        for y in range(0, len(df_CIPE_norm)):\n",
    "                            num = levenshtein(str(sin), df_CIPE_norm.at[y, 'Termo'])\n",
    "                            perc = 100 - num / len(df_CIPE_norm.at[y, 'Termo']) * 100\n",
    "                            if perc > perc_max:\n",
    "                                perc_max = perc\n",
    "                                candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                metodo = 12\n",
    "                                y_aux = y\n",
    "                            if perc_max == 100:\n",
    "                                metodo = 12\n",
    "                                break\n",
    "                        if not perc_max == 100:\n",
    "                            for y in range(0, len(df_CIPE_norm)):\n",
    "                                num = levenshtein(lematizador(str(sin)), df_CIPE_lemma.at[y, 'Termo'])\n",
    "                                perc = 100 - num / len(df_CIPE_lemma.at[y, 'Termo']) * 100\n",
    "                                if perc > perc_max:\n",
    "                                    perc_max = perc\n",
    "                                    candidato = df_CIPE_lemma.at[y, 'Termo']\n",
    "                                    metodo = 22\n",
    "                                    y_aux = y\n",
    "                                elif perc == 100 and perc_max == 100:\n",
    "                                    df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                    df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                    df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                    df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                    df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                    df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                    df_termos_match.at[zz, 'Regra'] = 22\n",
    "                                    df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                    zz += 1\n",
    "                                    perc_max = perc\n",
    "                                    candidato = df_CIPE_lemma.at[y, 'Termo']\n",
    "                                    metodo = 22\n",
    "                                    y_aux = y\n",
    "                            if not perc_max == 100:\n",
    "                                for y in range(0, len(df_CIPE_norm)):\n",
    "                                    num = levenshtein(stemmer(str(sin)), df_CIPE_stem.at[y, 'Termo'])\n",
    "                                    perc = 100 - num / len(df_CIPE_stem.at[y, 'Termo']) * 100\n",
    "                                    if perc > perc_max:\n",
    "                                        perc_max = perc\n",
    "                                        candidato = df_CIPE_stem.at[y, 'Termo']\n",
    "                                        metodo = 32\n",
    "                                        y_aux = y\n",
    "                                    elif perc == 100 and perc_max == 100:\n",
    "                                        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                        df_termos_match.at[zz, 'Regra'] = 32\n",
    "                                        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                        zz += 1\n",
    "                                        perc_max = perc\n",
    "                                        candidato = df_CIPE_lemma.at[y, 'Termo']\n",
    "                                        metodo = 32\n",
    "                                        y_aux = y\n",
    "                    if metodo == 12 and perc_max >= 90:\n",
    "                        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                        df_termos_match.at[zz, 'Regra'] = 12\n",
    "                        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                        zz += 1\n",
    "                    elif metodo == 22 and perc_max >= 90:\n",
    "                        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                        df_termos_match.at[zz, 'Regra'] = 22\n",
    "                        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                        zz += 1\n",
    "                    elif metodo == 32 and perc_max >= 90:\n",
    "                        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                        df_termos_match.at[zz, 'Regra'] = 32\n",
    "                        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                        zz += 1\n",
    "                #if not (metodo == 12 or metodo == 22 or metodo == 32):\n",
    "                if not (metodo == 122 or metodo == 222 or metodo == 322):\n",
    "                    perc_max = 0\n",
    "                    words = df_termos_norm.at[x, 'Termos'].split()\n",
    "                    if len(words) > 1:\n",
    "                        for y in range(0, len(df_CIPE_norm)):\n",
    "                            word_comp = df_CIPE_norm.at[y, 'Termo'].split()\n",
    "                            med_perc = 0\n",
    "                            if len(words) < len(word_comp):\n",
    "                                subString = True\n",
    "                                for p in words:\n",
    "                                    tem_word = False\n",
    "                                    for p_comp in word_comp:\n",
    "                                        num = levenshtein(p, p_comp)\n",
    "                                        perc = 100 - num / len(p_comp) * 100\n",
    "                                        if perc > 90:\n",
    "                                            med_perc += perc\n",
    "                                            tem_word = True\n",
    "                                            break\n",
    "                                    if not tem_word:\n",
    "                                        subString = False\n",
    "                                if subString:\n",
    "                                    perc_max = med_perc / len(words)\n",
    "                                    candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                    metodo = 51\n",
    "                                    y_aux = y\n",
    "                                    df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                    df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                    df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                    df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                    df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                    df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                    df_termos_match.at[zz, 'Regra'] = 51\n",
    "                                    df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                    zz += 1\n",
    "                            elif len(words) > len(word_comp):\n",
    "                                supString = True\n",
    "                                for p in word_comp:\n",
    "                                    tem_word = False\n",
    "                                    for p_comp in words:\n",
    "                                        num = levenshtein(p, p_comp)\n",
    "                                        perc = 100 - num / len(p_comp) * 100\n",
    "                                        if perc > 90:\n",
    "                                            med_perc += perc\n",
    "                                            tem_word = True\n",
    "                                            break\n",
    "                                    if not tem_word:\n",
    "                                        supString = False\n",
    "                                if supString:\n",
    "                                    perc_max = med_perc / len(word_comp)\n",
    "                                    candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                    metodo = 61\n",
    "                                    y_aux = y\n",
    "                                    df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                    df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                    df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                    df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                    df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                    df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                    df_termos_match.at[zz, 'Regra'] = 61\n",
    "                                    df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                    zz += 1\n",
    "                    elif len(words) == 1:\n",
    "                        for y in range(0, len(df_CIPE_norm)):\n",
    "                            word_comp = df_CIPE_norm.at[y, 'Termo'].split()\n",
    "                            med_perc = 0\n",
    "                            if len(words) < len(word_comp):\n",
    "                                subString = True\n",
    "                                for p in words:\n",
    "                                    tem_word = False\n",
    "                                    for p_comp in word_comp:\n",
    "                                        num = levenshtein(p, p_comp)\n",
    "                                        perc = 100 - num / len(p_comp) * 100\n",
    "                                        if perc > 90:\n",
    "                                            med_perc += perc\n",
    "                                            tem_word = True\n",
    "                                            break\n",
    "                                    if not tem_word:\n",
    "                                        subString = False\n",
    "                                if subString:\n",
    "                                    perc_max = med_perc / len(words)\n",
    "                                    candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                    metodo = 51\n",
    "                                    y_aux = y\n",
    "                                    df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                    df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                    df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                    df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                    df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                    df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                    df_termos_match.at[zz, 'Regra'] = 51\n",
    "                                    df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                    zz += 1\n",
    "                    if not (metodo == 51 or metodo == 61):\n",
    "                        words = df_termos_lemma.at[x, 'Termos'].split()\n",
    "                        if len(words) > 1:\n",
    "                            for y in range(0, len(df_CIPE_norm)):\n",
    "                                word_comp = df_CIPE_lemma.at[y, 'Termo'].split()\n",
    "                                med_perc = 0\n",
    "                                if len(words) < len(word_comp):\n",
    "                                    subString = True\n",
    "                                    for p in words:\n",
    "                                        tem_word = False\n",
    "                                        for p_comp in word_comp:\n",
    "                                            num = levenshtein(p, p_comp)\n",
    "                                            perc = 100 - num / len(p_comp) * 100\n",
    "                                            if perc > 90:\n",
    "                                                med_perc += perc\n",
    "                                                tem_word = True\n",
    "                                                break\n",
    "                                        if not tem_word:\n",
    "                                            subString = False\n",
    "                                    if subString:\n",
    "                                        perc_max = med_perc / len(words)\n",
    "                                        candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                        metodo = 52\n",
    "                                        y_aux = y\n",
    "                                        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                        df_termos_match.at[zz, 'Regra'] = 52\n",
    "                                        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                        zz += 1\n",
    "                                elif len(words) > len(word_comp):\n",
    "                                    supString = True\n",
    "                                    for p in word_comp:\n",
    "                                        tem_word = False\n",
    "                                        for p_comp in words:\n",
    "                                            num = levenshtein(p, p_comp)\n",
    "                                            perc = 100 - num / len(p_comp) * 100\n",
    "                                            if perc > 90:\n",
    "                                                med_perc += perc\n",
    "                                                tem_word = True\n",
    "                                                break\n",
    "                                        if not tem_word:\n",
    "                                            supString = False\n",
    "                                    if supString:\n",
    "                                        perc_max = med_perc / len(word_comp)\n",
    "                                        candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                        metodo = 62\n",
    "                                        y_aux = y\n",
    "                                        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                        df_termos_match.at[zz, 'Regra'] = 62\n",
    "                                        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                        zz += 1\n",
    "                        elif len(words) == 1:\n",
    "                            for y in range(0, len(df_CIPE_norm)):\n",
    "                                word_comp = df_CIPE_lemma.at[y, 'Termo'].split()\n",
    "                                med_perc = 0\n",
    "                                if len(words) < len(word_comp):\n",
    "                                    subString = True\n",
    "                                    for p in words:\n",
    "                                        tem_word = False\n",
    "                                        for p_comp in word_comp:\n",
    "                                            num = levenshtein(p, p_comp)\n",
    "                                            perc = 100 - num / len(p_comp) * 100\n",
    "                                            if perc > 90:\n",
    "                                                med_perc += perc\n",
    "                                                tem_word = True\n",
    "                                                break\n",
    "                                        if not tem_word:\n",
    "                                            subString = False\n",
    "                                    if subString:\n",
    "                                        perc_max = med_perc / len(words)\n",
    "                                        candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                        metodo = 52\n",
    "                                        y_aux = y\n",
    "                                        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                        df_termos_match.at[zz, 'Regra'] = 52\n",
    "                                        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                        zz += 1\n",
    "                        if not (metodo == 52 or metodo == 62):\n",
    "                            words = df_termos_stem.at[x, 'Termos'].split()\n",
    "                            if len(words) > 1:\n",
    "                                for y in range(0, len(df_CIPE_norm)):\n",
    "                                    word_comp = df_CIPE_stem.at[y, 'Termo'].split()\n",
    "                                    med_perc = 0\n",
    "                                    if len(words) < len(word_comp):\n",
    "                                        subString = True\n",
    "                                        for p in words:\n",
    "                                            tem_word = False\n",
    "                                            for p_comp in word_comp:\n",
    "                                                num = levenshtein(p, p_comp)\n",
    "                                                perc = 100 - num / len(p_comp) * 100\n",
    "                                                if perc > 90:\n",
    "                                                    med_perc += perc\n",
    "                                                    tem_word = True\n",
    "                                                    break\n",
    "                                            if not tem_word:\n",
    "                                                subString = False\n",
    "                                        if subString:\n",
    "                                            perc_max = med_perc / len(words)\n",
    "                                            candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                            metodo = 53\n",
    "                                            y_aux = y\n",
    "                                            df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                            df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                            df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                            df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                            df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                            df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                            df_termos_match.at[zz, 'Regra'] = 53\n",
    "                                            df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                            zz += 1\n",
    "                                    elif len(words) > len(word_comp):\n",
    "                                        supString = True\n",
    "                                        for p in word_comp:\n",
    "                                            tem_word = False\n",
    "                                            for p_comp in words:\n",
    "                                                num = levenshtein(p, p_comp)\n",
    "                                                perc = 100 - num / len(p_comp) * 100\n",
    "                                                if perc > 90:\n",
    "                                                    med_perc += perc\n",
    "                                                    tem_word = True\n",
    "                                                    break\n",
    "                                            if not tem_word:\n",
    "                                                supString = False\n",
    "                                        if supString:\n",
    "                                            perc_max = med_perc / len(word_comp)\n",
    "                                            candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                            metodo = 63\n",
    "                                            y_aux = y\n",
    "                                            df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                            df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                            df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                            df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                            df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                            df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                            df_termos_match.at[zz, 'Regra'] = 63\n",
    "                                            df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                            zz += 1\n",
    "                            elif len(words) == 1:\n",
    "                                for y in range(0, len(df_CIPE_norm)):\n",
    "                                    word_comp = df_CIPE_stem.at[y, 'Termo'].split()\n",
    "                                    med_perc = 0\n",
    "                                    if len(words) < len(word_comp):\n",
    "                                        subString = True\n",
    "                                        for p in words:\n",
    "                                            tem_word = False\n",
    "                                            for p_comp in word_comp:\n",
    "                                                num = levenshtein(p, p_comp)\n",
    "                                                perc = 100 - num / len(p_comp) * 100\n",
    "                                                if perc > 90:\n",
    "                                                    med_perc += perc\n",
    "                                                    tem_word = True\n",
    "                                                    break\n",
    "                                            if not tem_word:\n",
    "                                                subString = False\n",
    "                                        if subString:\n",
    "                                            perc_max = med_perc / len(words)\n",
    "                                            candidato = df_CIPE_norm.at[y, 'Termo']\n",
    "                                            metodo = 53\n",
    "                                            y_aux = y\n",
    "                                            df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "                                            df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "                                            df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "                                            df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "                                            df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "                                            df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "                                            df_termos_match.at[zz, 'Regra'] = 53\n",
    "                                            df_termos_match.at[zz, 'perc'] = perc_max\n",
    "                                            zz += 1\n",
    "    '''if metodo == 1 and perc_max >= 90:\n",
    "        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "        df_termos_match.at[zz, 'Regra'] = 1\n",
    "        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "        zz += 1\n",
    "    elif metodo == 2 and perc_max >= 90:\n",
    "        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "        df_termos_match.at[zz, 'Regra'] = 2\n",
    "        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "        zz += 1\n",
    "    elif metodo == 3 and perc_max >= 90:\n",
    "        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "        df_termos_match.at[zz, 'ICNPcode'] = df_CIPE.at[y_aux, 'Código']\n",
    "        df_termos_match.at[zz, 'ICNPterm'] = df_CIPE.at[y_aux, 'Termo']\n",
    "        df_termos_match.at[zz, 'ICNPmod'] = candidato\n",
    "        df_termos_match.at[zz, 'ICNPVersao'] = df_CIPE.at[y_aux, 'Versão']\n",
    "        df_termos_match.at[zz, 'ICNPeixo'] = df_CIPE.at[y_aux, 'Eixo']\n",
    "        df_termos_match.at[zz, 'Regra'] = 3\n",
    "        df_termos_match.at[zz, 'perc'] = perc_max\n",
    "        zz += 1\n",
    "    elif not (metodo == 51 or metodo == 61 or metodo == 52 or metodo == 62 or metodo == 53 or metodo == 63\n",
    "              or metodo == 12 or metodo == 22 or metodo == 32):\n",
    "        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "        df_termos_match.at[zz, 'Regra'] = 0\n",
    "        df_termos_match.at[zz, 'perc'] = 0\n",
    "        df_termos_match.at[zz, 'ICNPcode'] = ''\n",
    "        df_termos_match.at[zz, 'ICNPterm'] = ''\n",
    "        df_termos_match.at[zz, 'ICNPVersao'] = ''\n",
    "        df_termos_match.at[zz, 'ICNPeixo'] = ''\n",
    "        df_termos_match.at[zz, 'numICNP'] = 0\n",
    "        zz += 1\n",
    "    else:\n",
    "        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "        df_termos_match.at[zz, 'Regra'] = 0\n",
    "        df_termos_match.at[zz, 'perc'] = 0\n",
    "        df_termos_match.at[zz, 'ICNPcode'] = ''\n",
    "        df_termos_match.at[zz, 'ICNPterm'] = ''\n",
    "        df_termos_match.at[zz, 'ICNPVersao'] = ''\n",
    "        df_termos_match.at[zz, 'ICNPeixo'] = ''\n",
    "        df_termos_match.at[zz, 'numICNP'] = 0\n",
    "        zz += 1'''\n",
    "    if perc_max < 90:\n",
    "        df_termos_match.at[zz, 'Termos'] = df_termos.at[x, 'Termos']\n",
    "        df_termos_match.at[zz, 'Regra'] = 0\n",
    "        df_termos_match.at[zz, 'perc'] = 0\n",
    "        df_termos_match.at[zz, 'ICNPcode'] = ''\n",
    "        df_termos_match.at[zz, 'ICNPterm'] = ''\n",
    "        df_termos_match.at[zz, 'ICNPVersao'] = ''\n",
    "        df_termos_match.at[zz, 'ICNPeixo'] = ''\n",
    "        df_termos_match.at[zz, 'numICNP'] = 0\n",
    "        zz += 1\n",
    "    print(df_termos_norm.at[x, 'Termos'], ' tem o par ', candidato, ' com a porcentagem ', perc_max)\n",
    "    perc_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('CliniMap_CIPE_escol_sandra_2.xlsx')\n",
    "df_termos_match.to_excel(writer, 'Match')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742\n",
      "0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(df_termos_norm['Termos'].size)\n",
    "print(achou)\n",
    "print((achou/df_termos_norm['Termos'].size)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termos</th>\n",
       "      <th>Regra</th>\n",
       "      <th>perc</th>\n",
       "      <th>ICNPcode</th>\n",
       "      <th>ICNPterm</th>\n",
       "      <th>ICNPmod</th>\n",
       "      <th>ICNPeixo</th>\n",
       "      <th>ICNPVersao</th>\n",
       "      <th>numICNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abertura corporal</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10003422</td>\n",
       "      <td>abertura corporal</td>\n",
       "      <td>abertura corporal</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abrangência</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abrasão</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absenteísmo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absorver</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>10002641</td>\n",
       "      <td>aspirar</td>\n",
       "      <td>aspirar</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>absorver</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10000289</td>\n",
       "      <td>dispositivo para absorver ou coletar</td>\n",
       "      <td>dispositivo absorver coletar</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abstinência</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10040085</td>\n",
       "      <td>controle do sintoma de abstinência (de afastam...</td>\n",
       "      <td>controle sintoma abstinencia (de afastamento d...</td>\n",
       "      <td>DE/RE</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abstinência</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10039947</td>\n",
       "      <td>sintoma de abstinência (de afastamento ou de r...</td>\n",
       "      <td>sintoma abstinencia (de afastamento de retirad...</td>\n",
       "      <td>DE/RE</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abstinência</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10038718</td>\n",
       "      <td>gerenciar sintoma de abstinência (de afastamen...</td>\n",
       "      <td>gerenciar sintoma abstinencia (de afastamento ...</td>\n",
       "      <td>IE</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abstinência</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10036343</td>\n",
       "      <td>monitorar abstinência (afastamento ou retirada...</td>\n",
       "      <td>monitorar abstinencia (afastamento retirada algo)</td>\n",
       "      <td>IE</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abstinência</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10035433</td>\n",
       "      <td>obter dados sobre abstinência (afastamento ou ...</td>\n",
       "      <td>obter dados sobre abstinencia (afastamento ret...</td>\n",
       "      <td>IE</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abstinência</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10038725</td>\n",
       "      <td>orientar sobre manejo (controle) dos sintomas ...</td>\n",
       "      <td>orientar sobre manejo (controle) sintomas abst...</td>\n",
       "      <td>IE</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abstinência</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10035422</td>\n",
       "      <td>abstinência (afastamento ou retirada de algo)</td>\n",
       "      <td>abstinencia (afastamento retirada algo)</td>\n",
       "      <td>F</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>abstinência</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10040071</td>\n",
       "      <td>controle do sintoma de abstinência (de afastam...</td>\n",
       "      <td>controle sintoma abstinencia (de afastamento d...</td>\n",
       "      <td>F</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abstinência</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10038702</td>\n",
       "      <td>sintoma de abstinência (de afastamento ou de r...</td>\n",
       "      <td>sintoma abstinencia (de afastamento de retirad...</td>\n",
       "      <td>F</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abuso de álcool (ou alcoolismo)</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10022234</td>\n",
       "      <td>abuso de álcool (ou alcoolismo)</td>\n",
       "      <td>abuso alcool (ou alcoolismo)</td>\n",
       "      <td>DE/RE</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abuso de tabaco (ou de fumo)</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10022247</td>\n",
       "      <td>abuso de tabaco (ou de fumo)</td>\n",
       "      <td>abuso tabaco (ou fumo)</td>\n",
       "      <td>DE/RE</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ação</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10000386</td>\n",
       "      <td>ação</td>\n",
       "      <td>acao</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aceitação</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10000329</td>\n",
       "      <td>aceitação</td>\n",
       "      <td>aceitacao</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>acessibilidade</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>acesso</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10000340</td>\n",
       "      <td>acesso</td>\n",
       "      <td>acesso</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ácido</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>acidose</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10032010</td>\n",
       "      <td>acidose metabólica</td>\n",
       "      <td>acidose metabolica</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>acidose</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10032653</td>\n",
       "      <td>acidose respiratória</td>\n",
       "      <td>acidose respiratoria</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>adaptação</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10001741</td>\n",
       "      <td>adaptação</td>\n",
       "      <td>adaptacao</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>adaptação, prejudicada</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10022027</td>\n",
       "      <td>adaptação, prejudicada</td>\n",
       "      <td>adaptacao, prejudicada</td>\n",
       "      <td>DE/RE</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adesão</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10022210</td>\n",
       "      <td>adesão</td>\n",
       "      <td>adesao</td>\n",
       "      <td>DE/RE</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>administração</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>10001773</td>\n",
       "      <td>administrar</td>\n",
       "      <td>administr</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>administração</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>10011625</td>\n",
       "      <td>gerenciar</td>\n",
       "      <td>gerenciar</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>administração</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10024354</td>\n",
       "      <td>demonstrar administração de medicação</td>\n",
       "      <td>demonstrar administracao medicacao</td>\n",
       "      <td>IE</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>vasculogênicas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>vaselina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>vaso sanguíneo</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10003374</td>\n",
       "      <td>vaso sanguíneo</td>\n",
       "      <td>vaso sanguineo</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>vazamento</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>veia</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10020665</td>\n",
       "      <td>veia</td>\n",
       "      <td>veia</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>velocidade</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>venosa</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10027509</td>\n",
       "      <td>risco de trombose venosa profunda</td>\n",
       "      <td>risco trombose venosa profunda</td>\n",
       "      <td>DE/RE</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>venosa</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10036406</td>\n",
       "      <td>trombose venosa profunda, ausente</td>\n",
       "      <td>trombose venosa profunda, ausente</td>\n",
       "      <td>DE/RE</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>venosa</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10030100</td>\n",
       "      <td>úlcera venosa</td>\n",
       "      <td>ulcera venosa</td>\n",
       "      <td>DE/RE</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>venosa</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10016168</td>\n",
       "      <td>punção venosa</td>\n",
       "      <td>puncao venosa</td>\n",
       "      <td>IE</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>venosa</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10027495</td>\n",
       "      <td>trombose venosa profunda</td>\n",
       "      <td>trombose venosa profunda</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>venosa</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10036391</td>\n",
       "      <td>trombose venosa profunda, ausente</td>\n",
       "      <td>trombose venosa profunda, ausente</td>\n",
       "      <td>F</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>venosa</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10020683</td>\n",
       "      <td>úlcera venosa</td>\n",
       "      <td>ulcera venosa</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>venosa</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>10020677</td>\n",
       "      <td>cânula venosa</td>\n",
       "      <td>canula venosa</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>vestir</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10006253</td>\n",
       "      <td>vestir</td>\n",
       "      <td>vestir</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>via cutânea</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10005489</td>\n",
       "      <td>via cutânea</td>\n",
       "      <td>via cutanea</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>via oral</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10013749</td>\n",
       "      <td>via oral</td>\n",
       "      <td>via oral</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>via parenteral</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10014047</td>\n",
       "      <td>via parenteral</td>\n",
       "      <td>via parenteral</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>via tópica</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10033157</td>\n",
       "      <td>via tópica</td>\n",
       "      <td>via topica</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>vínculo</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10003548</td>\n",
       "      <td>vínculo</td>\n",
       "      <td>vinculo</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>visão</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10018124</td>\n",
       "      <td>visão</td>\n",
       "      <td>visao</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>viscosidade</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>vitalidade</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>10032113</td>\n",
       "      <td>monitorar sinais vitais</td>\n",
       "      <td>monitorar sinais vitais</td>\n",
       "      <td>IE</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>vitalidade</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>10020838</td>\n",
       "      <td>papel de sinal vital</td>\n",
       "      <td>papel sinal vital</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>vitalidade</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>10020829</td>\n",
       "      <td>sinal vital</td>\n",
       "      <td>sinal vital</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>vitalidade</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>10008846</td>\n",
       "      <td>sinal vital de frequência cardíaca</td>\n",
       "      <td>sinal vital frequencia cardiaca</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>vontade de viver</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10021113</td>\n",
       "      <td>vontade de viver</td>\n",
       "      <td>vontade viver</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>vulnerabilidade</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>10010311</td>\n",
       "      <td>insegurança</td>\n",
       "      <td>inseguranca</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>vulnerabilidade</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>vulnerabilidade emocional</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1553 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Termos Regra perc  ICNPcode  \\\n",
       "0                   abertura corporal     1  100  10003422   \n",
       "1                         abrangência     0    0             \n",
       "2                             abrasão     0    0             \n",
       "3                         absenteísmo     0    0             \n",
       "4                            absorver    12  100  10002641   \n",
       "5                            absorver    51  100  10000289   \n",
       "6                         abstinência    51  100  10040085   \n",
       "7                         abstinência    51  100  10039947   \n",
       "8                         abstinência    51  100  10038718   \n",
       "9                         abstinência    51  100  10036343   \n",
       "10                        abstinência    51  100  10035433   \n",
       "11                        abstinência    51  100  10038725   \n",
       "12                        abstinência    51  100  10035422   \n",
       "13                        abstinência    51  100  10040071   \n",
       "14                        abstinência    51  100  10038702   \n",
       "15    abuso de álcool (ou alcoolismo)     1  100  10022234   \n",
       "16       abuso de tabaco (ou de fumo)     1  100  10022247   \n",
       "17                               ação     1  100  10000386   \n",
       "18                          aceitação     1  100  10000329   \n",
       "19                     acessibilidade     0    0             \n",
       "20                             acesso     1  100  10000340   \n",
       "21                              ácido     0    0             \n",
       "22                            acidose    51  100  10032010   \n",
       "23                            acidose    51  100  10032653   \n",
       "24                          adaptação     1  100  10001741   \n",
       "25             adaptação, prejudicada     1  100  10022027   \n",
       "26                             adesão     1  100  10022210   \n",
       "27                      administração     3  100  10001773   \n",
       "28                      administração    12  100  10011625   \n",
       "29                      administração    51  100  10024354   \n",
       "...                               ...   ...  ...       ...   \n",
       "1523                   vasculogênicas     0    0             \n",
       "1524                         vaselina     0    0             \n",
       "1525                   vaso sanguíneo     1  100  10003374   \n",
       "1526                        vazamento     0    0             \n",
       "1527                             veia     1  100  10020665   \n",
       "1528                       velocidade     0    0             \n",
       "1529                           venosa    51  100  10027509   \n",
       "1530                           venosa    51  100  10036406   \n",
       "1531                           venosa    51  100  10030100   \n",
       "1532                           venosa    51  100  10016168   \n",
       "1533                           venosa    51  100  10027495   \n",
       "1534                           venosa    51  100  10036391   \n",
       "1535                           venosa    51  100  10020683   \n",
       "1536                           venosa    51  100  10020677   \n",
       "1537                           vestir     1  100  10006253   \n",
       "1538                      via cutânea     1  100  10005489   \n",
       "1539                         via oral     1  100  10013749   \n",
       "1540                   via parenteral     1  100  10014047   \n",
       "1541                      via tópica      1  100  10033157   \n",
       "1542                          vínculo     1  100  10003548   \n",
       "1543                            visão     1  100  10018124   \n",
       "1544                      viscosidade     0    0             \n",
       "1545                       vitalidade    52  100  10032113   \n",
       "1546                       vitalidade    52  100  10020838   \n",
       "1547                       vitalidade    52  100  10020829   \n",
       "1548                       vitalidade    52  100  10008846   \n",
       "1549                 vontade de viver     1  100  10021113   \n",
       "1550                  vulnerabilidade    12  100  10010311   \n",
       "1551                  vulnerabilidade     0    0             \n",
       "1552        vulnerabilidade emocional     0    0             \n",
       "\n",
       "                                               ICNPterm  \\\n",
       "0                                    abertura corporal    \n",
       "1                                                         \n",
       "2                                                         \n",
       "3                                                         \n",
       "4                                              aspirar    \n",
       "5                 dispositivo para absorver ou coletar    \n",
       "6     controle do sintoma de abstinência (de afastam...   \n",
       "7     sintoma de abstinência (de afastamento ou de r...   \n",
       "8     gerenciar sintoma de abstinência (de afastamen...   \n",
       "9     monitorar abstinência (afastamento ou retirada...   \n",
       "10    obter dados sobre abstinência (afastamento ou ...   \n",
       "11    orientar sobre manejo (controle) dos sintomas ...   \n",
       "12       abstinência (afastamento ou retirada de algo)    \n",
       "13    controle do sintoma de abstinência (de afastam...   \n",
       "14    sintoma de abstinência (de afastamento ou de r...   \n",
       "15                     abuso de álcool (ou alcoolismo)    \n",
       "16                        abuso de tabaco (ou de fumo)    \n",
       "17                                                ação    \n",
       "18                                           aceitação    \n",
       "19                                                        \n",
       "20                                              acesso    \n",
       "21                                                        \n",
       "22                                  acidose metabólica    \n",
       "23                                acidose respiratória    \n",
       "24                                           adaptação    \n",
       "25                              adaptação, prejudicada    \n",
       "26                                              adesão    \n",
       "27                                         administrar    \n",
       "28                                           gerenciar    \n",
       "29               demonstrar administração de medicação    \n",
       "...                                                 ...   \n",
       "1523                                                      \n",
       "1524                                                      \n",
       "1525                                    vaso sanguíneo    \n",
       "1526                                                      \n",
       "1527                                              veia    \n",
       "1528                                                      \n",
       "1529                 risco de trombose venosa profunda    \n",
       "1530                 trombose venosa profunda, ausente    \n",
       "1531                                     úlcera venosa    \n",
       "1532                                     punção venosa    \n",
       "1533                          trombose venosa profunda    \n",
       "1534                 trombose venosa profunda, ausente    \n",
       "1535                                     úlcera venosa    \n",
       "1536                                     cânula venosa    \n",
       "1537                                            vestir    \n",
       "1538                                       via cutânea    \n",
       "1539                                          via oral    \n",
       "1540                                    via parenteral    \n",
       "1541                                        via tópica    \n",
       "1542                                           vínculo    \n",
       "1543                                             visão    \n",
       "1544                                                      \n",
       "1545                           monitorar sinais vitais    \n",
       "1546                              papel de sinal vital    \n",
       "1547                                       sinal vital    \n",
       "1548                sinal vital de frequência cardíaca    \n",
       "1549                                 vontade de viver     \n",
       "1550                                       insegurança    \n",
       "1551                                                      \n",
       "1552                                                      \n",
       "\n",
       "                                                ICNPmod ICNPeixo ICNPVersao  \\\n",
       "0                                     abertura corporal       L           1   \n",
       "1                                                   NaN                       \n",
       "2                                                   NaN                       \n",
       "3                                                   NaN                       \n",
       "4                                               aspirar       A           1   \n",
       "5                          dispositivo absorver coletar       M           1   \n",
       "6     controle sintoma abstinencia (de afastamento d...   DE/RE        2013   \n",
       "7     sintoma abstinencia (de afastamento de retirad...   DE/RE        2013   \n",
       "8     gerenciar sintoma abstinencia (de afastamento ...      IE        2013   \n",
       "9     monitorar abstinencia (afastamento retirada algo)      IE        2013   \n",
       "10    obter dados sobre abstinencia (afastamento ret...      IE        2013   \n",
       "11    orientar sobre manejo (controle) sintomas abst...      IE        2013   \n",
       "12              abstinencia (afastamento retirada algo)       F        2013   \n",
       "13    controle sintoma abstinencia (de afastamento d...       F        2013   \n",
       "14    sintoma abstinencia (de afastamento de retirad...       F        2013   \n",
       "15                         abuso alcool (ou alcoolismo)   DE/RE         1.1   \n",
       "16                               abuso tabaco (ou fumo)   DE/RE         1.1   \n",
       "17                                                 acao       A           1   \n",
       "18                                            aceitacao       F           1   \n",
       "19                                                  NaN                       \n",
       "20                                               acesso       F           1   \n",
       "21                                                  NaN                       \n",
       "22                                   acidose metabolica       F           1   \n",
       "23                                 acidose respiratoria       F           1   \n",
       "24                                            adaptacao       F           1   \n",
       "25                               adaptacao, prejudicada   DE/RE         1.1   \n",
       "26                                               adesao   DE/RE         1.1   \n",
       "27                                            administr       A           1   \n",
       "28                                           gerenciar        A           1   \n",
       "29                   demonstrar administracao medicacao      IE         1.1   \n",
       "...                                                 ...      ...        ...   \n",
       "1523                                                NaN                       \n",
       "1524                                                NaN                       \n",
       "1525                                     vaso sanguineo       L           1   \n",
       "1526                                                NaN                       \n",
       "1527                                               veia       L           1   \n",
       "1528                                                NaN                       \n",
       "1529                     risco trombose venosa profunda   DE/RE           2   \n",
       "1530                  trombose venosa profunda, ausente   DE/RE        2013   \n",
       "1531                                      ulcera venosa   DE/RE           3   \n",
       "1532                                      puncao venosa      IE           1   \n",
       "1533                           trombose venosa profunda       F           2   \n",
       "1534                  trombose venosa profunda, ausente       F        2013   \n",
       "1535                                      ulcera venosa       F           1   \n",
       "1536                                      canula venosa       M           1   \n",
       "1537                                             vestir       A           1   \n",
       "1538                                        via cutanea       L           1   \n",
       "1539                                           via oral       L           1   \n",
       "1540                                     via parenteral       L           1   \n",
       "1541                                         via topica       L           3   \n",
       "1542                                            vinculo       F           1   \n",
       "1543                                              visao       F           1   \n",
       "1544                                                NaN                       \n",
       "1545                            monitorar sinais vitais      IE           3   \n",
       "1546                                  papel sinal vital       F           1   \n",
       "1547                                        sinal vital       F           1   \n",
       "1548                    sinal vital frequencia cardiaca       F           1   \n",
       "1549                                      vontade viver       F           1   \n",
       "1550                                        inseguranca       F           1   \n",
       "1551                                                NaN                       \n",
       "1552                                                NaN                       \n",
       "\n",
       "      numICNP  \n",
       "0         NaN  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         NaN  \n",
       "5         NaN  \n",
       "6         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "9         NaN  \n",
       "10        NaN  \n",
       "11        NaN  \n",
       "12        NaN  \n",
       "13        NaN  \n",
       "14        NaN  \n",
       "15        NaN  \n",
       "16        NaN  \n",
       "17        NaN  \n",
       "18        NaN  \n",
       "19        0.0  \n",
       "20        NaN  \n",
       "21        0.0  \n",
       "22        NaN  \n",
       "23        NaN  \n",
       "24        NaN  \n",
       "25        NaN  \n",
       "26        NaN  \n",
       "27        NaN  \n",
       "28        NaN  \n",
       "29        NaN  \n",
       "...       ...  \n",
       "1523      0.0  \n",
       "1524      0.0  \n",
       "1525      NaN  \n",
       "1526      0.0  \n",
       "1527      NaN  \n",
       "1528      0.0  \n",
       "1529      NaN  \n",
       "1530      NaN  \n",
       "1531      NaN  \n",
       "1532      NaN  \n",
       "1533      NaN  \n",
       "1534      NaN  \n",
       "1535      NaN  \n",
       "1536      NaN  \n",
       "1537      NaN  \n",
       "1538      NaN  \n",
       "1539      NaN  \n",
       "1540      NaN  \n",
       "1541      NaN  \n",
       "1542      NaN  \n",
       "1543      NaN  \n",
       "1544      0.0  \n",
       "1545      NaN  \n",
       "1546      NaN  \n",
       "1547      NaN  \n",
       "1548      NaN  \n",
       "1549      NaN  \n",
       "1550      NaN  \n",
       "1551      0.0  \n",
       "1552      0.0  \n",
       "\n",
       "[1553 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_termos_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from translate_api.translate_api import api\n",
    "from numpy import *\n",
    "import unidecode\n",
    "import snowballstemmer\n",
    "from hunspell import Hunspell\n",
    "import numpy as np\n",
    "from dicio import Dicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removearticles(text):\n",
    "    text = re.sub('\"','',text)\n",
    "    #text = re.sub('^(\\s*)(de|do|dos|da|das|o|os|a|as|com|para|pra|e|ou|na|nas|no|nos|ao|aos|em|mg|ml)(\\s+)','',text)\n",
    "    return re.sub('((^\\s*)|(\\s+))(de|do|dos|da|das|o|os|a|as|com|para|pra|e|ou|na|nas|no|nos|ao|aos|em|mg|ml)(($\\s*)|(\\s+))', ' ', text)\n",
    "\n",
    "def tem_num(s):\n",
    "    return bool(re.match('.*\\d.*', s))\n",
    "\n",
    "def lematizador(text):\n",
    "    auxt = str('')\n",
    "    words = text.split()\n",
    "    for x in words:\n",
    "        if h.spell(x):\n",
    "            if len(h.stem(x)) != 0:\n",
    "                auxt += h.stem(x)[0] + ' '\n",
    "            else:\n",
    "                auxt += x + ' '\n",
    "        else:\n",
    "            auxt += x + ' '\n",
    "    auxt.strip()\n",
    "    return auxt\n",
    "\n",
    "def stemmer(text):\n",
    "    stemmer = snowballstemmer.stemmer('portuguese')\n",
    "    return ' '.join(stemmer.stemWords(text.split())).strip()\n",
    "\n",
    "def comb(lis, dict_lis):\n",
    "    aux = []\n",
    "    for s in lis:\n",
    "        for ss in dict_lis:\n",
    "            aux.append(s+' '+ss)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Hunspell('pt_BR', hunspell_data_dir='pt_BR')\n",
    "\n",
    "read = pd.ExcelFile('procedim.xlsx')\n",
    "df_termos = read.parse('Planilha1')\n",
    "\n",
    "cnx = pymysql.connect(user='root', password='1234',database='annotationtool')\n",
    "cursor = cnx.cursor()\n",
    "sqlstr = (\"SELECT id FROM annotationtool.textos where not original_id like 'CAJURU%';\")\n",
    "cursor.execute(sqlstr)\n",
    "ids = []\n",
    "y = 0\n",
    "for (id,) in cursor:\n",
    "    ids.insert(y,id)\n",
    "    y+=1\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9053\n",
      "9128\n",
      "9135\n",
      "9160\n",
      "9162\n",
      "9165\n",
      "9185\n",
      "9186\n",
      "9187\n",
      "9193\n",
      "9228\n",
      "9229\n",
      "9230\n",
      "9231\n",
      "9232\n",
      "9233\n",
      "9234\n",
      "9235\n",
      "9236\n",
      "9237\n",
      "9238\n",
      "9239\n",
      "9240\n",
      "9241\n",
      "9242\n",
      "9243\n",
      "9244\n",
      "9245\n",
      "9246\n",
      "9247\n",
      "9248\n",
      "9249\n",
      "9250\n",
      "9251\n",
      "9252\n",
      "9253\n",
      "9254\n",
      "9255\n",
      "9256\n",
      "9257\n",
      "9258\n",
      "9259\n",
      "9260\n",
      "9262\n",
      "9275\n",
      "9320\n",
      "9321\n",
      "9322\n",
      "9323\n",
      "9324\n",
      "9325\n",
      "9326\n",
      "9327\n",
      "9328\n",
      "9329\n",
      "9330\n",
      "9331\n",
      "9332\n",
      "9333\n",
      "9334\n",
      "9335\n",
      "9336\n",
      "9337\n",
      "9338\n",
      "9339\n",
      "9340\n",
      "9341\n",
      "9342\n",
      "9343\n",
      "9344\n",
      "9345\n",
      "9346\n",
      "9347\n",
      "9348\n",
      "9349\n",
      "9350\n",
      "9351\n",
      "9352\n",
      "9353\n",
      "9354\n",
      "9355\n",
      "9356\n",
      "9357\n",
      "9358\n",
      "9359\n",
      "9369\n",
      "9370\n",
      "9371\n",
      "9375\n",
      "9378\n",
      "9383\n",
      "9384\n",
      "9389\n",
      "9390\n",
      "9393\n",
      "9394\n",
      "9395\n",
      "9397\n",
      "9400\n",
      "9401\n",
      "9404\n",
      "9405\n",
      "9406\n",
      "9408\n",
      "9410\n",
      "9411\n",
      "9412\n",
      "9413\n",
      "9414\n",
      "9415\n",
      "9416\n",
      "9417\n",
      "9418\n",
      "9419\n",
      "9420\n",
      "9421\n",
      "9422\n",
      "9424\n",
      "9425\n",
      "9426\n",
      "9428\n",
      "9430\n",
      "9431\n",
      "9432\n",
      "9436\n",
      "9437\n",
      "9438\n",
      "9439\n",
      "9440\n",
      "9441\n",
      "9444\n",
      "9445\n",
      "9451\n",
      "9453\n",
      "9454\n",
      "9455\n",
      "9456\n",
      "9457\n",
      "9460\n",
      "9461\n",
      "9462\n",
      "9463\n",
      "9465\n",
      "9466\n",
      "9467\n",
      "9468\n",
      "9469\n",
      "9472\n",
      "9474\n",
      "9475\n",
      "9476\n",
      "9477\n",
      "9478\n",
      "9481\n",
      "9482\n",
      "9484\n",
      "9485\n",
      "9486\n",
      "9491\n",
      "9492\n",
      "9494\n",
      "9496\n",
      "9497\n",
      "9498\n",
      "9499\n",
      "9500\n",
      "9501\n",
      "9502\n",
      "9504\n",
      "9506\n",
      "9507\n",
      "9508\n",
      "9509\n",
      "9510\n",
      "9511\n",
      "9512\n",
      "9513\n",
      "9514\n",
      "9515\n",
      "9516\n",
      "9517\n",
      "9518\n",
      "9519\n",
      "9520\n",
      "9521\n",
      "9522\n",
      "9523\n",
      "9524\n",
      "9525\n",
      "9526\n",
      "9527\n",
      "9528\n",
      "9529\n",
      "9530\n",
      "9531\n",
      "9532\n",
      "9533\n",
      "9534\n",
      "9535\n",
      "9536\n",
      "9537\n",
      "9538\n",
      "9539\n",
      "9540\n",
      "9541\n",
      "9542\n",
      "9543\n",
      "9544\n",
      "9545\n",
      "9546\n",
      "9547\n",
      "9548\n",
      "9549\n",
      "9550\n",
      "9551\n",
      "9552\n",
      "9553\n",
      "9554\n",
      "9555\n",
      "9556\n",
      "9557\n",
      "9558\n",
      "9559\n",
      "9560\n",
      "9561\n",
      "9562\n",
      "9563\n",
      "9564\n",
      "9565\n",
      "9566\n",
      "9567\n",
      "9568\n",
      "9569\n",
      "9570\n",
      "9571\n",
      "9572\n",
      "9573\n",
      "9574\n",
      "9575\n",
      "9576\n",
      "9577\n",
      "9578\n",
      "9579\n",
      "9580\n",
      "9581\n",
      "9582\n",
      "9583\n",
      "9584\n",
      "9585\n",
      "9586\n",
      "9587\n",
      "9588\n",
      "9589\n",
      "9590\n",
      "9591\n",
      "9592\n",
      "9593\n",
      "9594\n",
      "9595\n",
      "9596\n",
      "9597\n",
      "9598\n",
      "9599\n",
      "9600\n",
      "9601\n",
      "9602\n",
      "9603\n",
      "9604\n",
      "9605\n",
      "9606\n",
      "9607\n",
      "9608\n",
      "9609\n",
      "9610\n",
      "9611\n",
      "9612\n",
      "9613\n",
      "9614\n",
      "9615\n",
      "9616\n",
      "9617\n",
      "9618\n",
      "9619\n",
      "9620\n",
      "9621\n",
      "9622\n",
      "9623\n",
      "9624\n",
      "9625\n",
      "9626\n",
      "9627\n",
      "9628\n",
      "9629\n",
      "9630\n",
      "9631\n",
      "9632\n",
      "9633\n",
      "9634\n",
      "9635\n",
      "9636\n",
      "9637\n",
      "9638\n",
      "9639\n",
      "9640\n",
      "9641\n",
      "9642\n",
      "9643\n",
      "9644\n",
      "9645\n",
      "9646\n",
      "9647\n",
      "9648\n",
      "9649\n",
      "9650\n",
      "9651\n",
      "9652\n",
      "9653\n",
      "9654\n",
      "9655\n",
      "9656\n",
      "9657\n",
      "9658\n",
      "9659\n",
      "9660\n",
      "9661\n",
      "9662\n",
      "9663\n",
      "9664\n",
      "9665\n",
      "9666\n",
      "9667\n",
      "9668\n",
      "9669\n",
      "9670\n",
      "9671\n",
      "9672\n",
      "9673\n",
      "9674\n",
      "9675\n",
      "9676\n",
      "9677\n",
      "9678\n",
      "9679\n",
      "9680\n",
      "9681\n",
      "9682\n",
      "9683\n",
      "9684\n",
      "9685\n",
      "9686\n",
      "9687\n",
      "9688\n",
      "9689\n",
      "9690\n",
      "9691\n",
      "9692\n",
      "9693\n",
      "9694\n",
      "9695\n",
      "9696\n",
      "9697\n",
      "9698\n",
      "9699\n",
      "9700\n",
      "9701\n",
      "9702\n",
      "9703\n",
      "9704\n",
      "9705\n",
      "9706\n",
      "9707\n",
      "9708\n",
      "9709\n",
      "9710\n",
      "9711\n",
      "9712\n",
      "9713\n",
      "9714\n",
      "9715\n",
      "9716\n",
      "9717\n",
      "9718\n",
      "9719\n",
      "9720\n",
      "9721\n",
      "9722\n",
      "9723\n",
      "9724\n",
      "9725\n",
      "9726\n",
      "9727\n",
      "9728\n",
      "9729\n",
      "9730\n",
      "9731\n",
      "9732\n",
      "9733\n",
      "9734\n",
      "9735\n",
      "9736\n",
      "9737\n",
      "9738\n",
      "9739\n",
      "9740\n",
      "9741\n",
      "9742\n",
      "9743\n",
      "9744\n",
      "9745\n",
      "9746\n",
      "9747\n",
      "9748\n",
      "9749\n",
      "9750\n",
      "9751\n",
      "9752\n",
      "9753\n",
      "9754\n",
      "9755\n",
      "9756\n",
      "9757\n",
      "9758\n",
      "9759\n",
      "9760\n",
      "9761\n",
      "9762\n",
      "9763\n",
      "9764\n",
      "9765\n",
      "9766\n",
      "9767\n",
      "9768\n",
      "9769\n",
      "9770\n",
      "9771\n",
      "9772\n",
      "9773\n",
      "9774\n",
      "9775\n",
      "9776\n",
      "9777\n",
      "9778\n",
      "9779\n",
      "9780\n",
      "9781\n",
      "9782\n",
      "9783\n",
      "9784\n",
      "9785\n",
      "9786\n",
      "9787\n",
      "9788\n",
      "9789\n",
      "9825\n",
      "9826\n",
      "9827\n",
      "9828\n",
      "9829\n",
      "9830\n",
      "9831\n",
      "9832\n",
      "9833\n",
      "9834\n",
      "9835\n",
      "9836\n",
      "9837\n",
      "9838\n",
      "9839\n",
      "9840\n",
      "9841\n",
      "9842\n",
      "9843\n",
      "9844\n",
      "9845\n",
      "9846\n",
      "9847\n",
      "9848\n",
      "9849\n",
      "9850\n",
      "9851\n",
      "9852\n",
      "9853\n",
      "9854\n",
      "9855\n",
      "9856\n",
      "9857\n",
      "9858\n",
      "9859\n",
      "9860\n",
      "9861\n",
      "9862\n",
      "9863\n",
      "9864\n",
      "9865\n",
      "9866\n",
      "9867\n",
      "9868\n",
      "9869\n",
      "9870\n",
      "9871\n",
      "9872\n",
      "9873\n",
      "9874\n",
      "9875\n",
      "9876\n",
      "9877\n",
      "9878\n",
      "9879\n",
      "9880\n",
      "9881\n",
      "9882\n",
      "9883\n",
      "9884\n",
      "9885\n",
      "9886\n",
      "9887\n",
      "9888\n",
      "9889\n",
      "9890\n",
      "9891\n",
      "9892\n",
      "9893\n",
      "9894\n",
      "9895\n",
      "9896\n",
      "9897\n",
      "9898\n",
      "9899\n",
      "9900\n",
      "9901\n",
      "9902\n",
      "9903\n",
      "9904\n",
      "9905\n",
      "9906\n",
      "9907\n",
      "9908\n",
      "9909\n",
      "9910\n",
      "9911\n",
      "9912\n",
      "9913\n",
      "9914\n",
      "9915\n",
      "9916\n",
      "9917\n",
      "9918\n",
      "9919\n",
      "9920\n",
      "9921\n",
      "9922\n",
      "9923\n",
      "9924\n",
      "9925\n",
      "9926\n",
      "9927\n",
      "9928\n",
      "9929\n"
     ]
    }
   ],
   "source": [
    "termos_compostos = pd.DataFrame(data=None, columns=['texto_id','Termos','termo_norm','tk_id','tag','termoComposto_id','abreviatura','umlsCUI'])\n",
    "cnx = pymysql.connect(user='root', password='1234',database='annotationtool')\n",
    "cursor = cnx.cursor()\n",
    "z = 0\n",
    "for id_aux in ids:\n",
    "    if id_aux < 9930:\n",
    "        print(id_aux)\n",
    "        continue\n",
    "    sqlstr = (\"SELECT \"\n",
    "              \"\ta.*, \"\n",
    "              \"\tGROUP_CONCAT(token_id ORDER BY token_id ASC SEPARATOR ',') as token_ids, \"\n",
    "              \"\tGROUP_CONCAT(tk.token ORDER BY token_id ASC SEPARATOR ' ') as token_name, \"\n",
    "              \"\ttg.tag \"\n",
    "              \"FROM \"\n",
    "              \"\tanotacoes a \"\n",
    "              \"INNER JOIN tokens tk ON (a.token_id = tk.id) \"\n",
    "              \"INNER JOIN sentencas s ON (tk.sentenca_id = s.id) \"\n",
    "              \"INNER JOIN tags tg ON (a.tag_id = tg.id) \"\n",
    "              \"WHERE \"\n",
    "              \"\ts.texto_id = %s AND a.adjudicador =  1 AND termocomposto_id IS NOT NULL \"\n",
    "              \"GROUP BY \"\n",
    "              \"\ttermocomposto_id, tag_id\")\n",
    "    cursor.execute(sqlstr, str(id_aux))\n",
    "    token_ids_aux = []\n",
    "    token_name_aux = []\n",
    "    tag_aux = []\n",
    "    termocomposto_id_aux = []\n",
    "    abreviatura_aux = []\n",
    "    umlscui_aux = []\n",
    "    y = 0\n",
    "    for (id, tag_id, token_id, anotador_id, termocomposto_id, status, adjudicador, \n",
    "         dataanotacao, abreviatura, umlscui, snomedctid, token_ids, token_name, tag) in cursor:\n",
    "        token_ids_aux.insert(y,token_ids)\n",
    "        token_name_aux.insert(y,token_name)\n",
    "        tag_aux.insert(y,tag)\n",
    "        termocomposto_id_aux.insert(y,termocomposto_id)\n",
    "        abreviatura_aux.insert(y,abreviatura)\n",
    "        umlscui_aux.insert(y,umlscui)\n",
    "        y+=1\n",
    "    for i in range(0,len(token_ids_aux)):\n",
    "        if tem_num(token_name_aux[i]):\n",
    "            continue\n",
    "        term_norm = removearticles(unidecode.unidecode(str(token_name_aux[i]))).strip()\n",
    "        locTerm = termos_compostos.loc[termos_compostos['termo_norm'] == term_norm]\n",
    "        if locTerm['termo_norm'].empty:\n",
    "            termos_compostos.at[z,'texto_id'] = id_aux\n",
    "            termos_compostos.at[z,'Termos'] = token_name_aux[i]\n",
    "            termos_compostos.at[z,'termo_norm'] = term_norm\n",
    "            termos_compostos.at[z,'tk_id'] = token_ids_aux[i]\n",
    "            termos_compostos.at[z,'tag'] = tag_aux[i]\n",
    "            termos_compostos.at[z,'termoComposto_id'] = termocomposto_id_aux[i]\n",
    "            termos_compostos.at[z,'abreviatura'] = abreviatura_aux[i]\n",
    "            termos_compostos.at[z,'umlsCUI'] = umlscui_aux[i]\n",
    "            z+=1\n",
    "        else:\n",
    "            if tag_aux[i] == \"Abbreviation\":\n",
    "                termos_compostos.at[locTerm.index[0],'abreviatura'] = abreviatura_aux[i]\n",
    "                termos_compostos.at[locTerm.index[0],'Termos'] = abreviatura_aux[i]\n",
    "            if locTerm.at[locTerm.index[0],'termoComposto_id'] == termocomposto_id_aux[i]:\n",
    "                tags = locTerm.at[locTerm.index[0],'tag'].split(';')\n",
    "                tags_aux = tags\n",
    "                tag_str = ''\n",
    "                First = True\n",
    "                for t in tags:\n",
    "                    if t != tag_aux[i]:\n",
    "                        tags_aux.append(tag_aux[i])\n",
    "                for tg in tags_aux:\n",
    "                    if First:\n",
    "                        tag_str += tg\n",
    "                        First = False\n",
    "                    else:\n",
    "                        tag_str += ';' + tg\n",
    "                termos_compostos.at[locTerm.index[0],'tag'] = tag_str\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termo:  AO\n",
      "abreviatura:  None\n",
      "termo:  BARIÁTRICA\n",
      "abreviatura:  None\n",
      "termo:  BARIÁTRICA\n",
      "abreviatura:  None\n",
      "termo:  BARIÁTRICA\n",
      "abreviatura:  None\n",
      "termo:  PCTE\n",
      "abreviatura:  None\n",
      "termo:  exame físico\n",
      "abreviatura:  exame físico\n",
      "termo:  PCTE\n",
      "abreviatura:  None\n",
      "termo:  QP\n",
      "abreviatura:  None\n",
      "termo:  paciente\n",
      "abreviatura:  paciente\n",
      "termo:  exame físico\n",
      "abreviatura:  None\n",
      "termo:  escala de expressões faciais\n",
      "abreviatura:  escala de expressões faciais\n",
      "termo:  coronária direita\n",
      "abreviatura:  coronária direita\n"
     ]
    }
   ],
   "source": [
    "termos_simples = pd.DataFrame(data=None, columns=['texto_id','Termos','termo_norm','tk_id','tag','termoComposto_id','abreviatura','umlsCUI'])\n",
    "cnx = pymysql.connect(user='root', password='1234',database='annotationtool')\n",
    "cursor = cnx.cursor()\n",
    "cursor2 = cnx.cursor()\n",
    "z = 0\n",
    "for id_aux in ids:\n",
    "    if int(id_aux) < 9930:\n",
    "        continue\n",
    "    sqlstr = (\"SELECT  \"\n",
    "              \"\ta.*, tk.token, tg.tag  \"\n",
    "              \"FROM  \"\n",
    "              \"\tanotacoes a  \"\n",
    "              \"INNER JOIN tokens tk ON (a.token_id = tk.id)  \"\n",
    "              \"INNER JOIN sentencas s ON (tk.sentenca_id = s.id)  \"\n",
    "              \"INNER JOIN tags tg ON (a.tag_id = tg.id)  \"\n",
    "              \"WHERE \"  \n",
    "              \"\ts.texto_id = %s AND a.adjudicador = 1 AND termocomposto_id IS NULL\")\n",
    "    cursor.execute(sqlstr, str(id_aux))\n",
    "    token_id_aux = []\n",
    "    token_name_aux = []\n",
    "    tag_aux = []\n",
    "    termocomposto_id_aux = []\n",
    "    abreviatura_aux = []\n",
    "    umlscui_aux = []\n",
    "    y = 0\n",
    "    for (id, tag_id, token_id, anotador_id, termocomposto_id, status, adjudicador, \n",
    "         dataanotacao, abreviatura, umlscui, snomedctid, token, tag) in cursor:\n",
    "        token_id_aux.insert(y,token_id)\n",
    "        token_name_aux.insert(y,token)\n",
    "        tag_aux.insert(y,tag)\n",
    "        termocomposto_id_aux.insert(y,termocomposto_id)\n",
    "        abreviatura_aux.insert(y,abreviatura)\n",
    "        umlscui_aux.insert(y,umlscui)\n",
    "        y+=1\n",
    "    for i in range(0,len(token_id_aux)):\n",
    "        if tem_num(token_name_aux[i]):\n",
    "            continue\n",
    "        term_norm = removearticles(unidecode.unidecode(str(token_name_aux[i]))).strip()\n",
    "        locTerm = termos_simples.loc[termos_simples['termo_norm'] == term_norm]\n",
    "        if locTerm['termo_norm'].empty:\n",
    "            termos_simples.at[z,'texto_id'] = id_aux\n",
    "            termos_simples.at[z,'Termos'] = token_name_aux[i]\n",
    "            termos_simples.at[z,'termo_norm'] = term_norm\n",
    "            termos_simples.at[z,'tk_id'] = token_id_aux[i]\n",
    "            termos_simples.at[z,'tag'] = tag_aux[i]\n",
    "            termos_simples.at[z,'termoComposto_id'] = termocomposto_id_aux[i]\n",
    "            termos_simples.at[z,'abreviatura'] = abreviatura_aux[i]\n",
    "            termos_simples.at[z,'umlsCUI'] = umlscui_aux[i]\n",
    "            z+=1\n",
    "        else:\n",
    "            if tag_aux[i] == \"Abbreviation\":\n",
    "                termos_simples.at[locTerm.index[0],'abreviatura'] = abreviatura_aux[i]\n",
    "                if termos_simples.at[locTerm.index[0],'abreviatura'] != None:\n",
    "                    termos_simples.at[locTerm.index[0],'Termos'] = abreviatura_aux[i]\n",
    "                else:\n",
    "                    sqlstr2 = (\"SELECT acronimo,expansao FROM annotationtool.acronimos where acronimo=%s;\")\n",
    "                    cursor2.execute(sqlstr2, str(termos_simples.at[locTerm.index[0],'Termos']))\n",
    "                    for (acronimo,expansao) in cursor2:\n",
    "                        termos_simples.at[locTerm.index[0],'abreviatura'] = expansao\n",
    "                        termos_simples.at[locTerm.index[0],'Termos'] = expansao\n",
    "                        break\n",
    "                    print('termo: ',termos_simples.at[locTerm.index[0],'Termos'])\n",
    "                    print('abreviatura: ',termos_simples.at[locTerm.index[0],'abreviatura'])\n",
    "            if locTerm.at[locTerm.index[0],'tk_id'] == token_id_aux[i]:\n",
    "                tags = locTerm.at[locTerm.index[0],'tag'].split(';')\n",
    "                tags_aux = tags\n",
    "                tag_str = ''\n",
    "                First = True\n",
    "                for t in tags:\n",
    "                    if t != tag_aux[i]:\n",
    "                        tags_aux.append(tag_aux[i])\n",
    "                for tg in tags_aux:\n",
    "                    if First:\n",
    "                        tag_str += tg\n",
    "                        First = False\n",
    "                    else:\n",
    "                        tag_str += ';' + tg\n",
    "                termos_simples.at[locTerm.index[0],'tag'] = tag_str\n",
    "cursor2.close()\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLINIMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from translate_api.translate_api import api\n",
    "from numpy import *\n",
    "import unidecode\n",
    "import snowballstemmer\n",
    "from hunspell import Hunspell\n",
    "import numpy as np\n",
    "from dicio import Dicio\n",
    "\n",
    "\n",
    "def levenshtein(source, target):\n",
    "    if len(source) < len(target):\n",
    "        return levenshtein(target, source)\n",
    "\n",
    "    # So now we have len(source) >= len(target).\n",
    "    if len(target) == 0:\n",
    "        return len(source)\n",
    "\n",
    "    # We call tuple() to force strings to be used as sequences\n",
    "    # ('c', 'a', 't', 's') - numpy uses them as values by default.\n",
    "    source = np.array(tuple(source))\n",
    "    target = np.array(tuple(target))\n",
    "\n",
    "    # We use a dynamic programming algorithm, but with the\n",
    "    # added optimization that we only need the last two rows\n",
    "    # of the matrix.\n",
    "    previous_row = np.arange(target.size + 1)\n",
    "    for s in source:\n",
    "        # Insertion (target grows longer than source):\n",
    "        current_row = previous_row + 1\n",
    "\n",
    "        # Substitution or matching:\n",
    "        # Target and source items are aligned, and either\n",
    "        # are different (cost of 1), or are the same (cost of 0).\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                np.add(previous_row[:-1], target != s))\n",
    "\n",
    "        # Deletion (target grows shorter than source):\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                current_row[0:-1] + 1)\n",
    "\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "def removearticles(text):\n",
    "    text = re.sub('\"','',text)\n",
    "    #text = re.sub('^(\\s*)(de|do|dos|da|das|o|os|a|as|com|para|pra|e|ou|na|nas|no|nos|ao|aos|em|mg|ml)(\\s+)','',text)\n",
    "    return re.sub('((^\\s*)|(\\s+))(de|do|dos|da|das|o|os|a|as|com|para|pra|e|ou|na|nas|no|nos|ao|aos|em|mg|ml)(($\\s*)|(\\s+))', ' ', text)\n",
    "\n",
    "def lematizador(text):\n",
    "    auxt = str('')\n",
    "    words = text.split()\n",
    "    for x in words:\n",
    "        if h.spell(x):\n",
    "            if len(h.stem(x)) != 0:\n",
    "                auxt += h.stem(x)[0] + ' '\n",
    "            else:\n",
    "                auxt += x + ' '\n",
    "        else:\n",
    "            auxt += x + ' '\n",
    "    auxt.strip()\n",
    "    return auxt\n",
    "\n",
    "def stemmer(text):\n",
    "    stemmer = snowballstemmer.stemmer('portuguese')\n",
    "    return ' '.join(stemmer.stemWords(text.split())).strip()\n",
    "\n",
    "def comb(lis, dict_lis):\n",
    "    aux = []\n",
    "    for s in lis:\n",
    "        for ss in dict_lis:\n",
    "            aux.append(s+' '+ss)\n",
    "    return aux\n",
    "\n",
    "\n",
    "\n",
    "ini = time.time()\n",
    "h = Hunspell('pt_BR', hunspell_data_dir='pt_BR')\n",
    "\n",
    "df_termos = pd.DataFrame(data=None, columns=['Termos'])\n",
    "for x in range(0,len(termos_compostos['Termos'])):\n",
    "    df_termos.at[x,'Termos'] = termos_compostos.at[x,'Termos']\n",
    "\n",
    "cnx = pymysql.connect(user='root', password='1234',database='umls2017aa')\n",
    "cursor = cnx.cursor()\n",
    "sqlstr = (\"SELECT  CUI, STR FROM umls2017aa.mrconso where LAT='POR' order by CUI;\")\n",
    "cursor.execute(sqlstr)\n",
    "umls = []\n",
    "CUI1 = []\n",
    "STR1 = []\n",
    "y = 0\n",
    "for (CUI,STR) in cursor:\n",
    "    CUI1.insert(y,CUI)\n",
    "    STR1.insert(y,STR)\n",
    "    y+=1\n",
    "umls = array([STR1,CUI1])\n",
    "umls2 = array([STR1,STR1,STR1,CUI1])\n",
    "df_umls = pd.DataFrame(umls.transpose(),columns=['STR','CUI'])\n",
    "df_umls_norm = pd.DataFrame(umls2.transpose(),columns=['STR', 'STRlemma', 'STRstem', 'CUI'])\n",
    "\n",
    "sqlstr = (\"SELECT  CUI, WD FROM umls2017aa.mrxw_por;\")\n",
    "cursor.execute(sqlstr)\n",
    "umls = []\n",
    "CUI2 = []\n",
    "WD2 = []\n",
    "y = 0\n",
    "for (CUI,WD) in cursor:\n",
    "    CUI2.insert(y,CUI)\n",
    "    WD2.insert(y,WD)\n",
    "    y+=1\n",
    "umls_word = array([WD2,CUI2])\n",
    "umls2_word = array([WD2,WD2,WD2,CUI2])\n",
    "df_umls_word = pd.DataFrame(umls_word.transpose(),columns=['WD','CUI'])\n",
    "df_umls_word_norm = pd.DataFrame(umls2_word.transpose(),columns=['WD', 'WDlemma', 'WDstem', 'CUI'])\n",
    "\n",
    "cursor.close()\n",
    "cnx.close()\n",
    "\n",
    "for x in range(0,df_termos.size):\n",
    "    df_termos.at[x,'Termos'] = str(df_termos.at[x,'Termos']).lower()\n",
    "\n",
    "for x in range(0,df_umls['STR'].size):\n",
    "    df_umls.at[x,'STR'] = str(df_umls.at[x,'STR']).lower()\n",
    "\n",
    "for x in range(0,df_umls_word['WD'].size):\n",
    "    df_umls_word.at[x,'WD'] = str(df_umls_word.at[x,'WD']).lower()\n",
    "\n",
    "for x in range(0,df_umls_norm['STR'].size):\n",
    "    df_umls_norm.at[x,'STR'] = str(df_umls_norm.at[x,'STR']).lower()\n",
    "    df_umls_norm.at[x,'STRlemma'] = str(df_umls_norm.at[x,'STRlemma']).lower()\n",
    "    df_umls_norm.at[x,'STRstem'] = str(df_umls_norm.at[x,'STRstem']).lower()\n",
    "\n",
    "for x in range(0,df_umls_word_norm['WD'].size):\n",
    "    df_umls_word_norm.at[x,'WD'] = str(df_umls_word_norm.at[x,'WD']).lower()\n",
    "    df_umls_word_norm.at[x,'WDlemma'] = str(df_umls_word_norm.at[x,'WDlemma']).lower()\n",
    "    df_umls_word_norm.at[x,'WDstem'] = str(df_umls_word_norm.at[x,'WDstem']).lower()\n",
    "\n",
    "df_termos_norm = pd.DataFrame(data=None, columns=['Termos'])\n",
    "df_termos_lemma = pd.DataFrame(data=None, columns=['Termos'])\n",
    "df_termos_stem = pd.DataFrame(data=None, columns=['Termos'])\n",
    "\n",
    "for x in range(0,df_termos.size):\n",
    "    df_termos_norm.at[x,'Termos'] = removearticles(unidecode.unidecode(str(df_termos.at[x,'Termos']))).strip()\n",
    "\n",
    "for x in range(0,df_termos.size):\n",
    "    df_termos_lemma.at[x,'Termos'] = removearticles(unidecode.unidecode(lematizador(str(df_termos.at[x,'Termos']))))\n",
    "\n",
    "for x in range(0,df_termos.size):\n",
    "    df_termos_stem.at[x,'Termos'] = removearticles(unidecode.unidecode(stemmer(str(df_termos.at[x,'Termos']))))\n",
    "\n",
    "for x in range(0,df_umls_norm['STR'].size):\n",
    "    df_umls_norm.at[x,'STR'] = removearticles(unidecode.unidecode(str(df_umls_norm.at[x,'STR']))).strip()\n",
    "\n",
    "for x in range(0,df_umls_norm['STRlemma'].size):\n",
    "    df_umls_norm.at[x,'STRlemma'] = removearticles(unidecode.unidecode(lematizador(str(df_umls_norm.at[x,'STRlemma']))))\n",
    "\n",
    "for x in range(0,df_umls_norm['STRstem'].size):\n",
    "    df_umls_norm.at[x,'STRstem'] = removearticles(unidecode.unidecode(stemmer(str(df_umls_norm.at[x,'STRstem']))))\n",
    "\n",
    "for x in range(0,df_umls_word_norm['WD'].size):\n",
    "    df_umls_word_norm.at[x,'WD'] = unidecode.unidecode(str(df_umls_word_norm.at[x,'WD'])).strip()\n",
    "\n",
    "for x in range(0,df_umls_word_norm['WDlemma'].size):\n",
    "    df_umls_word_norm.at[x,'WDlemma'] = unidecode.unidecode(lematizador(str(df_umls_word_norm.at[x,'WDlemma'])))\n",
    "\n",
    "for x in range(0,df_umls_word_norm['WDstem'].size):\n",
    "    df_umls_word_norm.at[x,'WDstem'] = unidecode.unidecode(stemmer(str(df_umls_word_norm.at[x,'WDstem'])))\n",
    "\n",
    "#iniR = time.time()\n",
    "df_termos_match = pd.DataFrame(data=None, columns=['Termos', 'CUI', 'STR_UMLS', 'termo_match', 'Regra', 'num_lev'])\n",
    "\n",
    "print(100-1/len('lucass')*100)\n",
    "\n",
    "zz = 0\n",
    "achou = 0\n",
    "candidato = ''\n",
    "perc_max = 0\n",
    "metodo = 0\n",
    "y_aux = 0\n",
    "\n",
    "dicio = Dicio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>serviço particular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pupila fotorreagente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drusas perimaculares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atrofia de epitélio pigmentar retiniano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>córnea clara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hipertensão ocular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>há um ano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cirurgia bariátrica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>excesso de pele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cirurgia bariátrica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>manobra de valsalva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nódulo sólido no tecido celular subcutâneo do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vazamento de secreções</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sinais de alerta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sinais flogisticos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>torax a direita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>massas ou coleções organizadas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>com ecotextura semelhante a gordura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sinias flogisticos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hiperecogênico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>alta ambulatorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nódulo sólido bem definido discretamente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>origem lipomatosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>localizado no tecido celular subcutâneo do hem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>exerese da lesao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cervical anterior-esquerda , posterior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>fluxo medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>vertigem noturna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>discreto sopro sistólico em foco mitral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>dor de cabeça</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>palpitações de inicio súbito e desaparecimento...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>dor torácica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sintomas diários</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>exacerbação dos sintomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>parietal bilateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>herniorrafia inguinal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>prolapso de valva mitral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>camaras cardiacas normais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>falta de ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>alergias a medicamentos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>serviço de emergencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ausculta cardiaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>dispneia aos grandes esforços</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>mal estar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ventilatorio dependente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>refrigerantes de cola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>carcinoma de garganta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>trauma ocular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>consulta de rotina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>córnea cristalino transparente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>queixa específica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>quadro clínico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Termos\n",
       "0                                  serviço particular\n",
       "1                                pupila fotorreagente\n",
       "2                                                none\n",
       "3                                drusas perimaculares\n",
       "4             atrofia de epitélio pigmentar retiniano\n",
       "5                                                none\n",
       "6                                                none\n",
       "7                                                none\n",
       "8                                        córnea clara\n",
       "9                                  hipertensão ocular\n",
       "10                                          há um ano\n",
       "11                                cirurgia bariátrica\n",
       "12                                    excesso de pele\n",
       "13                                cirurgia bariátrica\n",
       "14                                manobra de valsalva\n",
       "15  nódulo sólido no tecido celular subcutâneo do ...\n",
       "16                             vazamento de secreções\n",
       "17                                   sinais de alerta\n",
       "18                                 sinais flogisticos\n",
       "19                                    torax a direita\n",
       "20                                               none\n",
       "21                     massas ou coleções organizadas\n",
       "22                com ecotextura semelhante a gordura\n",
       "23                                 sinias flogisticos\n",
       "24                                     hiperecogênico\n",
       "25                                  alta ambulatorial\n",
       "26           nódulo sólido bem definido discretamente\n",
       "27                                  origem lipomatosa\n",
       "28  localizado no tecido celular subcutâneo do hem...\n",
       "29                                   exerese da lesao\n",
       "..                                                ...\n",
       "46             cervical anterior-esquerda , posterior\n",
       "47                                        fluxo medio\n",
       "48                                   vertigem noturna\n",
       "49            discreto sopro sistólico em foco mitral\n",
       "50                                      dor de cabeça\n",
       "51  palpitações de inicio súbito e desaparecimento...\n",
       "52                                       dor torácica\n",
       "53                                   sintomas diários\n",
       "54                           exacerbação dos sintomas\n",
       "55                                 parietal bilateral\n",
       "56                              herniorrafia inguinal\n",
       "57                           prolapso de valva mitral\n",
       "58                          camaras cardiacas normais\n",
       "59                                        falta de ar\n",
       "60                            alergias a medicamentos\n",
       "61                              serviço de emergencia\n",
       "62                                  ausculta cardiaca\n",
       "63                      dispneia aos grandes esforços\n",
       "64                                          mal estar\n",
       "65                            ventilatorio dependente\n",
       "66                              refrigerantes de cola\n",
       "67                              carcinoma de garganta\n",
       "68                                      trauma ocular\n",
       "69                                 consulta de rotina\n",
       "70                                               none\n",
       "71                     córnea cristalino transparente\n",
       "72                                               none\n",
       "73                                               none\n",
       "74                                  queixa específica\n",
       "75                                     quadro clínico\n",
       "\n",
       "[76 rows x 1 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_termos_match = pd.DataFrame(data=None, columns=['Termos', 'CUI', 'STR_UMLS', 'termo_match', 'Regra', 'num_lev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'string'[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "servico particular\n",
      "22.5\n",
      "o termo em ingles é:  private service\n",
      "o termo em ingles sem normalização é:  private service\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  servico particular  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  35.17680382728577\n",
      "pupila fotorreagente\n",
      "22.5\n",
      "o termo em ingles é:  photoreceptor pupil\n",
      "o termo em ingles sem normalização é:  photoreceptor pupil\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  pupila fotorreagente  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  41.96259045600891\n",
      "none\n",
      "22.5\n",
      "o termo em ingles é:  none\n",
      "o termo em ingles sem normalização é:  none\n",
      "         CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "aqui  none  ---           CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "tempo,  6.12046217918396\n",
      "drusas perimaculares\n",
      "22.5\n",
      "o termo em ingles é:  perimacular druses\n",
      "o termo em ingles sem normalização é:  perimacular druses\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  drusas perimaculares  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  43.36135768890381\n",
      "atrofia epitelio pigmentar retiniano\n",
      "22.5\n",
      "o termo em ingles é:  retinal pigment epithelium atrophy\n",
      "o termo em ingles sem normalização é:  retinal pigment epithelial atrophy\n",
      "        CUI metodo porc                                   Termos  \\\n",
      "0  C1720251      4  100  atrofia de epitélio pigmentar retiniano   \n",
      "1  C1840457      4  100  atrofia de epitélio pigmentar retiniano   \n",
      "\n",
      "                             STR_UMLS                           termo_match  \n",
      "0  Retinal pigment epithelium atrophy  atrofia epitelio pigmentar retiniano  \n",
      "1  Retinal pigment epithelial atrophy  atrofia epitelio pigmentar retiniano  \n",
      "aqui  atrofia epitelio pigmentar retiniano  ---          CUI metodo porc                                   Termos  \\\n",
      "0  C1720251      4  100  atrofia de epitélio pigmentar retiniano   \n",
      "1  C1840457      4  100  atrofia de epitélio pigmentar retiniano   \n",
      "\n",
      "                             STR_UMLS                           termo_match  \n",
      "0  Retinal pigment epithelium atrophy  atrofia epitelio pigmentar retiniano  \n",
      "1  Retinal pigment epithelial atrophy  atrofia epitelio pigmentar retiniano  \n",
      "tempo,  57.7145049571991\n",
      "none\n",
      "22.5\n",
      "o termo em ingles é:  none\n",
      "o termo em ingles sem normalização é:  none\n",
      "         CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "aqui  none  ---           CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "tempo,  6.053556203842163\n",
      "none\n",
      "22.5\n",
      "o termo em ingles é:  none\n",
      "o termo em ingles sem normalização é:  none\n",
      "         CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "aqui  none  ---           CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "tempo,  6.165170907974243\n",
      "none\n",
      "22.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o termo em ingles é:  none\n",
      "o termo em ingles sem normalização é:  none\n",
      "         CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "aqui  none  ---           CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "tempo,  6.048622369766235\n",
      "cornea clara\n",
      "22.5\n",
      "o termo em ingles é:  clear cornea\n",
      "o termo em ingles sem normalização é:  clear cornea\n",
      "        CUI metodo porc        Termos      STR_UMLS   termo_match\n",
      "0  C1849214      4  100  córnea clara  Clear cornea  cornea clara\n",
      "aqui  cornea clara  ---          CUI metodo porc        Termos      STR_UMLS   termo_match\n",
      "0  C1849214      4  100  córnea clara  Clear cornea  cornea clara\n",
      "tempo,  15.569247722625732\n",
      "hipertensao ocular\n",
      "22.5\n",
      "o termo em ingles é:  ocular hypertension\n",
      "o termo em ingles sem normalização é:  ocular hypertension\n",
      "        CUI metodo porc              Termos             STR_UMLS  \\\n",
      "0  C0028840      4  100  hipertensão ocular  Ocular Hypertension   \n",
      "\n",
      "          termo_match  \n",
      "0  hipertensao ocular  \n",
      "aqui  hipertensao ocular  ---          CUI metodo porc              Termos             STR_UMLS  \\\n",
      "0  C0028840      4  100  hipertensão ocular  Ocular Hypertension   \n",
      "\n",
      "          termo_match  \n",
      "0  hipertensao ocular  \n",
      "tempo,  35.13306450843811\n",
      "ha um ano\n",
      "22.5\n",
      "o termo em ingles é:  a year ago\n",
      "o termo em ingles sem normalização é:  a year ago\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  ha um ano  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.888013124465942\n",
      "cirurgia bariatrica\n",
      "22.5\n",
      "o termo em ingles é:  bariatric surgery\n",
      "o termo em ingles sem normalização é:  bariatric surgery\n",
      "        CUI metodo porc               Termos           STR_UMLS  \\\n",
      "0  C1456587      4  100  cirurgia bariátrica  Bariatric Surgery   \n",
      "\n",
      "           termo_match  \n",
      "0  cirurgia bariatrica  \n",
      "aqui  cirurgia bariatrica  ---          CUI metodo porc               Termos           STR_UMLS  \\\n",
      "0  C1456587      4  100  cirurgia bariátrica  Bariatric Surgery   \n",
      "\n",
      "           termo_match  \n",
      "0  cirurgia bariatrica  \n",
      "tempo,  35.736079454422\n",
      "excesso pele\n",
      "22.5\n",
      "o termo em ingles é:  excess skin\n",
      "o termo em ingles sem normalização é:  excess skin\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  excesso pele  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  15.999450922012329\n",
      "cirurgia bariatrica\n",
      "22.5\n",
      "o termo em ingles é:  bariatric surgery\n",
      "o termo em ingles sem normalização é:  bariatric surgery\n",
      "        CUI metodo porc               Termos           STR_UMLS  \\\n",
      "0  C1456587      4  100  cirurgia bariátrica  Bariatric Surgery   \n",
      "\n",
      "           termo_match  \n",
      "0  cirurgia bariatrica  \n",
      "aqui  cirurgia bariatrica  ---          CUI metodo porc               Termos           STR_UMLS  \\\n",
      "0  C1456587      4  100  cirurgia bariátrica  Bariatric Surgery   \n",
      "\n",
      "           termo_match  \n",
      "0  cirurgia bariatrica  \n",
      "tempo,  35.81008815765381\n",
      "manobra valsalva\n",
      "22.5\n",
      "o termo em ingles é:  Valsalva maneuver\n",
      "o termo em ingles sem normalização é:  valsalva maneuver\n",
      "        CUI metodo porc               Termos           STR_UMLS  \\\n",
      "0  C0042293      4  100  manobra de valsalva  Valsalva Maneuver   \n",
      "\n",
      "        termo_match  \n",
      "0  manobra valsalva  \n",
      "aqui  manobra valsalva  ---          CUI metodo porc               Termos           STR_UMLS  \\\n",
      "0  C0042293      4  100  manobra de valsalva  Valsalva Maneuver   \n",
      "\n",
      "        termo_match  \n",
      "0  manobra valsalva  \n",
      "tempo,  29.874618768692017\n",
      "nodulo solido tecido celular subcutaneo hemitorax direito\n",
      "22.5\n",
      "o termo em ingles é:  nodule solid tissue subcutaneous hemitorax right\n",
      "o termo em ingles sem normalização é:  solid nodule in the subcutaneous tissue of the right hemithorax\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  nodulo solido tecido celular subcutaneo hemitorax direito  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  64.238516330719\n",
      "vazamento secrecoes\n",
      "22.5\n",
      "o termo em ingles é:  leak secretions\n",
      "o termo em ingles sem normalização é:  leakage of secretions\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  vazamento secrecoes  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  39.08096408843994\n",
      "sinais alerta\n",
      "22.5\n",
      "o termo em ingles é:  warning signs\n",
      "o termo em ingles sem normalização é:  warning signs\n",
      "        CUI metodo porc            Termos       STR_UMLS    termo_match\n",
      "0  C0871598      4  100  sinais de alerta  warning signs  sinais alerta\n",
      "aqui  sinais alerta  ---          CUI metodo porc            Termos       STR_UMLS    termo_match\n",
      "0  C0871598      4  100  sinais de alerta  warning signs  sinais alerta\n",
      "tempo,  18.917339324951172\n",
      "sinais flogisticos\n",
      "22.5\n",
      "o termo em ingles é:  phlogistic signs\n",
      "o termo em ingles sem normalização é:  phlogistic signs\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  sinais flogisticos  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  35.39371657371521\n",
      "torax direita\n",
      "22.5\n",
      "o termo em ingles é:  right thorax\n",
      "o termo em ingles sem normalização é:  right thorax\n",
      "        CUI metodo porc           Termos      STR_UMLS    termo_match\n",
      "0  C0230127      4  100  torax a direita  Right thorax  torax direita\n",
      "aqui  torax direita  ---          CUI metodo porc           Termos      STR_UMLS    termo_match\n",
      "0  C0230127      4  100  torax a direita  Right thorax  torax direita\n",
      "tempo,  18.96878981590271\n",
      "none\n",
      "22.5\n",
      "o termo em ingles é:  none\n",
      "o termo em ingles sem normalização é:  none\n",
      "         CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "16  C4050155      4  100   none     None        none\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aqui  none  ---           CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "tempo,  6.126916170120239\n",
      "massas colecoes organizadas\n",
      "22.5\n",
      "o termo em ingles é:  masses organized collections\n",
      "o termo em ingles sem normalização é:  masses or organized collections\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  massas colecoes organizadas  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  56.93759250640869\n",
      "ecotextura semelhante gordura\n",
      "22.5\n",
      "o termo em ingles é:  ecotexture similar fat\n",
      "o termo em ingles sem normalização é:  with fat-like ecotexture\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  ecotextura semelhante gordura  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  61.134350538253784\n",
      "sinias flogisticos\n",
      "22.5\n",
      "o termo em ingles é:  phlogistic signs\n",
      "o termo em ingles sem normalização é:  phlogistic signs\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  sinias flogisticos  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  35.28885221481323\n",
      "hiperecogenico\n",
      "22.5\n",
      "o termo em ingles é:  hyperechoic\n",
      "o termo em ingles sem normalização é:  hyperechoic\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  hiperecogenico  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  21.022120237350464\n",
      "alta ambulatorial\n",
      "22.5\n",
      "o termo em ingles é:  ambulatory discharge\n",
      "o termo em ingles sem normalização é:  ambulatory discharge\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  alta ambulatorial  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  31.651510000228882\n",
      "nodulo solido bem definido discretamente\n",
      "22.5\n",
      "o termo em ingles é:  discrete well defined solid nodule\n",
      "o termo em ingles sem normalização é:  discretely defined solid nodule\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  nodulo solido bem definido discretamente  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  59.950135707855225\n",
      "origem lipomatosa\n",
      "22.5\n",
      "o termo em ingles é:  lipomatous origin\n",
      "o termo em ingles sem normalização é:  lipomatous origin\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  origem lipomatosa  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  35.66106605529785\n",
      "localizado tecido celular subcutaneo hemitorax direito\n",
      "22.5\n",
      "o termo em ingles é:  located right subcutaneous tissue hemitorax right\n",
      "o termo em ingles sem normalização é:  located in the subcutaneous tissue of the right hemithorax\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  localizado tecido celular subcutaneo hemitorax direito  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  62.57954216003418\n",
      "exerese lesao\n",
      "22.5\n",
      "o termo em ingles é:  there is an injury\n",
      "o termo em ingles sem normalização é:  exeresis of the injury\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  exerese lesao  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  18.868204832077026\n",
      "fluxo exame doppler colorido\n",
      "22.5\n",
      "o termo em ingles é:  color Doppler examination flow\n",
      "o termo em ingles sem normalização é:  flow to color Doppler examination\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  fluxo exame doppler colorido  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  58.1293249130249\n",
      "oriento cuidados\n",
      "22.5\n",
      "o termo em ingles é:  care management\n",
      "o termo em ingles sem normalização é:  care management\n",
      "        CUI metodo porc            Termos         STR_UMLS       termo_match\n",
      "0  C2735309      4  100  oriento cuidados  Care management  oriento cuidados\n",
      "1  C2735310      4  100  oriento cuidados  Care management  oriento cuidados\n",
      "aqui  oriento cuidados  ---          CUI metodo porc            Termos         STR_UMLS       termo_match\n",
      "0  C2735309      4  100  oriento cuidados  Care management  oriento cuidados\n",
      "1  C2735310      4  100  oriento cuidados  Care management  oriento cuidados\n",
      "tempo,  29.83352303504944\n",
      "derrame pleural parapneumonico\n",
      "22.5\n",
      "o termo em ingles é:  parapneumonic pleural effusion\n",
      "o termo em ingles sem normalização é:  parapneumonic pleural effusion\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  derrame pleural parapneumonico  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  59.15062379837036\n",
      "none\n",
      "22.5\n",
      "o termo em ingles é:  none\n",
      "o termo em ingles sem normalização é:  none\n",
      "         CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "aqui  none  ---           CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "tempo,  6.115703344345093\n",
      "dores articulares\n",
      "22.5\n",
      "o termo em ingles é:  joint pain\n",
      "o termo em ingles sem normalização é:  joint pain\n",
      "        CUI metodo porc             Termos    STR_UMLS        termo_match\n",
      "0  C0003862      4  100  dores articulares  Joint Pain  dores articulares\n",
      "1  C1963066      4  100  dores articulares  Joint pain  dores articulares\n",
      "2  C4085641      4  100  dores articulares  Joint Pain  dores articulares\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aqui  dores articulares  ---          CUI metodo porc             Termos    STR_UMLS        termo_match\n",
      "0  C0003862      4  100  dores articulares  Joint Pain  dores articulares\n",
      "1  C1963066      4  100  dores articulares  Joint pain  dores articulares\n",
      "2  C4085641      4  100  dores articulares  Joint Pain  dores articulares\n",
      "tempo,  32.7315936088562\n",
      "lesoes hiperemiada\n",
      "22.5\n",
      "o termo em ingles é:  hyperemiotic lesions\n",
      "o termo em ingles sem normalização é:  hyperemiotic lesions\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  lesoes hiperemiada  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  36.039159059524536\n",
      "mao direita\n",
      "22.5\n",
      "o termo em ingles é:  right hand\n",
      "o termo em ingles sem normalização é:  right hand\n",
      "        CUI metodo porc       Termos    STR_UMLS  termo_match\n",
      "0  C0230370      4  100  mão direita  Right hand  mao direita\n",
      "1  C1288948      4  100  mão direita  Right hand  mao direita\n",
      "aqui  mao direita  ---          CUI metodo porc       Termos    STR_UMLS  termo_match\n",
      "0  C0230370      4  100  mão direita  Right hand  mao direita\n",
      "1  C1288948      4  100  mão direita  Right hand  mao direita\n",
      "tempo,  12.275952577590942\n",
      "deltode esquerdo\n",
      "22.5\n",
      "o termo em ingles é:  left deltoid\n",
      "o termo em ingles sem normalização é:  left deltoid\n",
      "        CUI metodo porc            Termos      STR_UMLS       termo_match\n",
      "0  C0694649      4  100  deltode esquerdo  Left deltoid  deltode esquerdo\n",
      "aqui  deltode esquerdo  ---          CUI metodo porc            Termos      STR_UMLS       termo_match\n",
      "0  C0694649      4  100  deltode esquerdo  Left deltoid  deltode esquerdo\n",
      "tempo,  29.057168006896973\n",
      "fatores melhora piora\n",
      "22.5\n",
      "o termo em ingles é:  Worsening factors\n",
      "o termo em ingles sem normalização é:  factors of improvement and worsening\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  fatores melhora piora  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  48.27134394645691\n",
      "processo mastoise\n",
      "22.5\n",
      "o termo em ingles é:  mastoise process\n",
      "o termo em ingles sem normalização é:  mastoise process\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  processo mastoise  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  31.935691356658936\n",
      "lesose pele maculo-vesicular\n",
      "22.5\n",
      "o termo em ingles é:  lesion maculo-vesicular skin\n",
      "o termo em ingles sem normalização é:  lesion of maculo-vesicular skin\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  lesose pele maculo-vesicular  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  58.33714580535889\n",
      "ciclo mesntrual regular\n",
      "22.5\n",
      "o termo em ingles é:  regular menstrual cycle\n",
      "o termo em ingles sem normalização é:  regular menstrual cycle\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  ciclo mesntrual regular  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  47.31459379196167\n",
      "none\n",
      "22.5\n",
      "o termo em ingles é:  none\n",
      "o termo em ingles sem normalização é:  none\n",
      "         CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "aqui  none  ---           CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "tempo,  6.250504970550537\n",
      "furcula esternal\n",
      "22.5\n",
      "o termo em ingles é:  furcula sternal\n",
      "o termo em ingles sem normalização é:  furcula sternal\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  furcula esternal  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  29.92746138572693\n",
      "limitacao articular\n",
      "22.5\n",
      "o termo em ingles é:  joint limitation\n",
      "o termo em ingles sem normalização é:  joint limitation\n",
      "        CUI metodo porc               Termos          STR_UMLS  \\\n",
      "0  C1860303      4  100  limitaçao articular  Joint limitation   \n",
      "\n",
      "           termo_match  \n",
      "0  limitacao articular  \n",
      "aqui  limitacao articular  ---          CUI metodo porc               Termos          STR_UMLS  \\\n",
      "0  C1860303      4  100  limitaçao articular  Joint limitation   \n",
      "\n",
      "           termo_match  \n",
      "0  limitacao articular  \n",
      "tempo,  38.309276819229126\n",
      "medicamentos imunossupressores\n",
      "22.5\n",
      "o termo em ingles é:  immunosuppressive drugs\n",
      "o termo em ingles sem normalização é:  immunosuppressive drugs\n",
      "        CUI metodo porc                          Termos  \\\n",
      "0  C2359945      4  100  medicamentos imunossupressores   \n",
      "\n",
      "                  STR_UMLS                     termo_match  \n",
      "0  Immunosuppressive drugs  medicamentos imunossupressores  \n",
      "aqui  medicamentos imunossupressores  ---          CUI metodo porc                          Termos  \\\n",
      "0  C2359945      4  100  medicamentos imunossupressores   \n",
      "\n",
      "                  STR_UMLS                     termo_match  \n",
      "0  Immunosuppressive drugs  medicamentos imunossupressores  \n",
      "tempo,  60.522162437438965\n",
      "cervical anterior-esquerda , posterior\n",
      "22.5\n",
      "o termo em ingles é:  cervical anterior-left, posterior\n",
      "o termo em ingles sem normalização é:  cervical anterior-left, posterior\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  cervical anterior-esquerda , posterior  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  55.793588638305664\n",
      "fluxo medio\n",
      "22.5\n",
      "o termo em ingles é:  average flow\n",
      "o termo em ingles sem normalização é:  average flow\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  fluxo medio  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.253777265548706\n",
      "vertigem noturna\n",
      "22.5\n",
      "o termo em ingles é:  night vertigo\n",
      "o termo em ingles sem normalização é:  night vertigo\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  vertigem noturna  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  29.58422565460205\n",
      "discreto sopro sistolico foco mitral\n",
      "22.5\n",
      "o termo em ingles é:  discrete murmur systolic murmur\n",
      "o termo em ingles sem normalização é:  discrete systolic murmur in mitral focus\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  discreto sopro sistolico foco mitral  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  58.68325686454773\n",
      "dor cabeca\n",
      "22.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o termo em ingles é:  headache\n",
      "o termo em ingles sem normalização é:  Headache\n",
      "        CUI metodo porc         Termos  STR_UMLS termo_match\n",
      "0  C0018681      4  100  dor de cabeça  Headache  dor cabeca\n",
      "aqui  dor cabeca  ---          CUI metodo porc         Termos  STR_UMLS termo_match\n",
      "0  C0018681      4  100  dor de cabeça  Headache  dor cabeca\n",
      "tempo,  11.023988246917725\n",
      "palpitacoes inicio subito desaparecimento gradual\n",
      "22.5\n",
      "o termo em ingles é:  palpitacoes beginning subito gradual disappearance\n",
      "o termo em ingles sem normalização é:  sudden onset palpitations and gradual disappearance\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  palpitacoes inicio subito desaparecimento gradual  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  67.41471791267395\n",
      "dor toracica\n",
      "22.5\n",
      "o termo em ingles é:  Chest pain\n",
      "o termo em ingles sem normalização é:  Chest pain\n",
      "        CUI metodo porc        Termos    STR_UMLS   termo_match\n",
      "0  C0008031      4  100  dor torácica  Chest Pain  dor toracica\n",
      "1  C2926613      4  100  dor torácica  Chest pain  dor toracica\n",
      "aqui  dor toracica  ---          CUI metodo porc        Termos    STR_UMLS   termo_match\n",
      "0  C0008031      4  100  dor torácica  Chest Pain  dor toracica\n",
      "1  C2926613      4  100  dor torácica  Chest pain  dor toracica\n",
      "tempo,  16.035314321517944\n",
      "sintomas diarios\n",
      "22.5\n",
      "o termo em ingles é:  daily symptoms\n",
      "o termo em ingles sem normalização é:  daily symptoms\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  sintomas diarios  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  28.662601232528687\n",
      "exacerbacao sintomas\n",
      "22.5\n",
      "o termo em ingles é:  exacerbation symptoms\n",
      "o termo em ingles sem normalização é:  exacerbation of symptoms\n",
      "        CUI metodo porc                    Termos                  STR_UMLS  \\\n",
      "0  C4062989      4  100  exacerbação dos sintomas  Exacerbation of symptoms   \n",
      "\n",
      "            termo_match  \n",
      "0  exacerbacao sintomas  \n",
      "aqui  exacerbacao sintomas  ---          CUI metodo porc                    Termos                  STR_UMLS  \\\n",
      "0  C4062989      4  100  exacerbação dos sintomas  Exacerbation of symptoms   \n",
      "\n",
      "            termo_match  \n",
      "0  exacerbacao sintomas  \n",
      "tempo,  42.8690459728241\n",
      "parietal bilateral\n",
      "22.5\n",
      "o termo em ingles é:  bilateral parietal\n",
      "o termo em ingles sem normalização é:  bilateral parietal\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  parietal bilateral  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  34.07919383049011\n",
      "herniorrafia inguinal\n",
      "22.5\n",
      "o termo em ingles é:  herniorrhaphy inguinal\n",
      "o termo em ingles sem normalização é:  herniorrhaphy inguinal\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  herniorrafia inguinal  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  47.12136101722717\n",
      "prolapso valva mitral\n",
      "22.5\n",
      "o termo em ingles é:  mitral valve prolapse\n",
      "o termo em ingles sem normalização é:  mitral valve prolapse\n",
      "        CUI metodo porc                    Termos               STR_UMLS  \\\n",
      "0  C0026267      4  100  prolapso de valva mitral  Mitral Valve Prolapse   \n",
      "\n",
      "             termo_match  \n",
      "0  prolapso valva mitral  \n",
      "aqui  prolapso valva mitral  ---          CUI metodo porc                    Termos               STR_UMLS  \\\n",
      "0  C0026267      4  100  prolapso de valva mitral  Mitral Valve Prolapse   \n",
      "\n",
      "             termo_match  \n",
      "0  prolapso valva mitral  \n",
      "tempo,  46.4499077796936\n",
      "camaras cardiacas normais\n",
      "22.5\n",
      "o termo em ingles é:  normal heart chambers\n",
      "o termo em ingles sem normalização é:  normal heart chambers\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  camaras cardiacas normais  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  53.66167950630188\n",
      "falta ar\n",
      "22.5\n",
      "o termo em ingles é:  there is no air\n",
      "o termo em ingles sem normalização é:  shortness of breath\n",
      "        CUI metodo porc       Termos             STR_UMLS termo_match\n",
      "0  C0013404      4  100  falta de ar  Shortness of Breath    falta ar\n",
      "1  C2707305      4  100  falta de ar  Shortness of breath    falta ar\n",
      "2  C3274920      4  100  falta de ar  Shortness of breath    falta ar\n",
      "3  C4084762      4  100  falta de ar  Shortness of breath    falta ar\n",
      "4  C4084763      4  100  falta de ar  Shortness of breath    falta ar\n",
      "5  C4084764      4  100  falta de ar  Shortness of breath    falta ar\n",
      "aqui  falta ar  ---          CUI metodo porc       Termos             STR_UMLS termo_match\n",
      "0  C0013404      4  100  falta de ar  Shortness of Breath    falta ar\n",
      "1  C2707305      4  100  falta de ar  Shortness of breath    falta ar\n",
      "2  C3274920      4  100  falta de ar  Shortness of breath    falta ar\n",
      "3  C4084762      4  100  falta de ar  Shortness of breath    falta ar\n",
      "4  C4084763      4  100  falta de ar  Shortness of breath    falta ar\n",
      "5  C4084764      4  100  falta de ar  Shortness of breath    falta ar\n",
      "tempo,  8.566588640213013\n",
      "alergias medicamentos\n",
      "22.5\n",
      "o termo em ingles é:  allergies medicines\n",
      "o termo em ingles sem normalização é:  drug allergies\n",
      "        CUI metodo porc                   Termos        STR_UMLS  \\\n",
      "0  C0013182      4  100  alergias a medicamentos  Drug Allergies   \n",
      "\n",
      "             termo_match  \n",
      "0  alergias medicamentos  \n",
      "aqui  alergias medicamentos  ---          CUI metodo porc                   Termos        STR_UMLS  \\\n",
      "0  C0013182      4  100  alergias a medicamentos  Drug Allergies   \n",
      "\n",
      "             termo_match  \n",
      "0  alergias medicamentos  \n",
      "tempo,  45.426679611206055\n",
      "servico emergencia\n",
      "22.5\n",
      "o termo em ingles é:  emergency service\n",
      "o termo em ingles sem normalização é:  emergency service\n",
      "        CUI metodo porc                 Termos           STR_UMLS  \\\n",
      "0  C0013961      4  100  serviço de emergencia  emergency service   \n",
      "\n",
      "          termo_match  \n",
      "0  servico emergencia  \n",
      "aqui  servico emergencia  ---          CUI metodo porc                 Termos           STR_UMLS  \\\n",
      "0  C0013961      4  100  serviço de emergencia  emergency service   \n",
      "\n",
      "          termo_match  \n",
      "0  servico emergencia  \n",
      "tempo,  35.264647006988525\n",
      "ausculta cardiaca\n",
      "22.5\n",
      "o termo em ingles é:  heart auscultation\n",
      "o termo em ingles sem normalização é:  heart auscultation\n",
      "        CUI metodo porc             Termos            STR_UMLS  \\\n",
      "0  C0018793      4  100  ausculta cardiaca  Heart Auscultation   \n",
      "\n",
      "         termo_match  \n",
      "0  ausculta cardiaca  \n",
      "aqui  ausculta cardiaca  ---          CUI metodo porc             Termos            STR_UMLS  \\\n",
      "0  C0018793      4  100  ausculta cardiaca  Heart Auscultation   \n",
      "\n",
      "         termo_match  \n",
      "0  ausculta cardiaca  \n",
      "tempo,  31.3097140789032\n",
      "dispneia grandes esforcos\n",
      "22.5\n",
      "o termo em ingles é:  dyspnoea great efforts\n",
      "o termo em ingles sem normalização é:  dyspnea on the great efforts\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  dispneia grandes esforcos  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  57.141621828079224\n",
      "mal estar\n",
      "22.5\n",
      "o termo em ingles é:  unwell\n",
      "o termo em ingles sem normalização é:  unwell\n",
      "        CUI metodo porc     Termos STR_UMLS termo_match\n",
      "0  C0857256      4  100  mal estar   Unwell   mal estar\n",
      "aqui  mal estar  ---          CUI metodo porc     Termos STR_UMLS termo_match\n",
      "0  C0857256      4  100  mal estar   Unwell   mal estar\n",
      "tempo,  9.699289560317993\n",
      "ventilatorio dependente\n",
      "22.5\n",
      "o termo em ingles é:  dependent ventilator\n",
      "o termo em ingles sem normalização é:  dependent ventilator\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  ventilatorio dependente  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  51.43791103363037\n",
      "refrigerantes cola\n",
      "22.5\n",
      "o termo em ingles é:  cola drinks\n",
      "o termo em ingles sem normalização é:  cola drinks\n",
      "        CUI metodo porc                 Termos     STR_UMLS  \\\n",
      "0  C0452444      4  100  refrigerantes de cola  cola drinks   \n",
      "\n",
      "          termo_match  \n",
      "0  refrigerantes cola  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aqui  refrigerantes cola  ---          CUI metodo porc                 Termos     STR_UMLS  \\\n",
      "0  C0452444      4  100  refrigerantes de cola  cola drinks   \n",
      "\n",
      "          termo_match  \n",
      "0  refrigerantes cola  \n",
      "tempo,  36.2611448764801\n",
      "carcinoma garganta\n",
      "22.5\n",
      "o termo em ingles é:  throat carcinoma\n",
      "o termo em ingles sem normalização é:  throat carcinoma\n",
      "        CUI metodo porc                 Termos          STR_UMLS  \\\n",
      "0  C0740339      4  100  carcinoma de garganta  Throat Carcinoma   \n",
      "\n",
      "          termo_match  \n",
      "0  carcinoma garganta  \n",
      "aqui  carcinoma garganta  ---          CUI metodo porc                 Termos          STR_UMLS  \\\n",
      "0  C0740339      4  100  carcinoma de garganta  Throat Carcinoma   \n",
      "\n",
      "          termo_match  \n",
      "0  carcinoma garganta  \n",
      "tempo,  33.85846209526062\n",
      "trauma ocular\n",
      "22.5\n",
      "o termo em ingles é:  ocular trauma\n",
      "o termo em ingles sem normalização é:  ocular trauma\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  trauma ocular  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  18.81842541694641\n",
      "consulta rotina\n",
      "22.5\n",
      "o termo em ingles é:  routine consultation\n",
      "o termo em ingles sem normalização é:  routine consultation\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  consulta rotina  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  22.993260145187378\n",
      "none\n",
      "22.5\n",
      "o termo em ingles é:  none\n",
      "o termo em ingles sem normalização é:  none\n",
      "         CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "aqui  none  ---           CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "tempo,  6.043749094009399\n",
      "cornea cristalino transparente\n",
      "22.5\n",
      "o termo em ingles é:  transparent cornea\n",
      "o termo em ingles sem normalização é:  transparent crystalline cornea\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  cornea cristalino transparente  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  58.006733655929565\n",
      "none\n",
      "22.5\n",
      "o termo em ingles é:  none\n",
      "o termo em ingles sem normalização é:  none\n",
      "         CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "aqui  none  ---           CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "tempo,  6.127235412597656\n",
      "none\n",
      "22.5\n",
      "o termo em ingles é:  none\n",
      "o termo em ingles sem normalização é:  none\n",
      "         CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "aqui  none  ---           CUI metodo porc Termos STR_UMLS termo_match\n",
      "0   C0456148      4  100   none     None        none\n",
      "14  C1706277      4  100   none     None        none\n",
      "13  C1556152      4  100   none     None        none\n",
      "12  C1556151      4  100   none     None        none\n",
      "11  C1556150      4  100   none     None        none\n",
      "10  C1556148      4  100   none     None        none\n",
      "9   C1556147      4  100   none     None        none\n",
      "15  C4050154      4  100   none     None        none\n",
      "8   C1556146      4  100   none     None        none\n",
      "6   C1551387      4  100   none     None        none\n",
      "5   C1550437      4  100   none     None        none\n",
      "4   C1550083      4  100   none     None        none\n",
      "3   C1547191      4  100   none     none        none\n",
      "2   C1546509      4  100   none     none        none\n",
      "1   C0549184      4  100   none     None        none\n",
      "7   C1553523      4  100   none     none        none\n",
      "16  C4050155      4  100   none     None        none\n",
      "tempo,  5.779443025588989\n",
      "queixa especifica\n",
      "22.5\n",
      "o termo em ingles é:  specific complaint\n",
      "o termo em ingles sem normalização é:  specific complaint\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  queixa especifica  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  32.81580090522766\n",
      "quadro clinico\n",
      "22.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o termo em ingles é:  clinical condition\n",
      "o termo em ingles sem normalização é:  clinical condition\n",
      "Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "aqui  quadro clinico  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  20.793199062347412\n"
     ]
    }
   ],
   "source": [
    "cnx = pymysql.connect(user='root', password='1234',database='umls2017aa')\n",
    "cursor = cnx.cursor()\n",
    "for x in range(0,len(df_termos_norm)):\n",
    "    num_max = len(df_termos_norm.at[x,'Termos'])+len(df_termos_norm.at[x,'Termos'])*0.25\n",
    "    num_min = len(df_termos_norm.at[x,'Termos'])-len(df_termos_norm.at[x,'Termos'])*0.25\n",
    "    print(df_termos_norm.at[x,'Termos'])\n",
    "    print(num_perc)\n",
    "    candidatos = pd.DataFrame(data=None, columns=['CUI', 'metodo', 'porc', 'Termos', 'STR_UMLS', 'termo_match'])\n",
    "    n_candidato = 0\n",
    "    words = df_termos_norm.at[x,'Termos'].split()\n",
    "    words_lemma = df_termos_lemma.at[x,'Termos'].split()\n",
    "    words_steam = df_termos_stem.at[x, 'Termos'].split()\n",
    "    termo_ingles_norm = api(df_termos_norm.at[x,'Termos'], 'pt', 'en')\n",
    "    print('o termo em ingles é: ', termo_ingles_norm)\n",
    "    termo_ingles = api(df_termos.at[x,'Termos'], 'pt', 'en')\n",
    "    print('o termo em ingles sem normalização é: ', termo_ingles)\n",
    "    \n",
    "    iniR = time.time()\n",
    "    sqlstr = (\"SELECT  CUI, STR FROM umls2017aa.mrconso where STR= %s and LAT='ENG' order by CUI;\")\n",
    "    cursor.execute(sqlstr, termo_ingles_norm)\n",
    "    CUIS_aux = []\n",
    "    for (CUI,STR) in cursor:\n",
    "        if not CUI in CUIS_aux:\n",
    "            CUIS_aux.append(CUI)\n",
    "            candidatos.at[n_candidato,'CUI'] = CUI\n",
    "            candidatos.at[n_candidato,'Termos'] = df_termos.at[x,'Termos']\n",
    "            candidatos.at[n_candidato,'STR_UMLS'] = STR\n",
    "            candidatos.at[n_candidato,'termo_match'] = df_termos_norm.at[x,'Termos']\n",
    "            candidatos.at[n_candidato, 'metodo'] = 4\n",
    "            candidatos.at[n_candidato, 'porc'] = 100\n",
    "            n_candidato += 1\n",
    "    \n",
    "    sqlstr = (\"SELECT  CUI, STR FROM umls2017aa.mrconso where STR= %s and LAT='ENG' order by CUI;\")\n",
    "    cursor.execute(sqlstr, termo_ingles)\n",
    "    for (CUI,STR) in cursor:\n",
    "        if not CUI in CUIS_aux:\n",
    "            CUIS_aux.append(CUI)\n",
    "            candidatos.at[n_candidato,'CUI'] = CUI\n",
    "            candidatos.at[n_candidato,'Termos'] = df_termos.at[x,'Termos']\n",
    "            candidatos.at[n_candidato,'STR_UMLS'] = STR\n",
    "            candidatos.at[n_candidato,'termo_match'] = df_termos_norm.at[x,'Termos']\n",
    "            candidatos.at[n_candidato, 'metodo'] = 4\n",
    "            candidatos.at[n_candidato, 'porc'] = 100\n",
    "            n_candidato += 1\n",
    "    print(candidatos)\n",
    "    achou_Term = False\n",
    "    fimR = time.time()\n",
    "    print('tempo, ', (fimR-iniR))\n",
    "    perc_max = 0\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('CliniMap_M4.xlsx')\n",
    "df_termos_match.to_excel(writer, 'Match')\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.ExcelFile('CliniMap_M4.xlsx')\n",
    "clinMap_4 = read.parse('Match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_termos_match = pd.DataFrame(data=None, columns=['Termos', 'CUI', 'STR_UMLS', 'termo_match', 'Regra', 'num_lev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "servico particular\n",
      "22.5  e  13.5\n",
      "aqui  servico particular  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.811729907989502\n",
      "pupila fotorreagente\n",
      "25.0  e  15.0\n",
      "aqui  pupila fotorreagente  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  13.089941263198853\n",
      "none\n",
      "5.0  e  3.0\n",
      "aqui  none  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.309885025024414\n",
      "drusas perimaculares\n",
      "25.0  e  15.0\n",
      "aqui  drusas perimaculares  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.323413848876953\n",
      "atrofia epitelio pigmentar retiniano\n",
      "45.0  e  27.0\n",
      "aqui  atrofia epitelio pigmentar retiniano  ---          CUI metodo     porc                                   Termos  \\\n",
      "0  C1720251      1  90.9091  atrofia de epitélio pigmentar retiniano   \n",
      "\n",
      "                            STR_UMLS                           termo_match  \n",
      "0  atrofia epitelio pigmentar retina  atrofia epitelio pigmentar retiniano  \n",
      "tempo,  14.077334642410278\n",
      "none\n",
      "5.0  e  3.0\n",
      "aqui  none  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.713636636734009\n",
      "none\n",
      "5.0  e  3.0\n",
      "aqui  none  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.098013877868652\n",
      "none\n",
      "5.0  e  3.0\n",
      "aqui  none  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.31788158416748\n",
      "cornea clara\n",
      "15.0  e  9.0\n",
      "aqui  cornea clara  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.380611181259155\n",
      "hipertensao ocular\n",
      "22.5  e  13.5\n",
      "aqui  hipertensao ocular  ---          CUI metodo porc              Termos            STR_UMLS  \\\n",
      "0  C0028840      1  100  hipertensão ocular  hipertensao ocular   \n",
      "\n",
      "          termo_match  \n",
      "0  hipertensao ocular  \n",
      "tempo,  1.2612240314483643\n",
      "ha um ano\n",
      "11.25  e  6.75\n",
      "aqui  ha um ano  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.980471134185791\n",
      "cirurgia bariatrica\n",
      "23.75  e  14.25\n",
      "aqui  cirurgia bariatrica  ---          CUI metodo porc               Termos             STR_UMLS  \\\n",
      "0  C1456587      1  100  cirurgia bariátrica  cirurgia bariatrica   \n",
      "\n",
      "           termo_match  \n",
      "0  cirurgia bariatrica  \n",
      "tempo,  9.9278883934021\n",
      "excesso pele\n",
      "15.0  e  9.0\n",
      "aqui  excesso pele  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.293663501739502\n",
      "cirurgia bariatrica\n",
      "23.75  e  14.25\n",
      "aqui  cirurgia bariatrica  ---          CUI metodo porc               Termos             STR_UMLS  \\\n",
      "0  C1456587      1  100  cirurgia bariátrica  cirurgia bariatrica   \n",
      "\n",
      "           termo_match  \n",
      "0  cirurgia bariatrica  \n",
      "tempo,  10.246693849563599\n",
      "manobra valsalva\n",
      "20.0  e  12.0\n",
      "aqui  manobra valsalva  ---          CUI metodo porc               Termos          STR_UMLS  \\\n",
      "0  C0042293      1  100  manobra de valsalva  manobra valsalva   \n",
      "\n",
      "        termo_match  \n",
      "0  manobra valsalva  \n",
      "tempo,  1.8028888702392578\n",
      "nodulo solido tecido celular subcutaneo hemitorax direito\n",
      "71.25  e  42.75\n",
      "aqui  nodulo solido tecido celular subcutaneo hemitorax direito  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.828950643539429\n",
      "vazamento secrecoes\n",
      "23.75  e  14.25\n",
      "aqui  vazamento secrecoes  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.085174083709717\n",
      "sinais alerta\n",
      "16.25  e  9.75\n",
      "aqui  sinais alerta  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.71540379524231\n",
      "sinais flogisticos\n",
      "22.5  e  13.5\n",
      "aqui  sinais flogisticos  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.674609184265137\n",
      "torax direita\n",
      "16.25  e  9.75\n",
      "aqui  torax direita  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.31329870223999\n",
      "none\n",
      "5.0  e  3.0\n",
      "aqui  none  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.685713291168213\n",
      "massas colecoes organizadas\n",
      "33.75  e  20.25\n",
      "aqui  massas colecoes organizadas  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.749117612838745\n",
      "ecotextura semelhante gordura\n",
      "36.25  e  21.75\n",
      "aqui  ecotextura semelhante gordura  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.32977557182312\n",
      "sinias flogisticos\n",
      "22.5  e  13.5\n",
      "aqui  sinias flogisticos  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.816900491714478\n",
      "hiperecogenico\n",
      "17.5  e  10.5\n",
      "aqui  hiperecogenico  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.966890335083008\n",
      "alta ambulatorial\n",
      "21.25  e  12.75\n",
      "aqui  alta ambulatorial  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.345083236694336\n",
      "nodulo solido bem definido discretamente\n",
      "50.0  e  30.0\n",
      "aqui  nodulo solido bem definido discretamente  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.950608491897583\n",
      "origem lipomatosa\n",
      "21.25  e  12.75\n",
      "aqui  origem lipomatosa  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.151351928710938\n",
      "localizado tecido celular subcutaneo hemitorax direito\n",
      "67.5  e  40.5\n",
      "aqui  localizado tecido celular subcutaneo hemitorax direito  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.533224105834961\n",
      "exerese lesao\n",
      "16.25  e  9.75\n",
      "aqui  exerese lesao  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.93383526802063\n",
      "fluxo exame doppler colorido\n",
      "35.0  e  21.0\n",
      "aqui  fluxo exame doppler colorido  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.58097791671753\n",
      "oriento cuidados\n",
      "20.0  e  12.0\n",
      "aqui  oriento cuidados  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.947617292404175\n",
      "derrame pleural parapneumonico\n",
      "37.5  e  22.5\n",
      "aqui  derrame pleural parapneumonico  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.60664415359497\n",
      "none\n",
      "5.0  e  3.0\n",
      "aqui  none  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.282247066497803\n",
      "dores articulares\n",
      "21.25  e  12.75\n",
      "aqui  dores articulares  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.083664894104004\n",
      "lesoes hiperemiada\n",
      "22.5  e  13.5\n",
      "aqui  lesoes hiperemiada  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.41369915008545\n",
      "mao direita\n",
      "13.75  e  8.25\n",
      "aqui  mao direita  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.043757200241089\n",
      "deltode esquerdo\n",
      "20.0  e  12.0\n",
      "aqui  deltode esquerdo  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.657471895217896\n",
      "fatores melhora piora\n",
      "26.25  e  15.75\n",
      "aqui  fatores melhora piora  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.586963176727295\n",
      "processo mastoise\n",
      "21.25  e  12.75\n",
      "aqui  processo mastoise  ---          CUI metodo     porc             Termos           STR_UMLS  \\\n",
      "0  C0446908      1  94.1176  processo mastoise  processo mastoide   \n",
      "\n",
      "         termo_match  \n",
      "0  processo mastoise  \n",
      "tempo,  12.101814031600952\n",
      "lesose pele maculo-vesicular\n",
      "35.0  e  21.0\n",
      "aqui  lesose pele maculo-vesicular  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.399656534194946\n",
      "ciclo mesntrual regular\n",
      "28.75  e  17.25\n",
      "aqui  ciclo mesntrual regular  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  14.83345365524292\n",
      "none\n",
      "5.0  e  3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aqui  none  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.348731756210327\n",
      "furcula esternal\n",
      "20.0  e  12.0\n",
      "aqui  furcula esternal  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.384435892105103\n",
      "limitacao articular\n",
      "23.75  e  14.25\n",
      "aqui  limitacao articular  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.75253415107727\n",
      "medicamentos imunossupressores\n",
      "37.5  e  22.5\n",
      "aqui  medicamentos imunossupressores  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.514661073684692\n",
      "cervical anterior-esquerda , posterior\n",
      "47.5  e  28.5\n",
      "aqui  cervical anterior-esquerda , posterior  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  16.04199719429016\n",
      "fluxo medio\n",
      "13.75  e  8.25\n",
      "aqui  fluxo medio  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.37563681602478\n",
      "vertigem noturna\n",
      "20.0  e  12.0\n",
      "aqui  vertigem noturna  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.208052635192871\n",
      "discreto sopro sistolico foco mitral\n",
      "45.0  e  27.0\n",
      "aqui  discreto sopro sistolico foco mitral  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.673377990722656\n",
      "dor cabeca\n",
      "12.5  e  7.5\n",
      "aqui  dor cabeca  ---          CUI metodo porc         Termos    STR_UMLS termo_match\n",
      "0  C0018681      1  100  dor de cabeça  dor cabeca  dor cabeca\n",
      "tempo,  0.6428263187408447\n",
      "palpitacoes inicio subito desaparecimento gradual\n",
      "61.25  e  36.75\n",
      "aqui  palpitacoes inicio subito desaparecimento gradual  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.387709140777588\n",
      "dor toracica\n",
      "15.0  e  9.0\n",
      "aqui  dor toracica  ---          CUI metodo porc        Termos      STR_UMLS   termo_match\n",
      "0  C0008031      1  100  dor torácica  dor toracica  dor toracica\n",
      "tempo,  0.2814490795135498\n",
      "sintomas diarios\n",
      "20.0  e  12.0\n",
      "aqui  sintomas diarios  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.466476678848267\n",
      "exacerbacao sintomas\n",
      "25.0  e  15.0\n",
      "aqui  exacerbacao sintomas  ---          CUI metodo porc                    Termos              STR_UMLS  \\\n",
      "0  C4042866      1  100  exacerbação dos sintomas  exacerbacao sintomas   \n",
      "\n",
      "            termo_match  \n",
      "0  exacerbacao sintomas  \n",
      "tempo,  11.680482149124146\n",
      "parietal bilateral\n",
      "22.5  e  13.5\n",
      "aqui  parietal bilateral  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.027655601501465\n",
      "herniorrafia inguinal\n",
      "26.25  e  15.75\n",
      "aqui  herniorrafia inguinal  ---          CUI metodo porc                 Termos               STR_UMLS  \\\n",
      "0  C0021446      1  100  herniorrafia inguinal  herniorrafia inguinal   \n",
      "\n",
      "             termo_match  \n",
      "0  herniorrafia inguinal  \n",
      "tempo,  0.9474565982818604\n",
      "prolapso valva mitral\n",
      "26.25  e  15.75\n",
      "aqui  prolapso valva mitral  ---          CUI metodo porc                    Termos               STR_UMLS  \\\n",
      "0  C0026267      1  100  prolapso de valva mitral  prolapso valva mitral   \n",
      "\n",
      "             termo_match  \n",
      "0  prolapso valva mitral  \n",
      "tempo,  1.1082451343536377\n",
      "camaras cardiacas normais\n",
      "31.25  e  18.75\n",
      "aqui  camaras cardiacas normais  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  15.398947954177856\n",
      "falta ar\n",
      "10.0  e  6.0\n",
      "aqui  falta ar  ---          CUI metodo porc       Termos  STR_UMLS termo_match\n",
      "0  C0013404      1  100  falta de ar  falta ar    falta ar\n",
      "tempo,  0.39179372787475586\n",
      "alergias medicamentos\n",
      "26.25  e  15.75\n",
      "aqui  alergias medicamentos  ---          CUI metodo     porc                   Termos               STR_UMLS  \\\n",
      "0  C0013182      1  90.4762  alergias a medicamentos  alergia medicamentosa   \n",
      "\n",
      "             termo_match  \n",
      "0  alergias medicamentos  \n",
      "tempo,  13.624064207077026\n",
      "servico emergencia\n",
      "22.5  e  13.5\n",
      "aqui  servico emergencia  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.8969087600708\n",
      "ausculta cardiaca\n",
      "21.25  e  12.75\n",
      "aqui  ausculta cardiaca  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.06250286102295\n",
      "dispneia grandes esforcos\n",
      "31.25  e  18.75\n",
      "aqui  dispneia grandes esforcos  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.654379844665527\n",
      "mal estar\n",
      "11.25  e  6.75\n",
      "aqui  mal estar  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.46712040901184\n",
      "ventilatorio dependente\n",
      "28.75  e  17.25\n",
      "aqui  ventilatorio dependente  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.083350896835327\n",
      "refrigerantes cola\n",
      "22.5  e  13.5\n",
      "aqui  refrigerantes cola  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.630475521087646\n",
      "carcinoma garganta\n",
      "22.5  e  13.5\n",
      "aqui  carcinoma garganta  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.919172286987305\n",
      "trauma ocular\n",
      "16.25  e  9.75\n",
      "aqui  trauma ocular  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.958935022354126\n",
      "consulta rotina\n",
      "18.75  e  11.25\n",
      "aqui  consulta rotina  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.001683473587036\n",
      "none\n",
      "5.0  e  3.0\n",
      "aqui  none  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  7.91816258430481\n",
      "cornea cristalino transparente\n",
      "37.5  e  22.5\n",
      "aqui  cornea cristalino transparente  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  15.623724699020386\n",
      "none\n",
      "5.0  e  3.0\n",
      "aqui  none  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.491099119186401\n",
      "none\n",
      "5.0  e  3.0\n",
      "aqui  none  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.38557767868042\n",
      "queixa especifica\n",
      "21.25  e  12.75\n",
      "aqui  queixa especifica  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.968159198760986\n",
      "quadro clinico\n",
      "17.5  e  10.5\n",
      "aqui  quadro clinico  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.496103048324585\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,len(df_termos_norm)):\n",
    "    if df_termos_norm.at[x,'Termos'] == None:\n",
    "        continue\n",
    "    num_max = len(df_termos_norm.at[x,'Termos'])+len(df_termos_norm.at[x,'Termos'])*0.25\n",
    "    num_min = len(df_termos_norm.at[x,'Termos'])-len(df_termos_norm.at[x,'Termos'])*0.25\n",
    "    print(df_termos_norm.at[x,'Termos'])\n",
    "    print(num_max, ' e ', num_min)\n",
    "    candidatos = pd.DataFrame(data=None, columns=['CUI', 'metodo', 'porc', 'Termos', 'STR_UMLS', 'termo_match'])\n",
    "    n_candidato = 0\n",
    "    \n",
    "    iniR = time.time()\n",
    "    for y in range(0,len(df_umls_norm['STR'])):\n",
    "        if df_umls_norm.at[y,'STR'] == None:\n",
    "            continue\n",
    "        if len(df_umls_norm.at[y,'STR']) < int(num_min):\n",
    "            continue\n",
    "        if len(df_umls_norm.at[y,'STR']) > int(num_max):\n",
    "            continue\n",
    "        if not df_umls_norm.at[y,'STR'][0] == df_termos_norm.at[x,'Termos'][0]:\n",
    "            continue\n",
    "        num = levenshtein(df_termos_norm.at[x,'Termos'],df_umls_norm.at[y,'STR'])\n",
    "        if len(df_umls_norm.at[y,'STR']) > 0:\n",
    "            perc = 100-num/len(df_umls_norm.at[y,'STR'])*100\n",
    "        else:\n",
    "            perc = 0\n",
    "        if perc == 100:\n",
    "            achou_Term = True\n",
    "            candidatos.at[n_candidato,'CUI'] = df_umls_norm.at[y, 'CUI']\n",
    "            candidatos.at[n_candidato,'Termos'] = df_termos.at[x,'Termos']\n",
    "            candidatos.at[n_candidato,'STR_UMLS'] = df_umls_norm.at[y, 'STR']\n",
    "            candidatos.at[n_candidato,'termo_match'] = df_termos_norm.at[x,'Termos']\n",
    "            candidatos.at[n_candidato, 'metodo'] = 1\n",
    "            candidatos.at[n_candidato, 'porc'] = perc\n",
    "            n_candidato += 1\n",
    "            break\n",
    "        if perc >= 90:\n",
    "            candidatos.at[n_candidato,'CUI'] = df_umls_norm.at[y, 'CUI']\n",
    "            candidatos.at[n_candidato,'Termos'] = df_termos.at[x,'Termos']\n",
    "            candidatos.at[n_candidato,'STR_UMLS'] = df_umls_norm.at[y, 'STR']\n",
    "            candidatos.at[n_candidato,'termo_match'] = df_termos_norm.at[x,'Termos']\n",
    "            candidatos.at[n_candidato, 'metodo'] = 1\n",
    "            candidatos.at[n_candidato, 'porc'] = perc\n",
    "            n_candidato += 1\n",
    "    candidatos = candidatos.sort_values('metodo')\n",
    "    print('aqui ', df_termos_norm.at[x,'Termos'] , ' --- ', candidatos)\n",
    "    if len(candidatos['CUI']) == 0:\n",
    "        df_termos_match.at[zz,'Termos'] = df_termos.at[x,'Termos']\n",
    "        df_termos_match.at[zz,'Regra'] = 0\n",
    "        df_termos_match.at[zz,'num_lev'] = 0\n",
    "        df_termos_match.at[zz, 'CUI'] = ''\n",
    "        df_termos_match.at[zz, 'STR_UMLS'] = ''\n",
    "        df_termos_match.at[zz, 'termo_match'] = ''\n",
    "        zz += 1\n",
    "    else:\n",
    "        for y in range(0, len(candidatos['CUI'])):\n",
    "            df_termos_match.at[zz,'Termos'] = df_termos.at[x,'Termos']\n",
    "            df_termos_match.at[zz,'Regra'] = candidatos.at[y,'metodo']\n",
    "            df_termos_match.at[zz,'num_lev'] = candidatos.at[y,'porc']\n",
    "            df_termos_match.at[zz, 'CUI'] = candidatos.at[y,'CUI']\n",
    "            df_termos_match.at[zz, 'STR_UMLS'] = candidatos.at[y,'STR_UMLS']\n",
    "            df_termos_match.at[zz, 'termo_match'] = candidatos.at[y,'termo_match']\n",
    "            zz += 1\n",
    "    fimR = time.time()\n",
    "    print('tempo, ', (fimR-iniR))\n",
    "    perc_max = 0\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('CliniMap_M1.xlsx')\n",
    "df_termos_match.to_excel(writer, 'Match')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.ExcelFile('CliniMap_M1.xlsx')\n",
    "clinMap_1 = read.parse('Match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_termos_match = pd.DataFrame(data=None, columns=['Termos', 'CUI', 'STR_UMLS', 'termo_match', 'Regra', 'num_lev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "servico particular \n",
      "23.75  e  14.25\n",
      "aqui  servico particular   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.60045337677002\n",
      "pupilar fotorreagente \n",
      "27.5  e  16.5\n",
      "aqui  pupilar fotorreagente   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  15.887298345565796\n",
      "none \n",
      "6.25  e  3.75\n",
      "aqui  none   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.568651914596558\n",
      "druso perimaculares \n",
      "25.0  e  15.0\n",
      "aqui  druso perimaculares   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.305294036865234\n",
      "atrofiar epitelio pigmentar retiniano \n",
      "47.5  e  28.5\n",
      "aqui  atrofiar epitelio pigmentar retiniano   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  13.711738586425781\n",
      "none \n",
      "6.25  e  3.75\n",
      "aqui  none   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.294533252716064\n",
      "none \n",
      "6.25  e  3.75\n",
      "aqui  none   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.420172214508057\n",
      "none \n",
      "6.25  e  3.75\n",
      "aqui  none   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.336052894592285\n",
      "corneo claro \n",
      "16.25  e  9.75\n",
      "aqui  corneo claro   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.326240539550781\n",
      "tensao ocular \n",
      "17.5  e  10.5\n",
      "aqui  tensao ocular   ---          CUI metodo porc              Termos       STR_UMLS     termo_match\n",
      "0  C0004095      2  100  hipertensão ocular  tensao ocular  tensao ocular \n",
      "tempo,  0.1449108123779297\n",
      "haver um ano \n",
      "16.25  e  9.75\n",
      "aqui  haver um ano   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.695461988449097\n",
      "cirurgia bariatrico \n",
      "25.0  e  15.0\n",
      "aqui  cirurgia bariatrico   ---          CUI metodo porc               Termos             STR_UMLS  \\\n",
      "0  C1456587      2  100  cirurgia bariátrica  cirurgia bariatrica   \n",
      "\n",
      "            termo_match  \n",
      "0  cirurgia bariatrico   \n",
      "tempo,  10.983282089233398\n",
      "excesso pelar \n",
      "17.5  e  10.5\n",
      "aqui  excesso pelar   ---          CUI metodo     porc           Termos      STR_UMLS     termo_match\n",
      "0  C0497406      2  92.8571  excesso de pele  excesso peso  excesso pelar \n",
      "1  C0497406      2  92.8571  excesso de pele  excesso peso  excesso pelar \n",
      "tempo,  10.085622072219849\n",
      "cirurgia bariatrico \n",
      "25.0  e  15.0\n",
      "aqui  cirurgia bariatrico   ---          CUI metodo porc               Termos             STR_UMLS  \\\n",
      "0  C1456587      2  100  cirurgia bariátrica  cirurgia bariatrica   \n",
      "\n",
      "            termo_match  \n",
      "0  cirurgia bariatrico   \n",
      "tempo,  11.029307842254639\n",
      "manobrar valsalva \n",
      "22.5  e  13.5\n",
      "aqui  manobrar valsalva   ---          CUI metodo porc               Termos          STR_UMLS  \\\n",
      "0  C0042293      2  100  manobra de valsalva  manobra valsalva   \n",
      "\n",
      "          termo_match  \n",
      "0  manobrar valsalva   \n",
      "tempo,  1.8255417346954346\n",
      "nodulo solido tecer celular cutaneo hemitorax direito \n",
      "67.5  e  40.5\n",
      "aqui  nodulo solido tecer celular cutaneo hemitorax direito   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.95129942893982\n",
      "vazar secrecao \n",
      "18.75  e  11.25\n",
      "aqui  vazar secrecao   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.506848573684692\n",
      "sinar alertar \n",
      "17.5  e  10.5\n",
      "aqui  sinar alertar   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.918864727020264\n",
      "sinar flogisticos \n",
      "22.5  e  13.5\n",
      "aqui  sinar flogisticos   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.258554220199585\n",
      "torax direito \n",
      "17.5  e  10.5\n",
      "aqui  torax direito   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.802474021911621\n",
      "none \n",
      "6.25  e  3.75\n",
      "aqui  none   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.35496997833252\n",
      "massar colecao organizar \n",
      "31.25  e  18.75\n",
      "aqui  massar colecao organizar   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.513941526412964\n",
      " ecotextura semelhar gordurar \n",
      "37.5  e  22.5\n",
      "aqui   ecotextura semelhar gordurar   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.380870580673218\n",
      "sinias flogisticos \n",
      "23.75  e  14.25\n",
      "aqui  sinias flogisticos   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.532922506332397\n",
      "ecogenico \n",
      "12.5  e  7.5\n",
      "aqui  ecogenico   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.872857570648193\n",
      "alto ambulatorial \n",
      "22.5  e  13.5\n",
      "aqui  alto ambulatorial   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.549128293991089\n",
      "nodulo solido bem definir discreto \n",
      "43.75  e  26.25\n",
      "aqui  nodulo solido bem definir discreto   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.203948974609375\n",
      "origem lipomatoso \n",
      "22.5  e  13.5\n",
      "aqui  origem lipomatoso   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.430949449539185\n",
      "localizar tecer celular cutaneo hemitorax direito \n",
      "62.5  e  37.5\n",
      "aqui  localizar tecer celular cutaneo hemitorax direito   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.723241090774536\n",
      "exerese lesao \n",
      "17.5  e  10.5\n",
      "aqui  exerese lesao   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.107319593429565\n",
      "fluxo exame doppler colorir \n",
      "35.0  e  21.0\n",
      "aqui  fluxo exame doppler colorir   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.007803916931152\n",
      "orientar cuidar \n",
      "20.0  e  12.0\n",
      "aqui  orientar cuidar   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.947798728942871\n",
      "derramar pleural parapneumonico \n",
      "40.0  e  24.0\n",
      "aqui  derramar pleural parapneumonico   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.267944097518921\n",
      "none \n",
      "6.25  e  3.75\n",
      "aqui  none   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.243154287338257\n",
      "dor articular \n",
      "17.5  e  10.5\n",
      "aqui  dor articular   ---          CUI metodo porc             Termos       STR_UMLS     termo_match\n",
      "0  C0003862      2  100  dores articulares  dor articular  dor articular \n",
      "tempo,  0.1434023380279541\n",
      "lesoes hiperemiar \n",
      "22.5  e  13.5\n",
      "aqui  lesoes hiperemiar   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.70108413696289\n",
      "mao direito \n",
      "15.0  e  9.0\n",
      "aqui  mao direito   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.543280124664307\n",
      "deltode esquerdo \n",
      "21.25  e  12.75\n",
      "aqui  deltode esquerdo   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.116409540176392\n",
      "fatorar melhorar piorar \n",
      "30.0  e  18.0\n",
      "aqui  fatorar melhorar piorar   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.322671175003052\n",
      "processar mastoise \n",
      "23.75  e  14.25\n",
      "aqui  processar mastoise   ---          CUI metodo     porc             Termos           STR_UMLS  \\\n",
      "0  C0446908      2  94.7368  processo mastoise  processo mastoide   \n",
      "\n",
      "           termo_match  \n",
      "0  processar mastoise   \n",
      "tempo,  16.49451518058777\n",
      "lesose pelar maculo-vesicular \n",
      "37.5  e  22.5\n",
      "aqui  lesose pelar maculo-vesicular   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.184958934783936\n",
      "ciclo mesntrual regular \n",
      "30.0  e  18.0\n",
      "aqui  ciclo mesntrual regular   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  16.413679361343384\n",
      "none \n",
      "6.25  e  3.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aqui  none   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.110544919967651\n",
      "furcula esternal \n",
      "21.25  e  12.75\n",
      "aqui  furcula esternal   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.8753981590271\n",
      "limitacao articular \n",
      "25.0  e  15.0\n",
      "aqui  limitacao articular   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.817301750183105\n",
      "medicar imunossupressor \n",
      "30.0  e  18.0\n",
      "aqui  medicar imunossupressor   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  13.862738132476807\n",
      "cervical anterior-esquerda , posterior \n",
      "48.75  e  29.25\n",
      "aqui  cervical anterior-esquerda , posterior   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  17.60726571083069\n",
      "fluxo medio \n",
      "15.0  e  9.0\n",
      "aqui  fluxo medio   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.152507543563843\n",
      "vertigem noturno \n",
      "21.25  e  12.75\n",
      "aqui  vertigem noturno   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.93117904663086\n",
      "discreto soprar sistolico focar mitral \n",
      "48.75  e  29.25\n",
      "aqui  discreto soprar sistolico focar mitral   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.042250394821167\n",
      "dor cabeca \n",
      "13.75  e  8.25\n",
      "aqui  dor cabeca   ---          CUI metodo porc         Termos    STR_UMLS  termo_match\n",
      "0  C0018681      2  100  dor de cabeça  dor cabeca  dor cabeca \n",
      "tempo,  0.6486349105834961\n",
      "palpitacao iniciar subito aparecer gradual \n",
      "53.75  e  32.25\n",
      "aqui  palpitacao iniciar subito aparecer gradual   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  13.271385431289673\n",
      "dor toracico \n",
      "16.25  e  9.75\n",
      "aqui  dor toracico   ---          CUI metodo porc        Termos      STR_UMLS    termo_match\n",
      "0  C0008031      2  100  dor torácica  dor toracica  dor toracico \n",
      "tempo,  0.28664326667785645\n",
      "sintoma diario \n",
      "18.75  e  11.25\n",
      "aqui  sintoma diario   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.734737157821655\n",
      "exacerbacao sintoma \n",
      "25.0  e  15.0\n",
      "aqui  exacerbacao sintoma   ---          CUI metodo porc                    Termos              STR_UMLS  \\\n",
      "0  C4042866      2  100  exacerbação dos sintomas  exacerbacao sintomas   \n",
      "\n",
      "            termo_match  \n",
      "0  exacerbacao sintoma   \n",
      "tempo,  11.841130018234253\n",
      "parietal bilateral \n",
      "23.75  e  14.25\n",
      "aqui  parietal bilateral   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.301650047302246\n",
      "herniorrafia guinal \n",
      "25.0  e  15.0\n",
      "aqui  herniorrafia guinal   ---          CUI metodo porc                 Termos               STR_UMLS  \\\n",
      "0  C0021446      2  100  herniorrafia inguinal  herniorrafia inguinal   \n",
      "\n",
      "            termo_match  \n",
      "0  herniorrafia guinal   \n",
      "tempo,  0.915703535079956\n",
      "lapso valva mitral \n",
      "23.75  e  14.25\n",
      "aqui  lapso valva mitral   ---          CUI metodo porc                    Termos               STR_UMLS  \\\n",
      "0  C0026267      2  100  prolapso de valva mitral  prolapso valva mitral   \n",
      "\n",
      "           termo_match  \n",
      "0  lapso valva mitral   \n",
      "tempo,  1.062185525894165\n",
      "camaras cardiacas normal \n",
      "31.25  e  18.75\n",
      "aqui  camaras cardiacas normal   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  16.464499711990356\n",
      "faltar ar \n",
      "12.5  e  7.5\n",
      "aqui  faltar ar   ---          CUI metodo porc       Termos  STR_UMLS termo_match\n",
      "0  C0013404      2  100  falta de ar  falta ar  faltar ar \n",
      "tempo,  0.3976762294769287\n",
      "alergia medicar \n",
      "20.0  e  12.0\n",
      "aqui  alergia medicar   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.626300573348999\n",
      "servico emergencia \n",
      "23.75  e  14.25\n",
      "aqui  servico emergencia   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.257521390914917\n",
      "auscultar cardiaca \n",
      "23.75  e  14.25\n",
      "aqui  auscultar cardiaca   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.620952129364014\n",
      "dispneia grande esforcos \n",
      "31.25  e  18.75\n",
      "aqui  dispneia grande esforcos   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.552936553955078\n",
      "mal estar \n",
      "12.5  e  7.5\n",
      "aqui  mal estar   ---          CUI metodo porc     Termos   STR_UMLS termo_match\n",
      "0  C2364135      2   90  mal estar  mal-estar  mal estar \n",
      "1  C2364135      2   90  mal estar  mal-estar  mal estar \n",
      "tempo,  8.603066205978394\n",
      "ventilatorio dependente \n",
      "30.0  e  18.0\n",
      "aqui  ventilatorio dependente   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.697076559066772\n",
      "refrigerar colar \n",
      "21.25  e  12.75\n",
      "aqui  refrigerar colar   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.334417819976807\n",
      "carcinoma garganta \n",
      "23.75  e  14.25\n",
      "aqui  carcinoma garganta   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  13.272244215011597\n",
      "trauma ocular \n",
      "17.5  e  10.5\n",
      "aqui  trauma ocular   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.600719451904297\n",
      "consultar rotina \n",
      "21.25  e  12.75\n",
      "aqui  consultar rotina   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.668793439865112\n",
      "none \n",
      "6.25  e  3.75\n",
      "aqui  none   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.225239515304565\n",
      "corneo cristalino parentar \n",
      "33.75  e  20.25\n",
      "aqui  corneo cristalino parentar   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  15.683768033981323\n",
      "none \n",
      "6.25  e  3.75\n",
      "aqui  none   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.144323825836182\n",
      "none \n",
      "6.25  e  3.75\n",
      "aqui  none   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.096953392028809\n",
      "queixar especifico \n",
      "23.75  e  14.25\n",
      "aqui  queixar especifico   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.692728042602539\n",
      "quadrar clinico \n",
      "20.0  e  12.0\n",
      "aqui  quadrar clinico   ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.43769359588623\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,len(df_termos_lemma)):\n",
    "    if df_termos_lemma.at[x,'Termos'] == None:\n",
    "        continue\n",
    "    \n",
    "    num_max = len(df_termos_lemma.at[x,'Termos'])+len(df_termos_lemma.at[x,'Termos'])*0.25\n",
    "    num_min = len(df_termos_lemma.at[x,'Termos'])-len(df_termos_lemma.at[x,'Termos'])*0.25\n",
    "    print(df_termos_lemma.at[x,'Termos'])\n",
    "    print(num_max, ' e ', num_min)\n",
    "    candidatos = pd.DataFrame(data=None, columns=['CUI', 'metodo', 'porc', 'Termos', 'STR_UMLS', 'termo_match'])\n",
    "    n_candidato = 0\n",
    "    \n",
    "    iniR = time.time()\n",
    "    for y in range(0,len(df_umls_norm['STR'])):\n",
    "        if df_umls_norm.at[y,'STRlemma'] == None:\n",
    "            continue\n",
    "        if len(df_umls_norm.at[y,'STRlemma']) < int(num_min):\n",
    "            continue\n",
    "        if len(df_umls_norm.at[y,'STRlemma']) > int(num_max):\n",
    "            continue\n",
    "        if not df_umls_norm.at[y,'STRlemma'][0] == df_termos_lemma.at[x,'Termos'][0]:\n",
    "            continue\n",
    "        num = levenshtein(df_termos_lemma.at[x,'Termos'],df_umls_norm.at[y,'STRlemma'])\n",
    "        if len(df_umls_norm.at[y,'STRlemma']) > 0:\n",
    "            perc = 100-num/len(df_umls_norm.at[y,'STRlemma'])*100\n",
    "        else:\n",
    "            perc = 0\n",
    "        if perc == 100:\n",
    "            achou_Term = True\n",
    "            candidatos.at[n_candidato,'CUI'] = df_umls_norm.at[y, 'CUI']\n",
    "            candidatos.at[n_candidato,'Termos'] = df_termos.at[x,'Termos']\n",
    "            candidatos.at[n_candidato,'STR_UMLS'] = df_umls_norm.at[y, 'STR']\n",
    "            candidatos.at[n_candidato,'termo_match'] = df_termos_lemma.at[x,'Termos']\n",
    "            candidatos.at[n_candidato, 'metodo'] = 2\n",
    "            candidatos.at[n_candidato, 'porc'] = perc\n",
    "            n_candidato += 1\n",
    "            break\n",
    "        if perc >= 90:\n",
    "            candidatos.at[n_candidato,'CUI'] = df_umls_norm.at[y, 'CUI']\n",
    "            candidatos.at[n_candidato,'Termos'] = df_termos.at[x,'Termos']\n",
    "            candidatos.at[n_candidato,'STR_UMLS'] = df_umls_norm.at[y, 'STR']\n",
    "            candidatos.at[n_candidato,'termo_match'] = df_termos_lemma.at[x,'Termos']\n",
    "            candidatos.at[n_candidato, 'metodo'] = 2\n",
    "            candidatos.at[n_candidato, 'porc'] = perc\n",
    "            n_candidato += 1\n",
    "    candidatos = candidatos.sort_values('metodo')\n",
    "    print('aqui ', df_termos_lemma.at[x,'Termos'] , ' --- ', candidatos)\n",
    "    if len(candidatos['CUI']) == 0:\n",
    "        df_termos_match.at[zz,'Termos'] = df_termos.at[x,'Termos']\n",
    "        df_termos_match.at[zz,'Regra'] = 0\n",
    "        df_termos_match.at[zz,'num_lev'] = 0\n",
    "        df_termos_match.at[zz, 'CUI'] = ''\n",
    "        df_termos_match.at[zz, 'STR_UMLS'] = ''\n",
    "        df_termos_match.at[zz, 'termo_match'] = ''\n",
    "        zz += 1\n",
    "    else:\n",
    "        for y in range(0, len(candidatos['CUI'])):\n",
    "            df_termos_match.at[zz,'Termos'] = df_termos.at[x,'Termos']\n",
    "            df_termos_match.at[zz,'Regra'] = candidatos.at[y,'metodo']\n",
    "            df_termos_match.at[zz,'num_lev'] = candidatos.at[y,'porc']\n",
    "            df_termos_match.at[zz, 'CUI'] = candidatos.at[y,'CUI']\n",
    "            df_termos_match.at[zz, 'STR_UMLS'] = candidatos.at[y,'STR_UMLS']\n",
    "            df_termos_match.at[zz, 'termo_match'] = candidatos.at[y,'termo_match']\n",
    "            zz += 1\n",
    "    fimR = time.time()\n",
    "    print('tempo, ', (fimR-iniR))\n",
    "    perc_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('CliniMap_M2.xlsx')\n",
    "df_termos_match.to_excel(writer, 'Match')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.ExcelFile('CliniMap_M2.xlsx')\n",
    "clinMap_2 = read.parse('Match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_termos_match = pd.DataFrame(data=None, columns=['Termos', 'CUI', 'STR_UMLS', 'termo_match', 'Regra', 'num_lev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "servic particul\n",
      "18.75  e  11.25\n",
      "aqui  servic particul  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.557265996932983\n",
      "pupil fotorreagent\n",
      "22.5  e  13.5\n",
      "aqui  pupil fotorreagent  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.557745456695557\n",
      "non\n",
      "3.75  e  2.25\n",
      "aqui  non  ---          CUI metodo porc Termos STR_UMLS termo_match\n",
      "0  C1010822      3  100   none     noni         non\n",
      "tempo,  5.218588590621948\n",
      "drus perimacul\n",
      "17.5  e  10.5\n",
      "aqui  drus perimacul  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.269019365310669\n",
      "atrof epiteli pigment retinian\n",
      "37.5  e  22.5\n",
      "aqui  atrof epiteli pigment retinian  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.432944059371948\n",
      "non\n",
      "3.75  e  2.25\n",
      "aqui  non  ---          CUI metodo porc Termos STR_UMLS termo_match\n",
      "0  C1010822      3  100   none     noni         non\n",
      "tempo,  5.022890090942383\n",
      "non\n",
      "3.75  e  2.25\n",
      "aqui  non  ---          CUI metodo porc Termos STR_UMLS termo_match\n",
      "0  C1010822      3  100   none     noni         non\n",
      "tempo,  5.240396022796631\n",
      "non\n",
      "3.75  e  2.25\n",
      "aqui  non  ---          CUI metodo porc Termos STR_UMLS termo_match\n",
      "0  C1010822      3  100   none     noni         non\n",
      "tempo,  5.215924263000488\n",
      "corn clar\n",
      "11.25  e  6.75\n",
      "aqui  corn clar  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.159081935882568\n",
      "hipertensa ocul\n",
      "18.75  e  11.25\n",
      "aqui  hipertensa ocul  ---          CUI metodo porc              Termos            STR_UMLS  \\\n",
      "0  C0028840      3  100  hipertensão ocular  hipertensao ocular   \n",
      "\n",
      "       termo_match  \n",
      "0  hipertensa ocul  \n",
      "tempo,  1.1914992332458496\n",
      "ha um ano\n",
      "11.25  e  6.75\n",
      "aqui  ha um ano  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.732796907424927\n",
      "cirurg bariatr\n",
      "17.5  e  10.5\n",
      "aqui  cirurg bariatr  ---          CUI metodo porc               Termos             STR_UMLS  \\\n",
      "0  C1456587      3  100  cirurgia bariátrica  cirurgia bariatrica   \n",
      "\n",
      "      termo_match  \n",
      "0  cirurg bariatr  \n",
      "tempo,  8.44710397720337\n",
      "excess pel\n",
      "12.5  e  7.5\n",
      "aqui  excess pel  ---          CUI metodo porc           Termos      STR_UMLS termo_match\n",
      "0  C0497406      3   90  excesso de pele  excesso peso  excess pel\n",
      "1  C0497406      3   90  excesso de pele  excesso peso  excess pel\n",
      "tempo,  9.138405799865723\n",
      "cirurg bariatr\n",
      "17.5  e  10.5\n",
      "aqui  cirurg bariatr  ---          CUI metodo porc               Termos             STR_UMLS  \\\n",
      "0  C1456587      3  100  cirurgia bariátrica  cirurgia bariatrica   \n",
      "\n",
      "      termo_match  \n",
      "0  cirurg bariatr  \n",
      "tempo,  8.604750156402588\n",
      "manobr valsalv\n",
      "17.5  e  10.5\n",
      "aqui  manobr valsalv  ---          CUI metodo porc               Termos          STR_UMLS     termo_match\n",
      "0  C0042293      3  100  manobra de valsalva  manobra valsalva  manobr valsalv\n",
      "tempo,  1.7148597240447998\n",
      "nodul sol tec celul subcutan hemitorax direit\n",
      "56.25  e  33.75\n",
      "aqui  nodul sol tec celul subcutan hemitorax direit  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.272836208343506\n",
      "vazament secreco\n",
      "20.0  e  12.0\n",
      "aqui  vazament secreco  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.857237577438354\n",
      "sin alert\n",
      "11.25  e  6.75\n",
      "aqui  sin alert  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.666009664535522\n",
      "sin flogist\n",
      "13.75  e  8.25\n",
      "aqui  sin flogist  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.959665775299072\n",
      "torax direit\n",
      "15.0  e  9.0\n",
      "aqui  torax direit  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.594477891921997\n",
      "non\n",
      "3.75  e  2.25\n",
      "aqui  non  ---          CUI metodo porc Termos STR_UMLS termo_match\n",
      "0  C1010822      3  100   none     noni         non\n",
      "tempo,  5.199939250946045\n",
      "mass coleco organiz\n",
      "23.75  e  14.25\n",
      "aqui  mass coleco organiz  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.76783537864685\n",
      " ecotextur semelh gordur\n",
      "30.0  e  18.0\n",
      "aqui   ecotextur semelh gordur  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.032259225845337\n",
      "sin flogist\n",
      "13.75  e  8.25\n",
      "aqui  sin flogist  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.94292402267456\n",
      "hiperecogen\n",
      "13.75  e  8.25\n",
      "aqui  hiperecogen  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.183475494384766\n",
      "alta ambulatorial\n",
      "21.25  e  12.75\n",
      "aqui  alta ambulatorial  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.37072467803955\n",
      "nodul sol bem defin discret\n",
      "33.75  e  20.25\n",
      "aqui  nodul sol bem defin discret  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.164714813232422\n",
      "orig lipomat\n",
      "15.0  e  9.0\n",
      "aqui  orig lipomat  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.168899536132812\n",
      "localiz tec celul subcutan hemitorax direit\n",
      "53.75  e  32.25\n",
      "aqui  localiz tec celul subcutan hemitorax direit  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.66983413696289\n",
      "exeres lesa\n",
      "13.75  e  8.25\n",
      "aqui  exeres lesa  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.5436532497406\n",
      "flux exam doppl color\n",
      "26.25  e  15.75\n",
      "aqui  flux exam doppl color  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.010485887527466\n",
      "orient cuid\n",
      "13.75  e  8.25\n",
      "aqui  orient cuid  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.057849645614624\n",
      "derram pleural parapneumon\n",
      "32.5  e  19.5\n",
      "aqui  derram pleural parapneumon  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.510209083557129\n",
      "non\n",
      "3.75  e  2.25\n",
      "aqui  non  ---          CUI metodo porc Termos STR_UMLS termo_match\n",
      "0  C1010822      3  100   none     noni         non\n",
      "tempo,  5.092540979385376\n",
      "dor articul\n",
      "13.75  e  8.25\n",
      "aqui  dor articul  ---          CUI metodo porc             Termos       STR_UMLS  termo_match\n",
      "0  C0003862      3  100  dores articulares  dor articular  dor articul\n",
      "tempo,  0.14063143730163574\n",
      "leso hiperemi\n",
      "16.25  e  9.75\n",
      "aqui  leso hiperemi  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.543572425842285\n",
      "ma direit\n",
      "11.25  e  6.75\n",
      "aqui  ma direit  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.86483359336853\n",
      "deltod esquerd\n",
      "17.5  e  10.5\n",
      "aqui  deltod esquerd  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.468039512634277\n",
      "fator melhor pior\n",
      "21.25  e  12.75\n",
      "aqui  fator melhor pior  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.614237308502197\n",
      "process mastois\n",
      "18.75  e  11.25\n",
      "aqui  process mastois  ---          CUI metodo     porc             Termos           STR_UMLS  \\\n",
      "0  C0446908      3  93.3333  processo mastoise  processo mastoide   \n",
      "\n",
      "       termo_match  \n",
      "0  process mastois  \n",
      "tempo,  11.104915618896484\n",
      "lesos pel maculo-vesicul\n",
      "30.0  e  18.0\n",
      "aqui  lesos pel maculo-vesicul  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.650155067443848\n",
      "cicl mesntrual regul\n",
      "25.0  e  15.0\n",
      "aqui  cicl mesntrual regul  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  13.906876802444458\n",
      "non\n",
      "3.75  e  2.25\n",
      "aqui  non  ---          CUI metodo porc Termos STR_UMLS termo_match\n",
      "0  C1010822      3  100   none     noni         non\n",
      "tempo,  5.122723340988159\n",
      "furcul esternal\n",
      "18.75  e  11.25\n",
      "aqui  furcul esternal  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.917826414108276\n",
      "limitaca articul\n",
      "20.0  e  12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aqui  limitaca articul  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.125761985778809\n",
      "medic imunossupressor\n",
      "26.25  e  15.75\n",
      "aqui  medic imunossupressor  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.419002771377563\n",
      "cervical anterior-esquerd , posterior\n",
      "46.25  e  27.75\n",
      "aqui  cervical anterior-esquerd , posterior  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  14.497195482254028\n",
      "flux medi\n",
      "11.25  e  6.75\n",
      "aqui  flux medi  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.65909218788147\n",
      "vertig noturn\n",
      "16.25  e  9.75\n",
      "aqui  vertig noturn  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.407527685165405\n",
      "discret sopr sistol foc mitral\n",
      "37.5  e  22.5\n",
      "aqui  discret sopr sistol foc mitral  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.999230146408081\n",
      "dor cabec\n",
      "11.25  e  6.75\n",
      "aqui  dor cabec  ---          CUI metodo porc         Termos    STR_UMLS termo_match\n",
      "0  C0018681      3  100  dor de cabeça  dor cabeca   dor cabec\n",
      "tempo,  0.6630644798278809\n",
      "palpit inici subit desaparec gradual\n",
      "45.0  e  27.0\n",
      "aqui  palpit inici subit desaparec gradual  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.658987522125244\n",
      "dor torac\n",
      "11.25  e  6.75\n",
      "aqui  dor torac  ---          CUI metodo porc        Termos      STR_UMLS termo_match\n",
      "0  C0008031      3  100  dor torácica  dor toracica   dor torac\n",
      "tempo,  0.26047253608703613\n",
      "sintom diari\n",
      "15.0  e  9.0\n",
      "aqui  sintom diari  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.642290353775024\n",
      "exacerb sintom\n",
      "17.5  e  10.5\n",
      "aqui  exacerb sintom  ---          CUI metodo porc                    Termos              STR_UMLS  \\\n",
      "0  C4042866      3  100  exacerbação dos sintomas  exacerbacao sintomas   \n",
      "\n",
      "      termo_match  \n",
      "0  exacerb sintom  \n",
      "tempo,  10.117723941802979\n",
      "parietal bilateral\n",
      "22.5  e  13.5\n",
      "aqui  parietal bilateral  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.534846782684326\n",
      "herniorraf inguinal\n",
      "23.75  e  14.25\n",
      "aqui  herniorraf inguinal  ---          CUI metodo porc                 Termos               STR_UMLS  \\\n",
      "0  C0021446      3  100  herniorrafia inguinal  herniorrafia inguinal   \n",
      "\n",
      "           termo_match  \n",
      "0  herniorraf inguinal  \n",
      "tempo,  0.8826193809509277\n",
      "prolaps valv mitral\n",
      "23.75  e  14.25\n",
      "aqui  prolaps valv mitral  ---          CUI metodo porc                    Termos               STR_UMLS  \\\n",
      "0  C0026267      3  100  prolapso de valva mitral  prolapso valva mitral   \n",
      "\n",
      "           termo_match  \n",
      "0  prolaps valv mitral  \n",
      "tempo,  1.0786778926849365\n",
      "cam cardiac norm\n",
      "20.0  e  12.0\n",
      "aqui  cam cardiac norm  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  12.408658266067505\n",
      "falt ar\n",
      "8.75  e  5.25\n",
      "aqui  falt ar  ---          CUI metodo porc       Termos  STR_UMLS termo_match\n",
      "0  C0013404      3  100  falta de ar  falta ar     falt ar\n",
      "tempo,  0.36097097396850586\n",
      "alerg medic\n",
      "13.75  e  8.25\n",
      "aqui  alerg medic  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.661828994750977\n",
      "servic emergenc\n",
      "18.75  e  11.25\n",
      "aqui  servic emergenc  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.171354055404663\n",
      "auscult cardiac\n",
      "18.75  e  11.25\n",
      "aqui  auscult cardiac  ---          CUI metodo porc             Termos              STR_UMLS  \\\n",
      "0  C0018793      3  100  ausculta cardiaca  auscultacao cardiaca   \n",
      "\n",
      "       termo_match  \n",
      "0  auscult cardiac  \n",
      "tempo,  1.1005470752716064\n",
      "dispn grand esforc\n",
      "22.5  e  13.5\n",
      "aqui  dispn grand esforc  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.019419431686401\n",
      "mal estar\n",
      "11.25  e  6.75\n",
      "aqui  mal estar  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.725194454193115\n",
      "ventilatori dependent\n",
      "26.25  e  15.75\n",
      "aqui  ventilatori dependent  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  10.268089532852173\n",
      "refriger col\n",
      "15.0  e  9.0\n",
      "aqui  refriger col  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.3213951587677\n",
      "carcinom gargant\n",
      "20.0  e  12.0\n",
      "aqui  carcinom gargant  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  13.135990142822266\n",
      "traum ocul\n",
      "12.5  e  7.5\n",
      "aqui  traum ocul  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.340534448623657\n",
      "consult rotin\n",
      "16.25  e  9.75\n",
      "aqui  consult rotin  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  11.484755516052246\n",
      "non\n",
      "3.75  e  2.25\n",
      "aqui  non  ---          CUI metodo porc Termos STR_UMLS termo_match\n",
      "0  C1010822      3  100   none     noni         non\n",
      "tempo,  5.492123126983643\n",
      "corn cristalin transparent\n",
      "32.5  e  19.5\n",
      "aqui  corn cristalin transparent  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  14.004456281661987\n",
      "non\n",
      "3.75  e  2.25\n",
      "aqui  non  ---          CUI metodo porc Termos STR_UMLS termo_match\n",
      "0  C1010822      3  100   none     noni         non\n",
      "tempo,  5.241971731185913\n",
      "non\n",
      "3.75  e  2.25\n",
      "aqui  non  ---          CUI metodo porc Termos STR_UMLS termo_match\n",
      "0  C1010822      3  100   none     noni         non\n",
      "tempo,  5.058460712432861\n",
      "queix especif\n",
      "16.25  e  9.75\n",
      "aqui  queix especif  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  9.284824848175049\n",
      "quadr clinic\n",
      "15.0  e  9.0\n",
      "aqui  quadr clinic  ---  Empty DataFrame\n",
      "Columns: [CUI, metodo, porc, Termos, STR_UMLS, termo_match]\n",
      "Index: []\n",
      "tempo,  8.918783187866211\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,len(df_termos_stem)):\n",
    "    if df_termos_stem.at[x,'Termos'] == None:\n",
    "        continue\n",
    "    \n",
    "    num_max = len(df_termos_stem.at[x,'Termos'])+len(df_termos_stem.at[x,'Termos'])*0.25\n",
    "    num_min = len(df_termos_stem.at[x,'Termos'])-len(df_termos_stem.at[x,'Termos'])*0.25\n",
    "    print(df_termos_stem.at[x,'Termos'])\n",
    "    print(num_max, ' e ', num_min)\n",
    "    candidatos = pd.DataFrame(data=None, columns=['CUI', 'metodo', 'porc', 'Termos', 'STR_UMLS', 'termo_match'])\n",
    "    n_candidato = 0\n",
    "    \n",
    "    iniR = time.time()\n",
    "    for y in range(0,len(df_umls_norm['STR'])):\n",
    "        if df_umls_norm.at[y,'STRstem'] == None:\n",
    "            continue\n",
    "        if len(df_umls_norm.at[y,'STRstem']) < int(num_min):\n",
    "            continue\n",
    "        if len(df_umls_norm.at[y,'STRstem']) > int(num_max):\n",
    "            continue\n",
    "        if not df_umls_norm.at[y,'STRstem'][0] == df_termos_stem.at[x,'Termos'][0]:\n",
    "            continue\n",
    "        num = levenshtein(df_termos_stem.at[x,'Termos'],df_umls_norm.at[y,'STRstem'])\n",
    "        if len(df_umls_norm.at[y,'STRstem']) > 0:\n",
    "            perc = 100-num/len(df_umls_norm.at[y,'STRstem'])*100\n",
    "        else:\n",
    "            perc = 0\n",
    "        if perc == 100:\n",
    "            achou_Term = True\n",
    "            candidatos.at[n_candidato,'CUI'] = df_umls_norm.at[y, 'CUI']\n",
    "            candidatos.at[n_candidato,'Termos'] = df_termos.at[x,'Termos']\n",
    "            candidatos.at[n_candidato,'STR_UMLS'] = df_umls_norm.at[y, 'STR']\n",
    "            candidatos.at[n_candidato,'termo_match'] = df_termos_stem.at[x,'Termos']\n",
    "            candidatos.at[n_candidato, 'metodo'] = 3\n",
    "            candidatos.at[n_candidato, 'porc'] = perc\n",
    "            n_candidato += 1\n",
    "            break\n",
    "        if perc >= 90:\n",
    "            candidatos.at[n_candidato,'CUI'] = df_umls_norm.at[y, 'CUI']\n",
    "            candidatos.at[n_candidato,'Termos'] = df_termos.at[x,'Termos']\n",
    "            candidatos.at[n_candidato,'STR_UMLS'] = df_umls_norm.at[y, 'STR']\n",
    "            candidatos.at[n_candidato,'termo_match'] = df_termos_stem.at[x,'Termos']\n",
    "            candidatos.at[n_candidato, 'metodo'] = 3\n",
    "            candidatos.at[n_candidato, 'porc'] = perc\n",
    "            n_candidato += 1\n",
    "    candidatos = candidatos.sort_values('metodo')\n",
    "    print('aqui ', df_termos_stem.at[x,'Termos'] , ' --- ', candidatos)\n",
    "    if len(candidatos['CUI']) == 0:\n",
    "        df_termos_match.at[zz,'Termos'] = df_termos.at[x,'Termos']\n",
    "        df_termos_match.at[zz,'Regra'] = 0\n",
    "        df_termos_match.at[zz,'num_lev'] = 0\n",
    "        df_termos_match.at[zz, 'CUI'] = ''\n",
    "        df_termos_match.at[zz, 'STR_UMLS'] = ''\n",
    "        df_termos_match.at[zz, 'termo_match'] = ''\n",
    "        zz += 1\n",
    "    else:\n",
    "        for y in range(0, len(candidatos['CUI'])):\n",
    "            df_termos_match.at[zz,'Termos'] = df_termos.at[x,'Termos']\n",
    "            df_termos_match.at[zz,'Regra'] = candidatos.at[y,'metodo']\n",
    "            df_termos_match.at[zz,'num_lev'] = candidatos.at[y,'porc']\n",
    "            df_termos_match.at[zz, 'CUI'] = candidatos.at[y,'CUI']\n",
    "            df_termos_match.at[zz, 'STR_UMLS'] = candidatos.at[y,'STR_UMLS']\n",
    "            df_termos_match.at[zz, 'termo_match'] = candidatos.at[y,'termo_match']\n",
    "            zz += 1\n",
    "    fimR = time.time()\n",
    "    print('tempo, ', (fimR-iniR))\n",
    "    perc_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('CliniMap_M3.xlsx')\n",
    "df_termos_match.to_excel(writer, 'Match')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.ExcelFile('CliniMap_M3.xlsx')\n",
    "clinMap_3 = read.parse('Match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_termos_match = pd.DataFrame(data=None, columns=['Termos', 'CUI', 'STR_UMLS', 'termo_match', 'Regra', 'num_lev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,len(df_termos_norm)):\n",
    "    if df_termos_norm.at[x,'Termos'] == None:\n",
    "        continue\n",
    "    num_max = len(df_termos_norm.at[x,'Termos'])+len(df_termos_norm.at[x,'Termos'])*0.25\n",
    "    num_min = len(df_termos_norm.at[x,'Termos'])-len(df_termos_norm.at[x,'Termos'])*0.25\n",
    "    print(df_termos_norm.at[x,'Termos'])\n",
    "    print(num_max, ' e ', num_min)\n",
    "    candidatos = pd.DataFrame(data=None, columns=['CUI', 'metodo', 'porc', 'Termos', 'STR_UMLS', 'termo_match'])\n",
    "    n_candidato = 0\n",
    "    words = df_termos_norm.at[x,'Termos'].split()\n",
    "    words_lemma = df_termos_lemma.at[x,'Termos'].split()\n",
    "    words_steam = df_termos_stem.at[x, 'Termos'].split()\n",
    "    \n",
    "    iniR = time.time()\n",
    "    for y in range(0,len(df_umls_norm['STR'])):\n",
    "        if df_umls_norm.at[y,'STR'] == None:\n",
    "            continue\n",
    "        if len(df_umls_norm.at[y,'STR']) < int(num_min):\n",
    "            continue\n",
    "        if len(df_umls_norm.at[y,'STR']) > int(num_max):\n",
    "            continue\n",
    "        if not df_umls_norm.at[y,'STR'][0] == df_termos_norm.at[x,'Termos'][0]:\n",
    "            continue\n",
    "        num = levenshtein(df_termos_norm.at[x,'Termos'],df_umls_norm.at[y,'STR'])\n",
    "        if len(df_umls_norm.at[y,'STR']) > 0:\n",
    "            perc = 100-num/len(df_umls_norm.at[y,'STR'])*100\n",
    "        else:\n",
    "            perc = 0\n",
    "        if perc == 100:\n",
    "            achou_Term = True\n",
    "            candidatos.at[n_candidato,'CUI'] = df_umls_norm.at[y, 'CUI']\n",
    "            candidatos.at[n_candidato,'Termos'] = df_termos.at[x,'Termos']\n",
    "            candidatos.at[n_candidato,'STR_UMLS'] = df_umls_norm.at[y, 'STR']\n",
    "            candidatos.at[n_candidato,'termo_match'] = df_termos_norm.at[x,'Termos']\n",
    "            candidatos.at[n_candidato, 'metodo'] = 1\n",
    "            candidatos.at[n_candidato, 'porc'] = perc\n",
    "            n_candidato += 1\n",
    "            break\n",
    "        if perc >= 90:\n",
    "            candidatos.at[n_candidato,'CUI'] = df_umls_norm.at[y, 'CUI']\n",
    "            candidatos.at[n_candidato,'Termos'] = df_termos.at[x,'Termos']\n",
    "            candidatos.at[n_candidato,'STR_UMLS'] = df_umls_norm.at[y, 'STR']\n",
    "            candidatos.at[n_candidato,'termo_match'] = df_termos_norm.at[x,'Termos']\n",
    "            candidatos.at[n_candidato, 'metodo'] = 1\n",
    "            candidatos.at[n_candidato, 'porc'] = perc\n",
    "            n_candidato += 1\n",
    "    candidatos = candidatos.sort_values('metodo')\n",
    "    print('aqui ', df_termos_norm.at[x,'Termos'] , ' --- ', candidatos)\n",
    "    if len(candidatos['CUI']) == 0:\n",
    "        df_termos_match.at[zz,'Termos'] = df_termos.at[x,'Termos']\n",
    "        df_termos_match.at[zz,'Regra'] = 0\n",
    "        df_termos_match.at[zz,'num_lev'] = 0\n",
    "        df_termos_match.at[zz, 'CUI'] = ''\n",
    "        df_termos_match.at[zz, 'STR_UMLS'] = ''\n",
    "        df_termos_match.at[zz, 'termo_match'] = ''\n",
    "        zz += 1\n",
    "    else:\n",
    "        for y in range(0, len(candidatos['CUI'])):\n",
    "            df_termos_match.at[zz,'Termos'] = df_termos.at[x,'Termos']\n",
    "            df_termos_match.at[zz,'Regra'] = candidatos.at[y,'metodo']\n",
    "            df_termos_match.at[zz,'num_lev'] = candidatos.at[y,'porc']\n",
    "            df_termos_match.at[zz, 'CUI'] = candidatos.at[y,'CUI']\n",
    "            df_termos_match.at[zz, 'STR_UMLS'] = candidatos.at[y,'STR_UMLS']\n",
    "            df_termos_match.at[zz, 'termo_match'] = candidatos.at[y,'termo_match']\n",
    "            zz += 1\n",
    "    fimR = time.time()\n",
    "    print('tempo, ', (fimR-iniR))\n",
    "    perc_max = 0\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
